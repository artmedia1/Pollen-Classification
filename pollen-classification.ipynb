{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1335,"status":"ok","timestamp":1675408977525,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"2-ydIxyNKW8M","outputId":"59c8fa53-0cf7-41be-b74e-8ddaa56b4773"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive') #note - you must add the shared ENG 4000 folder as a shortcut to your google drive in the /content/drive/MyDrive/ path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zWdnC_E2zvaP"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np \n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns \n","from statsmodels.graphics.gofplots import qqplot\n","import scipy.stats\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestRegressor\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from keras.layers import Dense, Dropout, BatchNormalization, Activation\n","from tensorflow.keras.optimizers import SGD\n","import math\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from keras import layers, optimizers, regularizers\n","from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n","from keras.metrics import Precision, Recall\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1675408984539,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"0_h112AEBv3A","outputId":"b37d631b-2ac8-4b16-8b60-318d070d50a5"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-29f3a052-59d3-44b0-8b91-dd9b05442784\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sample ID</th>\n","      <th>Pollen</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29f3a052-59d3-44b0-8b91-dd9b05442784')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-29f3a052-59d3-44b0-8b91-dd9b05442784 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-29f3a052-59d3-44b0-8b91-dd9b05442784');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   Sample ID  Pollen\n","0          0       0\n","1          1       0\n","2          2       0\n","3          3       0\n","4          4       0"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["#Import libraries needed for EDA\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","%matplotlib inline\n","from sklearn.preprocessing import LabelEncoder\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from keras.layers import Dense, Dropout, BatchNormalization, Activation\n","from tensorflow.keras.optimizers import SGD\n","\n","#Import labels (these will the target variables we will use to predict)\n","labels = pd.read_csv(\"/content/drive/MyDrive/ENG 4000/labels.csv\") \n","labels.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"executionInfo":{"elapsed":407,"status":"ok","timestamp":1675408984933,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"Kol4P0B9oiHo","outputId":"8fa7911f-f7fc-45e8-b266-467aa22d86a4"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-d0fc2f0b-0f15-45c3-99ad-10b83f54e44a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sample ID</th>\n","      <th>350-400 nm, t=0</th>\n","      <th>350-400 nm, t=1</th>\n","      <th>350-400 nm, t=2</th>\n","      <th>350-400 nm, t=3</th>\n","      <th>350-400 nm, t=4</th>\n","      <th>350-400 nm, t=5</th>\n","      <th>350-400 nm, t=6</th>\n","      <th>350-400 nm, t=7</th>\n","      <th>350-400 nm, t=8</th>\n","      <th>...</th>\n","      <th>672-800 nm, t=14</th>\n","      <th>672-800 nm, t=15</th>\n","      <th>672-800 nm, t=16</th>\n","      <th>672-800 nm, t=17</th>\n","      <th>672-800 nm, t=18</th>\n","      <th>672-800 nm, t=19</th>\n","      <th>672-800 nm, t=20</th>\n","      <th>672-800 nm, t=21</th>\n","      <th>672-800 nm, t=22</th>\n","      <th>672-800 nm, t=23</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>-0.010454</td>\n","      <td>0.000201</td>\n","      <td>0.010856</td>\n","      <td>0.114194</td>\n","      <td>0.217531</td>\n","      <td>0.166868</td>\n","      <td>0.116204</td>\n","      <td>0.109168</td>\n","      <td>0.102131</td>\n","      <td>...</td>\n","      <td>-0.015480</td>\n","      <td>-0.016084</td>\n","      <td>-0.017089</td>\n","      <td>-0.014877</td>\n","      <td>-0.013068</td>\n","      <td>-0.003418</td>\n","      <td>0.006031</td>\n","      <td>0.011460</td>\n","      <td>0.016888</td>\n","      <td>0.013872</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.119942</td>\n","      <td>0.184249</td>\n","      <td>0.248555</td>\n","      <td>0.236994</td>\n","      <td>0.225434</td>\n","      <td>0.098988</td>\n","      <td>-0.028179</td>\n","      <td>-0.054191</td>\n","      <td>-0.081647</td>\n","      <td>...</td>\n","      <td>0.013006</td>\n","      <td>0.028179</td>\n","      <td>0.043353</td>\n","      <td>0.057081</td>\n","      <td>0.070809</td>\n","      <td>0.057081</td>\n","      <td>0.043353</td>\n","      <td>0.013728</td>\n","      <td>-0.016618</td>\n","      <td>-0.026012</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>-0.016149</td>\n","      <td>0.063383</td>\n","      <td>0.142915</td>\n","      <td>0.286637</td>\n","      <td>0.430359</td>\n","      <td>0.262414</td>\n","      <td>0.094469</td>\n","      <td>0.082761</td>\n","      <td>0.071054</td>\n","      <td>...</td>\n","      <td>0.024223</td>\n","      <td>0.023819</td>\n","      <td>0.023415</td>\n","      <td>0.014534</td>\n","      <td>0.005248</td>\n","      <td>-0.009285</td>\n","      <td>-0.024627</td>\n","      <td>-0.027049</td>\n","      <td>-0.030279</td>\n","      <td>-0.015745</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0.067116</td>\n","      <td>0.198401</td>\n","      <td>0.329687</td>\n","      <td>0.366400</td>\n","      <td>0.403114</td>\n","      <td>0.235325</td>\n","      <td>0.067536</td>\n","      <td>0.063644</td>\n","      <td>0.059752</td>\n","      <td>...</td>\n","      <td>-0.008100</td>\n","      <td>-0.006627</td>\n","      <td>-0.005365</td>\n","      <td>-0.001999</td>\n","      <td>0.001262</td>\n","      <td>0.003787</td>\n","      <td>0.006312</td>\n","      <td>0.007469</td>\n","      <td>0.008626</td>\n","      <td>0.004103</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>-0.043760</td>\n","      <td>0.090762</td>\n","      <td>0.225284</td>\n","      <td>0.214749</td>\n","      <td>0.204214</td>\n","      <td>0.213128</td>\n","      <td>0.222042</td>\n","      <td>0.133712</td>\n","      <td>0.044571</td>\n","      <td>...</td>\n","      <td>-0.059157</td>\n","      <td>-0.068882</td>\n","      <td>-0.080227</td>\n","      <td>-0.052674</td>\n","      <td>-0.026742</td>\n","      <td>-0.004052</td>\n","      <td>0.017828</td>\n","      <td>0.031605</td>\n","      <td>0.045381</td>\n","      <td>0.020259</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 97 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0fc2f0b-0f15-45c3-99ad-10b83f54e44a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d0fc2f0b-0f15-45c3-99ad-10b83f54e44a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d0fc2f0b-0f15-45c3-99ad-10b83f54e44a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   Sample ID  350-400 nm, t=0  350-400 nm, t=1  350-400 nm, t=2  \\\n","0          0        -0.010454         0.000201         0.010856   \n","1          1         0.119942         0.184249         0.248555   \n","2          2        -0.016149         0.063383         0.142915   \n","3          3         0.067116         0.198401         0.329687   \n","4          4        -0.043760         0.090762         0.225284   \n","\n","   350-400 nm, t=3  350-400 nm, t=4  350-400 nm, t=5  350-400 nm, t=6  \\\n","0         0.114194         0.217531         0.166868         0.116204   \n","1         0.236994         0.225434         0.098988        -0.028179   \n","2         0.286637         0.430359         0.262414         0.094469   \n","3         0.366400         0.403114         0.235325         0.067536   \n","4         0.214749         0.204214         0.213128         0.222042   \n","\n","   350-400 nm, t=7  350-400 nm, t=8  ...  672-800 nm, t=14  672-800 nm, t=15  \\\n","0         0.109168         0.102131  ...         -0.015480         -0.016084   \n","1        -0.054191        -0.081647  ...          0.013006          0.028179   \n","2         0.082761         0.071054  ...          0.024223          0.023819   \n","3         0.063644         0.059752  ...         -0.008100         -0.006627   \n","4         0.133712         0.044571  ...         -0.059157         -0.068882   \n","\n","   672-800 nm, t=16  672-800 nm, t=17  672-800 nm, t=18  672-800 nm, t=19  \\\n","0         -0.017089         -0.014877         -0.013068         -0.003418   \n","1          0.043353          0.057081          0.070809          0.057081   \n","2          0.023415          0.014534          0.005248         -0.009285   \n","3         -0.005365         -0.001999          0.001262          0.003787   \n","4         -0.080227         -0.052674         -0.026742         -0.004052   \n","\n","   672-800 nm, t=20  672-800 nm, t=21  672-800 nm, t=22  672-800 nm, t=23  \n","0          0.006031          0.011460          0.016888          0.013872  \n","1          0.043353          0.013728         -0.016618         -0.026012  \n","2         -0.024627         -0.027049         -0.030279         -0.015745  \n","3          0.006312          0.007469          0.008626          0.004103  \n","4          0.017828          0.031605          0.045381          0.020259  \n","\n","[5 rows x 97 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["#Import features (these will the be data we use to predict the labels)\n","lifetime = pd.read_csv(\"/content/drive/MyDrive/ENG 4000/lifetime.csv\")\n","lifetime.head() #Head allows us to show the first 4 rows of the data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"executionInfo":{"elapsed":298,"status":"ok","timestamp":1675408985227,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"RqWFNtzupbnk","outputId":"436bee76-54f0-4169-943b-9353afbd777f"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-82f0abae-9dfa-4202-8549-3fed7d52906c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sample ID</th>\n","      <th>350 nm, t=0</th>\n","      <th>364 nm, t=0</th>\n","      <th>379 nm, t=0</th>\n","      <th>393 nm, t=0</th>\n","      <th>408 nm, t=0</th>\n","      <th>422 nm, t=0</th>\n","      <th>437 nm, t=0</th>\n","      <th>451 nm, t=0</th>\n","      <th>466 nm, t=0</th>\n","      <th>...</th>\n","      <th>669 nm, t=3</th>\n","      <th>683 nm, t=3</th>\n","      <th>698 nm, t=3</th>\n","      <th>712 nm, t=3</th>\n","      <th>727 nm, t=3</th>\n","      <th>741 nm, t=3</th>\n","      <th>756 nm, t=3</th>\n","      <th>770 nm, t=3</th>\n","      <th>785 nm, t=3</th>\n","      <th>800 nm, t=3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.129278</td>\n","      <td>0.041910</td>\n","      <td>0.121054</td>\n","      <td>0.496012</td>\n","      <td>0.800121</td>\n","      <td>1.000000</td>\n","      <td>0.853183</td>\n","      <td>0.962091</td>\n","      <td>0.745947</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000144</td>\n","      <td>-0.000576</td>\n","      <td>-0.000790</td>\n","      <td>-0.000681</td>\n","      <td>-0.000004</td>\n","      <td>-0.000105</td>\n","      <td>-1.480000e-19</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>-0.011963</td>\n","      <td>0.086481</td>\n","      <td>0.099374</td>\n","      <td>0.132618</td>\n","      <td>0.527263</td>\n","      <td>0.820056</td>\n","      <td>0.939995</td>\n","      <td>1.000000</td>\n","      <td>0.914903</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000286</td>\n","      <td>-0.001143</td>\n","      <td>-0.001451</td>\n","      <td>-0.001815</td>\n","      <td>-0.000667</td>\n","      <td>-0.000672</td>\n","      <td>-9.580000e-19</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>-0.006165</td>\n","      <td>0.110295</td>\n","      <td>0.157199</td>\n","      <td>0.232229</td>\n","      <td>0.404684</td>\n","      <td>0.739406</td>\n","      <td>1.000000</td>\n","      <td>0.887348</td>\n","      <td>0.716564</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>-0.000157</td>\n","      <td>0.000630</td>\n","      <td>0.000892</td>\n","      <td>0.000630</td>\n","      <td>-3.147950e-04</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>-0.005657</td>\n","      <td>0.036070</td>\n","      <td>0.101411</td>\n","      <td>0.245322</td>\n","      <td>0.426752</td>\n","      <td>0.674580</td>\n","      <td>0.992005</td>\n","      <td>1.000000</td>\n","      <td>0.851382</td>\n","      <td>...</td>\n","      <td>-0.000191</td>\n","      <td>0.000048</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>-0.000130</td>\n","      <td>0.000519</td>\n","      <td>0.000606</td>\n","      <td>1.038110e-03</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>-0.007325</td>\n","      <td>0.063621</td>\n","      <td>0.125746</td>\n","      <td>0.214150</td>\n","      <td>0.409600</td>\n","      <td>0.782647</td>\n","      <td>1.000000</td>\n","      <td>0.770002</td>\n","      <td>0.544802</td>\n","      <td>...</td>\n","      <td>0.001524</td>\n","      <td>-0.000381</td>\n","      <td>0.0</td>\n","      <td>0.000466</td>\n","      <td>-0.001863</td>\n","      <td>-0.001919</td>\n","      <td>-0.004657</td>\n","      <td>-0.003952</td>\n","      <td>-0.003444</td>\n","      <td>-4.060000e-18</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 129 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82f0abae-9dfa-4202-8549-3fed7d52906c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-82f0abae-9dfa-4202-8549-3fed7d52906c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-82f0abae-9dfa-4202-8549-3fed7d52906c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   Sample ID  350 nm, t=0  364 nm, t=0  379 nm, t=0  393 nm, t=0  408 nm, t=0  \\\n","0          0     0.129278     0.041910     0.121054     0.496012     0.800121   \n","1          1    -0.011963     0.086481     0.099374     0.132618     0.527263   \n","2          2    -0.006165     0.110295     0.157199     0.232229     0.404684   \n","3          3    -0.005657     0.036070     0.101411     0.245322     0.426752   \n","4          4    -0.007325     0.063621     0.125746     0.214150     0.409600   \n","\n","   422 nm, t=0  437 nm, t=0  451 nm, t=0  466 nm, t=0  ...  669 nm, t=3  \\\n","0     1.000000     0.853183     0.962091     0.745947  ...     0.000000   \n","1     0.820056     0.939995     1.000000     0.914903  ...     0.000000   \n","2     0.739406     1.000000     0.887348     0.716564  ...     0.000000   \n","3     0.674580     0.992005     1.000000     0.851382  ...    -0.000191   \n","4     0.782647     1.000000     0.770002     0.544802  ...     0.001524   \n","\n","   683 nm, t=3  698 nm, t=3  712 nm, t=3  727 nm, t=3  741 nm, t=3  \\\n","0     0.000000          0.0     0.000144    -0.000576    -0.000790   \n","1     0.000000          0.0     0.000286    -0.001143    -0.001451   \n","2     0.000000          0.0     0.000000     0.000000    -0.000157   \n","3     0.000048          0.0     0.000000     0.000000     0.000000   \n","4    -0.000381          0.0     0.000466    -0.001863    -0.001919   \n","\n","   756 nm, t=3  770 nm, t=3  785 nm, t=3   800 nm, t=3  \n","0    -0.000681    -0.000004    -0.000105 -1.480000e-19  \n","1    -0.001815    -0.000667    -0.000672 -9.580000e-19  \n","2     0.000630     0.000892     0.000630 -3.147950e-04  \n","3    -0.000130     0.000519     0.000606  1.038110e-03  \n","4    -0.004657    -0.003952    -0.003444 -4.060000e-18  \n","\n","[5 rows x 129 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["spectrum = pd.read_csv(\"/content/drive/MyDrive/ENG 4000/spectrum.csv\")\n","spectrum.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"executionInfo":{"elapsed":8809,"status":"ok","timestamp":1675408994030,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"V2Bs4mVJpt9Y","outputId":"555a3eae-ed83-4206-886c-46be8aa04c74"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-05e8fef8-4d87-4668-98c5-195d24a7c0cb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sample ID</th>\n","      <th>angle=-37.5, t=0</th>\n","      <th>angle=-37.5, t=1</th>\n","      <th>angle=-37.5, t=2</th>\n","      <th>angle=-37.5, t=3</th>\n","      <th>angle=-37.5, t=4</th>\n","      <th>angle=-37.5, t=5</th>\n","      <th>angle=-37.5, t=6</th>\n","      <th>angle=-37.5, t=7</th>\n","      <th>angle=-37.5, t=8</th>\n","      <th>...</th>\n","      <th>angle=37.5, t=110</th>\n","      <th>angle=37.5, t=111</th>\n","      <th>angle=37.5, t=112</th>\n","      <th>angle=37.5, t=113</th>\n","      <th>angle=37.5, t=114</th>\n","      <th>angle=37.5, t=115</th>\n","      <th>angle=37.5, t=116</th>\n","      <th>angle=37.5, t=117</th>\n","      <th>angle=37.5, t=118</th>\n","      <th>angle=37.5, t=119</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>982.383616</td>\n","      <td>1002.18053</td>\n","      <td>1034.797552</td>\n","      <td>892.183468</td>\n","      <td>840.017425</td>\n","      <td>739.383196</td>\n","      <td>740.476799</td>\n","      <td>600.65502</td>\n","      <td>695.104062</td>\n","      <td>873.792882</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 2401 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05e8fef8-4d87-4668-98c5-195d24a7c0cb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-05e8fef8-4d87-4668-98c5-195d24a7c0cb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-05e8fef8-4d87-4668-98c5-195d24a7c0cb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   Sample ID  angle=-37.5, t=0  angle=-37.5, t=1  angle=-37.5, t=2  \\\n","0          0               0.0               0.0               0.0   \n","1          1               0.0               0.0               0.0   \n","2          2               0.0               0.0               0.0   \n","3          3               0.0               0.0               0.0   \n","4          4               0.0               0.0               0.0   \n","\n","   angle=-37.5, t=3  angle=-37.5, t=4  angle=-37.5, t=5  angle=-37.5, t=6  \\\n","0               0.0               0.0               0.0               0.0   \n","1               0.0               0.0               0.0               0.0   \n","2               0.0               0.0               0.0               0.0   \n","3               0.0               0.0               0.0               0.0   \n","4               0.0               0.0               0.0               0.0   \n","\n","   angle=-37.5, t=7  angle=-37.5, t=8  ...  angle=37.5, t=110  \\\n","0               0.0               0.0  ...           0.000000   \n","1               0.0               0.0  ...           0.000000   \n","2               0.0               0.0  ...           0.000000   \n","3               0.0               0.0  ...         982.383616   \n","4               0.0               0.0  ...           0.000000   \n","\n","   angle=37.5, t=111  angle=37.5, t=112  angle=37.5, t=113  angle=37.5, t=114  \\\n","0            0.00000           0.000000           0.000000           0.000000   \n","1            0.00000           0.000000           0.000000           0.000000   \n","2            0.00000           0.000000           0.000000           0.000000   \n","3         1002.18053        1034.797552         892.183468         840.017425   \n","4            0.00000           0.000000           0.000000           0.000000   \n","\n","   angle=37.5, t=115  angle=37.5, t=116  angle=37.5, t=117  angle=37.5, t=118  \\\n","0           0.000000           0.000000            0.00000           0.000000   \n","1           0.000000           0.000000            0.00000           0.000000   \n","2           0.000000           0.000000            0.00000           0.000000   \n","3         739.383196         740.476799          600.65502         695.104062   \n","4           0.000000           0.000000            0.00000           0.000000   \n","\n","   angle=37.5, t=119  \n","0           0.000000  \n","1           0.000000  \n","2           0.000000  \n","3         873.792882  \n","4           0.000000  \n","\n","[5 rows x 2401 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["scattering = pd.read_csv(\"/content/drive/MyDrive/ENG 4000/scattering.csv\")\n","scattering.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1675408994252,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"3CncIN8tqK2a","outputId":"f94fd43a-d6be-4d88-c9f1-02240c213609"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-a5fdc07b-23d8-41dc-b034-db0a468893c3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>size</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>12.513989</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>19.461646</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>25.726931</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>35.178985</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>4.672308</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5fdc07b-23d8-41dc-b034-db0a468893c3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a5fdc07b-23d8-41dc-b034-db0a468893c3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a5fdc07b-23d8-41dc-b034-db0a468893c3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   Unnamed: 0       size\n","0           0  12.513989\n","1           1  19.461646\n","2           2  25.726931\n","3           3  35.178985\n","4           4   4.672308"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["size = pd.read_csv(\"/content/drive/MyDrive/ENG 4000/size.csv\")\n","size.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1675408994253,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"lfS5AS_IqKx1","outputId":"ef511aec-0bec-4555-cdb3-62e9c9df0749"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-0a2e07e1-3707-4a5b-a931-960a1b4685bf\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>lt feature 1</th>\n","      <th>lt feature 2</th>\n","      <th>lt feature 3</th>\n","      <th>lt feature 4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.280202</td>\n","      <td>1.0</td>\n","      <td>0.134079</td>\n","      <td>-0.008439</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.481173</td>\n","      <td>1.0</td>\n","      <td>0.266975</td>\n","      <td>0.140432</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.519641</td>\n","      <td>1.0</td>\n","      <td>0.145762</td>\n","      <td>0.002905</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0.639556</td>\n","      <td>1.0</td>\n","      <td>0.305319</td>\n","      <td>-0.015814</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0.624575</td>\n","      <td>1.0</td>\n","      <td>0.396259</td>\n","      <td>-0.059949</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a2e07e1-3707-4a5b-a931-960a1b4685bf')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0a2e07e1-3707-4a5b-a931-960a1b4685bf button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0a2e07e1-3707-4a5b-a931-960a1b4685bf');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   Unnamed: 0  lt feature 1  lt feature 2  lt feature 3  lt feature 4\n","0           0      0.280202           1.0      0.134079     -0.008439\n","1           1      0.481173           1.0      0.266975      0.140432\n","2           2      0.519641           1.0      0.145762      0.002905\n","3           3      0.639556           1.0      0.305319     -0.015814\n","4           4      0.624575           1.0      0.396259     -0.059949"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["lifetime_features = pd.read_csv(\"/content/drive/MyDrive/ENG 4000/lifetime_features.csv\")\n","lifetime_features.head()"]},{"cell_type":"markdown","metadata":{"id":"cZ4lw5JeP9lX"},"source":["# Checking for duplicates and nulls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3449,"status":"ok","timestamp":1675408997693,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"uDQ5IZ4BLzFG","outputId":"7552736d-813a-46d8-c404-bc1a6e01bf1c"},"outputs":[{"name":"stdout","output_type":"stream","text":["lifetime\n","Nulls: 0\n","Duplicates: 0\n","\n","spectrum\n","Nulls: 0\n","Duplicates: 0\n","\n","scattering\n","Nulls: 0\n","Duplicates: 0\n","\n","size\n","Nulls: 0\n","Duplicates: 0\n","\n","lifetime_features\n","Nulls: 0\n","Duplicates: 0\n","\n"]}],"source":["data = {'lifetime':lifetime,\n","        'spectrum':spectrum,\n","        'scattering':scattering,\n","        'size':size,\n","        'lifetime_features':lifetime_features}\n","pd.set_option('display.max_rows',None)\n","for x in data:\n","  print(x)\n","  print(f'Nulls: {(data[x][data[x].isna().any(axis=1)].sum() > 0).sum()}')\n","  print(f'Duplicates: {data[x].duplicated().sum()}\\n')\n","\n","  #No null features so we will not need to adjust our dataset"]},{"cell_type":"markdown","metadata":{"id":"c5wYSNd6D5wT"},"source":["# Check labels for nulls and duplicates"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1675408997694,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"go0dzf-wD5a7","outputId":"11ecf978-76f0-43b8-e33e-da90563b57ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 9866 entries, 0 to 9865\n","Data columns (total 2 columns):\n"," #   Column     Non-Null Count  Dtype\n","---  ------     --------------  -----\n"," 0   Sample ID  9866 non-null   int64\n"," 1   Pollen     9866 non-null   int64\n","dtypes: int64(2)\n","memory usage: 154.3 KB\n"]}],"source":["labels.info() #Check the data types and how many nulls in the labels table"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1675408997695,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"3tTrXHZ_EqIy","outputId":"eb0fd529-5388-428c-fb8c-ba4146ed89a6"},"outputs":[{"data":{"text/plain":["array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["labels['Pollen'].unique() #There are 11 unique values for pollen, which correlates to 12 different types of pollen"]},{"cell_type":"markdown","metadata":{"id":"ajB7-DaEWXHy"},"source":["# Combine features into one dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"executionInfo":{"elapsed":999,"status":"ok","timestamp":1675408998686,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"mA3V0bXTT9GY","outputId":"76d11faa-f49b-470e-9ced-3a8582f347c1"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-f68d0b5e-1fb1-45aa-99ac-4b9d56468a3f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>350-400 nm, t=0</th>\n","      <th>350-400 nm, t=1</th>\n","      <th>350-400 nm, t=2</th>\n","      <th>350-400 nm, t=3</th>\n","      <th>350-400 nm, t=4</th>\n","      <th>350-400 nm, t=5</th>\n","      <th>350-400 nm, t=6</th>\n","      <th>350-400 nm, t=7</th>\n","      <th>350-400 nm, t=8</th>\n","      <th>350-400 nm, t=9</th>\n","      <th>...</th>\n","      <th>angle=37.5, t=115</th>\n","      <th>angle=37.5, t=116</th>\n","      <th>angle=37.5, t=117</th>\n","      <th>angle=37.5, t=118</th>\n","      <th>angle=37.5, t=119</th>\n","      <th>size</th>\n","      <th>lt feature 1</th>\n","      <th>lt feature 2</th>\n","      <th>lt feature 3</th>\n","      <th>lt feature 4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.010454</td>\n","      <td>0.000201</td>\n","      <td>0.010856</td>\n","      <td>0.114194</td>\n","      <td>0.217531</td>\n","      <td>0.166868</td>\n","      <td>0.116204</td>\n","      <td>0.109168</td>\n","      <td>0.102131</td>\n","      <td>0.054684</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>12.513989</td>\n","      <td>0.280202</td>\n","      <td>1.0</td>\n","      <td>0.134079</td>\n","      <td>-0.008439</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.119942</td>\n","      <td>0.184249</td>\n","      <td>0.248555</td>\n","      <td>0.236994</td>\n","      <td>0.225434</td>\n","      <td>0.098988</td>\n","      <td>-0.028179</td>\n","      <td>-0.054191</td>\n","      <td>-0.081647</td>\n","      <td>-0.058526</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>19.461646</td>\n","      <td>0.481173</td>\n","      <td>1.0</td>\n","      <td>0.266975</td>\n","      <td>0.140432</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.016149</td>\n","      <td>0.063383</td>\n","      <td>0.142915</td>\n","      <td>0.286637</td>\n","      <td>0.430359</td>\n","      <td>0.262414</td>\n","      <td>0.094469</td>\n","      <td>0.082761</td>\n","      <td>0.071054</td>\n","      <td>0.093258</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>25.726931</td>\n","      <td>0.519641</td>\n","      <td>1.0</td>\n","      <td>0.145762</td>\n","      <td>0.002905</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.067116</td>\n","      <td>0.198401</td>\n","      <td>0.329687</td>\n","      <td>0.366400</td>\n","      <td>0.403114</td>\n","      <td>0.235325</td>\n","      <td>0.067536</td>\n","      <td>0.063644</td>\n","      <td>0.059752</td>\n","      <td>0.032085</td>\n","      <td>...</td>\n","      <td>739.383196</td>\n","      <td>740.476799</td>\n","      <td>600.65502</td>\n","      <td>695.104062</td>\n","      <td>873.792882</td>\n","      <td>35.178985</td>\n","      <td>0.639556</td>\n","      <td>1.0</td>\n","      <td>0.305319</td>\n","      <td>-0.015814</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.043760</td>\n","      <td>0.090762</td>\n","      <td>0.225284</td>\n","      <td>0.214749</td>\n","      <td>0.204214</td>\n","      <td>0.213128</td>\n","      <td>0.222042</td>\n","      <td>0.133712</td>\n","      <td>0.044571</td>\n","      <td>-0.012966</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>4.672308</td>\n","      <td>0.624575</td>\n","      <td>1.0</td>\n","      <td>0.396259</td>\n","      <td>-0.059949</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 2629 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f68d0b5e-1fb1-45aa-99ac-4b9d56468a3f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f68d0b5e-1fb1-45aa-99ac-4b9d56468a3f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f68d0b5e-1fb1-45aa-99ac-4b9d56468a3f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   350-400 nm, t=0  350-400 nm, t=1  350-400 nm, t=2  350-400 nm, t=3  \\\n","0        -0.010454         0.000201         0.010856         0.114194   \n","1         0.119942         0.184249         0.248555         0.236994   \n","2        -0.016149         0.063383         0.142915         0.286637   \n","3         0.067116         0.198401         0.329687         0.366400   \n","4        -0.043760         0.090762         0.225284         0.214749   \n","\n","   350-400 nm, t=4  350-400 nm, t=5  350-400 nm, t=6  350-400 nm, t=7  \\\n","0         0.217531         0.166868         0.116204         0.109168   \n","1         0.225434         0.098988        -0.028179        -0.054191   \n","2         0.430359         0.262414         0.094469         0.082761   \n","3         0.403114         0.235325         0.067536         0.063644   \n","4         0.204214         0.213128         0.222042         0.133712   \n","\n","   350-400 nm, t=8  350-400 nm, t=9  ...  angle=37.5, t=115  \\\n","0         0.102131         0.054684  ...           0.000000   \n","1        -0.081647        -0.058526  ...           0.000000   \n","2         0.071054         0.093258  ...           0.000000   \n","3         0.059752         0.032085  ...         739.383196   \n","4         0.044571        -0.012966  ...           0.000000   \n","\n","   angle=37.5, t=116  angle=37.5, t=117  angle=37.5, t=118  angle=37.5, t=119  \\\n","0           0.000000            0.00000           0.000000           0.000000   \n","1           0.000000            0.00000           0.000000           0.000000   \n","2           0.000000            0.00000           0.000000           0.000000   \n","3         740.476799          600.65502         695.104062         873.792882   \n","4           0.000000            0.00000           0.000000           0.000000   \n","\n","        size  lt feature 1  lt feature 2  lt feature 3  lt feature 4  \n","0  12.513989      0.280202           1.0      0.134079     -0.008439  \n","1  19.461646      0.481173           1.0      0.266975      0.140432  \n","2  25.726931      0.519641           1.0      0.145762      0.002905  \n","3  35.178985      0.639556           1.0      0.305319     -0.015814  \n","4   4.672308      0.624575           1.0      0.396259     -0.059949  \n","\n","[5 rows x 2629 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["#Courtesy of Randy\n","features = pd.DataFrame()\n","\n","for x in data:\n","  features = pd.concat([features,data[x].iloc[: , 1:]], axis=1)\n","\n","features.head()\n","\n","#Thanks Randy!!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1675408998687,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"fJm2hlNEu9B_","outputId":"f2948568-f0e5-42db-db3f-727294edf1dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 9866 entries, 0 to 9865\n","Columns: 2629 entries, 350-400 nm, t=0 to lt feature 4\n","dtypes: float64(2629)\n","memory usage: 197.9 MB\n"]}],"source":["features.info() #Check for nulls, appears to be all floating point entries for data about the pollen"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":330},"executionInfo":{"elapsed":11908,"status":"ok","timestamp":1675409010586,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"w62YjHot_hyE","outputId":"0cb3152d-4d51-4e21-980a-8f90dde58729"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-5dbca8d7-162e-4419-8cf7-3334941a6398\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>350-400 nm, t=0</th>\n","      <th>350-400 nm, t=1</th>\n","      <th>350-400 nm, t=2</th>\n","      <th>350-400 nm, t=3</th>\n","      <th>350-400 nm, t=4</th>\n","      <th>350-400 nm, t=5</th>\n","      <th>350-400 nm, t=6</th>\n","      <th>350-400 nm, t=7</th>\n","      <th>350-400 nm, t=8</th>\n","      <th>350-400 nm, t=9</th>\n","      <th>...</th>\n","      <th>angle=37.5, t=115</th>\n","      <th>angle=37.5, t=116</th>\n","      <th>angle=37.5, t=117</th>\n","      <th>angle=37.5, t=118</th>\n","      <th>angle=37.5, t=119</th>\n","      <th>size</th>\n","      <th>lt feature 1</th>\n","      <th>lt feature 2</th>\n","      <th>lt feature 3</th>\n","      <th>lt feature 4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>9866.000000</td>\n","      <td>9866.000000</td>\n","      <td>9866.000000</td>\n","      <td>9866.000000</td>\n","      <td>9866.000000</td>\n","      <td>9866.000000</td>\n","      <td>9866.000000</td>\n","      <td>9866.000000</td>\n","      <td>9866.000000</td>\n","      <td>9866.000000</td>\n","      <td>...</td>\n","      <td>9866.000000</td>\n","      <td>9866.000000</td>\n","      <td>9866.000000</td>\n","      <td>9866.000000</td>\n","      <td>9866.000000</td>\n","      <td>9866.000000</td>\n","      <td>9866.000000</td>\n","      <td>9866.000000</td>\n","      <td>9866.000000</td>\n","      <td>9866.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.054501</td>\n","      <td>0.129879</td>\n","      <td>0.207672</td>\n","      <td>0.278997</td>\n","      <td>0.357199</td>\n","      <td>0.278295</td>\n","      <td>0.199518</td>\n","      <td>0.146643</td>\n","      <td>0.094979</td>\n","      <td>0.066842</td>\n","      <td>...</td>\n","      <td>14.088371</td>\n","      <td>12.621426</td>\n","      <td>11.445568</td>\n","      <td>10.200185</td>\n","      <td>10.393801</td>\n","      <td>26.204309</td>\n","      <td>0.729342</td>\n","      <td>0.919023</td>\n","      <td>0.402750</td>\n","      <td>0.005201</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.112790</td>\n","      <td>0.111535</td>\n","      <td>0.151223</td>\n","      <td>0.115425</td>\n","      <td>0.141304</td>\n","      <td>0.117297</td>\n","      <td>0.128957</td>\n","      <td>0.110486</td>\n","      <td>0.112885</td>\n","      <td>0.092936</td>\n","      <td>...</td>\n","      <td>167.409003</td>\n","      <td>158.018837</td>\n","      <td>149.590872</td>\n","      <td>140.410387</td>\n","      <td>144.395803</td>\n","      <td>10.220080</td>\n","      <td>0.253455</td>\n","      <td>0.172159</td>\n","      <td>0.270874</td>\n","      <td>0.169294</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>-0.325911</td>\n","      <td>-0.261134</td>\n","      <td>-0.290650</td>\n","      <td>-0.171657</td>\n","      <td>-0.246316</td>\n","      <td>-0.161798</td>\n","      <td>-0.309446</td>\n","      <td>-0.424242</td>\n","      <td>-0.567100</td>\n","      <td>-0.450216</td>\n","      <td>...</td>\n","      <td>-173.999937</td>\n","      <td>-193.665145</td>\n","      <td>-219.937796</td>\n","      <td>-186.138296</td>\n","      <td>-221.157807</td>\n","      <td>3.582779</td>\n","      <td>-4.160000</td>\n","      <td>-2.641791</td>\n","      <td>-6.440000</td>\n","      <td>-6.840000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.000000</td>\n","      <td>0.056260</td>\n","      <td>0.088899</td>\n","      <td>0.208653</td>\n","      <td>0.271081</td>\n","      <td>0.199449</td>\n","      <td>0.110214</td>\n","      <td>0.071947</td>\n","      <td>0.028002</td>\n","      <td>0.013775</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>18.772832</td>\n","      <td>0.546894</td>\n","      <td>0.926986</td>\n","      <td>0.229302</td>\n","      <td>-0.015708</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.020483</td>\n","      <td>0.113195</td>\n","      <td>0.188349</td>\n","      <td>0.277258</td>\n","      <td>0.361482</td>\n","      <td>0.275712</td>\n","      <td>0.182363</td>\n","      <td>0.129294</td>\n","      <td>0.075682</td>\n","      <td>0.053462</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>26.966954</td>\n","      <td>0.761776</td>\n","      <td>1.000000</td>\n","      <td>0.360906</td>\n","      <td>0.002202</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.067851</td>\n","      <td>0.182943</td>\n","      <td>0.308304</td>\n","      <td>0.350088</td>\n","      <td>0.435018</td>\n","      <td>0.349174</td>\n","      <td>0.275445</td>\n","      <td>0.204631</td>\n","      <td>0.140749</td>\n","      <td>0.102684</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>33.312604</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.545189</td>\n","      <td>0.023612</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.979619</td>\n","      <td>0.765217</td>\n","      <td>1.009491</td>\n","      <td>0.874499</td>\n","      <td>1.249406</td>\n","      <td>0.945368</td>\n","      <td>0.851730</td>\n","      <td>0.875536</td>\n","      <td>1.206009</td>\n","      <td>1.042918</td>\n","      <td>...</td>\n","      <td>5116.110912</td>\n","      <td>4788.091254</td>\n","      <td>4838.284826</td>\n","      <td>5009.191806</td>\n","      <td>5084.968633</td>\n","      <td>82.466110</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 2629 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dbca8d7-162e-4419-8cf7-3334941a6398')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5dbca8d7-162e-4419-8cf7-3334941a6398 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5dbca8d7-162e-4419-8cf7-3334941a6398');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["       350-400 nm, t=0  350-400 nm, t=1  350-400 nm, t=2  350-400 nm, t=3  \\\n","count      9866.000000      9866.000000      9866.000000      9866.000000   \n","mean          0.054501         0.129879         0.207672         0.278997   \n","std           0.112790         0.111535         0.151223         0.115425   \n","min          -0.325911        -0.261134        -0.290650        -0.171657   \n","25%           0.000000         0.056260         0.088899         0.208653   \n","50%           0.020483         0.113195         0.188349         0.277258   \n","75%           0.067851         0.182943         0.308304         0.350088   \n","max           0.979619         0.765217         1.009491         0.874499   \n","\n","       350-400 nm, t=4  350-400 nm, t=5  350-400 nm, t=6  350-400 nm, t=7  \\\n","count      9866.000000      9866.000000      9866.000000      9866.000000   \n","mean          0.357199         0.278295         0.199518         0.146643   \n","std           0.141304         0.117297         0.128957         0.110486   \n","min          -0.246316        -0.161798        -0.309446        -0.424242   \n","25%           0.271081         0.199449         0.110214         0.071947   \n","50%           0.361482         0.275712         0.182363         0.129294   \n","75%           0.435018         0.349174         0.275445         0.204631   \n","max           1.249406         0.945368         0.851730         0.875536   \n","\n","       350-400 nm, t=8  350-400 nm, t=9  ...  angle=37.5, t=115  \\\n","count      9866.000000      9866.000000  ...        9866.000000   \n","mean          0.094979         0.066842  ...          14.088371   \n","std           0.112885         0.092936  ...         167.409003   \n","min          -0.567100        -0.450216  ...        -173.999937   \n","25%           0.028002         0.013775  ...           0.000000   \n","50%           0.075682         0.053462  ...           0.000000   \n","75%           0.140749         0.102684  ...           0.000000   \n","max           1.206009         1.042918  ...        5116.110912   \n","\n","       angle=37.5, t=116  angle=37.5, t=117  angle=37.5, t=118  \\\n","count        9866.000000        9866.000000        9866.000000   \n","mean           12.621426          11.445568          10.200185   \n","std           158.018837         149.590872         140.410387   \n","min          -193.665145        -219.937796        -186.138296   \n","25%             0.000000           0.000000           0.000000   \n","50%             0.000000           0.000000           0.000000   \n","75%             0.000000           0.000000           0.000000   \n","max          4788.091254        4838.284826        5009.191806   \n","\n","       angle=37.5, t=119         size  lt feature 1  lt feature 2  \\\n","count        9866.000000  9866.000000   9866.000000   9866.000000   \n","mean           10.393801    26.204309      0.729342      0.919023   \n","std           144.395803    10.220080      0.253455      0.172159   \n","min          -221.157807     3.582779     -4.160000     -2.641791   \n","25%             0.000000    18.772832      0.546894      0.926986   \n","50%             0.000000    26.966954      0.761776      1.000000   \n","75%             0.000000    33.312604      1.000000      1.000000   \n","max          5084.968633    82.466110      1.000000      1.000000   \n","\n","       lt feature 3  lt feature 4  \n","count   9866.000000   9866.000000  \n","mean       0.402750      0.005201  \n","std        0.270874      0.169294  \n","min       -6.440000     -6.840000  \n","25%        0.229302     -0.015708  \n","50%        0.360906      0.002202  \n","75%        0.545189      0.023612  \n","max        1.000000      1.000000  \n","\n","[8 rows x 2629 columns]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["features.describe() #We can further verify in describe()"]},{"cell_type":"markdown","metadata":{"id":"T_ahBhwUAkpp"},"source":["# Combine Features and Labels into 'results' table"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":863},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1675409010586,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"JqDSdu5AAgOh","outputId":"e38cf7cc-7a5d-4dd3-94be-bdab2badf633"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-7d2db568-a5aa-4b9f-ada0-a3b2f4225587\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sample ID</th>\n","      <th>Pollen</th>\n","      <th>350-400 nm, t=0</th>\n","      <th>350-400 nm, t=1</th>\n","      <th>350-400 nm, t=2</th>\n","      <th>350-400 nm, t=3</th>\n","      <th>350-400 nm, t=4</th>\n","      <th>350-400 nm, t=5</th>\n","      <th>350-400 nm, t=6</th>\n","      <th>350-400 nm, t=7</th>\n","      <th>...</th>\n","      <th>angle=37.5, t=115</th>\n","      <th>angle=37.5, t=116</th>\n","      <th>angle=37.5, t=117</th>\n","      <th>angle=37.5, t=118</th>\n","      <th>angle=37.5, t=119</th>\n","      <th>size</th>\n","      <th>lt feature 1</th>\n","      <th>lt feature 2</th>\n","      <th>lt feature 3</th>\n","      <th>lt feature 4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-0.010454</td>\n","      <td>0.000201</td>\n","      <td>0.010856</td>\n","      <td>0.114194</td>\n","      <td>0.217531</td>\n","      <td>0.166868</td>\n","      <td>0.116204</td>\n","      <td>0.109168</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>12.513989</td>\n","      <td>0.280202</td>\n","      <td>1.000000</td>\n","      <td>0.134079</td>\n","      <td>-0.008439</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.119942</td>\n","      <td>0.184249</td>\n","      <td>0.248555</td>\n","      <td>0.236994</td>\n","      <td>0.225434</td>\n","      <td>0.098988</td>\n","      <td>-0.028179</td>\n","      <td>-0.054191</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>19.461646</td>\n","      <td>0.481173</td>\n","      <td>1.000000</td>\n","      <td>0.266975</td>\n","      <td>0.140432</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>-0.016149</td>\n","      <td>0.063383</td>\n","      <td>0.142915</td>\n","      <td>0.286637</td>\n","      <td>0.430359</td>\n","      <td>0.262414</td>\n","      <td>0.094469</td>\n","      <td>0.082761</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>25.726931</td>\n","      <td>0.519641</td>\n","      <td>1.000000</td>\n","      <td>0.145762</td>\n","      <td>0.002905</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0.067116</td>\n","      <td>0.198401</td>\n","      <td>0.329687</td>\n","      <td>0.366400</td>\n","      <td>0.403114</td>\n","      <td>0.235325</td>\n","      <td>0.067536</td>\n","      <td>0.063644</td>\n","      <td>...</td>\n","      <td>739.383196</td>\n","      <td>740.476799</td>\n","      <td>600.65502</td>\n","      <td>695.104062</td>\n","      <td>873.792882</td>\n","      <td>35.178985</td>\n","      <td>0.639556</td>\n","      <td>1.000000</td>\n","      <td>0.305319</td>\n","      <td>-0.015814</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>-0.043760</td>\n","      <td>0.090762</td>\n","      <td>0.225284</td>\n","      <td>0.214749</td>\n","      <td>0.204214</td>\n","      <td>0.213128</td>\n","      <td>0.222042</td>\n","      <td>0.133712</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>4.672308</td>\n","      <td>0.624575</td>\n","      <td>1.000000</td>\n","      <td>0.396259</td>\n","      <td>-0.059949</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0.004977</td>\n","      <td>0.024748</td>\n","      <td>0.044518</td>\n","      <td>0.202820</td>\n","      <td>0.361123</td>\n","      <td>0.254390</td>\n","      <td>0.147657</td>\n","      <td>0.106180</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>32.669015</td>\n","      <td>0.508910</td>\n","      <td>1.000000</td>\n","      <td>0.384810</td>\n","      <td>0.028841</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>-0.004771</td>\n","      <td>0.002135</td>\n","      <td>0.009041</td>\n","      <td>0.184957</td>\n","      <td>0.360874</td>\n","      <td>0.289427</td>\n","      <td>0.217981</td>\n","      <td>0.142516</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>16.917568</td>\n","      <td>0.528344</td>\n","      <td>1.000000</td>\n","      <td>0.325935</td>\n","      <td>-0.021346</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>-0.034386</td>\n","      <td>-0.019729</td>\n","      <td>-0.005637</td>\n","      <td>0.249154</td>\n","      <td>0.503946</td>\n","      <td>0.315671</td>\n","      <td>0.127396</td>\n","      <td>0.106539</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>5.183246</td>\n","      <td>0.542076</td>\n","      <td>1.000000</td>\n","      <td>0.058968</td>\n","      <td>-0.143428</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>0.051364</td>\n","      <td>0.197967</td>\n","      <td>0.344569</td>\n","      <td>0.212413</td>\n","      <td>0.080257</td>\n","      <td>0.124131</td>\n","      <td>0.168004</td>\n","      <td>0.113965</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>10.300820</td>\n","      <td>0.487222</td>\n","      <td>1.000000</td>\n","      <td>0.185278</td>\n","      <td>0.069306</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0.032342</td>\n","      <td>0.212160</td>\n","      <td>0.391979</td>\n","      <td>0.239327</td>\n","      <td>0.086675</td>\n","      <td>0.124838</td>\n","      <td>0.163001</td>\n","      <td>0.172057</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>10.891347</td>\n","      <td>0.349795</td>\n","      <td>1.000000</td>\n","      <td>0.157729</td>\n","      <td>-0.011491</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>0.041036</td>\n","      <td>0.093508</td>\n","      <td>0.145980</td>\n","      <td>0.202825</td>\n","      <td>0.259670</td>\n","      <td>0.133199</td>\n","      <td>0.006727</td>\n","      <td>0.003700</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>13.280824</td>\n","      <td>0.319376</td>\n","      <td>1.000000</td>\n","      <td>0.244995</td>\n","      <td>0.040220</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>0.003179</td>\n","      <td>0.003709</td>\n","      <td>0.004238</td>\n","      <td>0.141192</td>\n","      <td>0.278146</td>\n","      <td>0.179338</td>\n","      <td>0.080530</td>\n","      <td>0.053510</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>16.409027</td>\n","      <td>0.332133</td>\n","      <td>1.000000</td>\n","      <td>0.381038</td>\n","      <td>0.032803</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>0.028302</td>\n","      <td>0.102404</td>\n","      <td>0.176506</td>\n","      <td>0.178180</td>\n","      <td>0.179854</td>\n","      <td>0.123554</td>\n","      <td>0.067255</td>\n","      <td>0.030280</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>34.757318</td>\n","      <td>0.252751</td>\n","      <td>1.000000</td>\n","      <td>0.260605</td>\n","      <td>0.000475</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>0.048544</td>\n","      <td>0.064725</td>\n","      <td>0.080906</td>\n","      <td>0.197411</td>\n","      <td>0.313916</td>\n","      <td>0.319310</td>\n","      <td>0.324703</td>\n","      <td>0.151564</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>23.499978</td>\n","      <td>0.562924</td>\n","      <td>1.000000</td>\n","      <td>0.369398</td>\n","      <td>0.039384</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>-0.111416</td>\n","      <td>0.037443</td>\n","      <td>0.186301</td>\n","      <td>0.398174</td>\n","      <td>0.610046</td>\n","      <td>0.416438</td>\n","      <td>0.222831</td>\n","      <td>0.212785</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>13.441137</td>\n","      <td>0.735643</td>\n","      <td>1.000000</td>\n","      <td>0.023720</td>\n","      <td>-0.035268</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>0.037859</td>\n","      <td>0.084886</td>\n","      <td>0.131914</td>\n","      <td>0.239130</td>\n","      <td>0.346347</td>\n","      <td>0.251405</td>\n","      <td>0.156463</td>\n","      <td>0.091393</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>23.008255</td>\n","      <td>0.620442</td>\n","      <td>1.000000</td>\n","      <td>0.192139</td>\n","      <td>0.014740</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>-0.008780</td>\n","      <td>0.123373</td>\n","      <td>0.255525</td>\n","      <td>0.271874</td>\n","      <td>0.288223</td>\n","      <td>0.189525</td>\n","      <td>0.090827</td>\n","      <td>0.055404</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>19.037387</td>\n","      <td>0.378269</td>\n","      <td>1.000000</td>\n","      <td>0.249493</td>\n","      <td>-0.021156</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>0.102941</td>\n","      <td>0.107026</td>\n","      <td>0.111111</td>\n","      <td>0.330882</td>\n","      <td>0.550654</td>\n","      <td>0.347222</td>\n","      <td>0.143791</td>\n","      <td>0.030229</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>6.463340</td>\n","      <td>0.673014</td>\n","      <td>1.000000</td>\n","      <td>0.217869</td>\n","      <td>0.115342</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>-0.001626</td>\n","      <td>0.020325</td>\n","      <td>0.042276</td>\n","      <td>0.176016</td>\n","      <td>0.309756</td>\n","      <td>0.255285</td>\n","      <td>0.200813</td>\n","      <td>0.106098</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>8.009680</td>\n","      <td>0.640159</td>\n","      <td>1.000000</td>\n","      <td>0.522061</td>\n","      <td>-0.032497</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>19</td>\n","      <td>0</td>\n","      <td>-0.045455</td>\n","      <td>0.062500</td>\n","      <td>0.170455</td>\n","      <td>0.217330</td>\n","      <td>0.264205</td>\n","      <td>0.198864</td>\n","      <td>0.133523</td>\n","      <td>0.061080</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>9.573579</td>\n","      <td>0.490219</td>\n","      <td>1.000000</td>\n","      <td>0.063291</td>\n","      <td>0.216341</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>0.015745</td>\n","      <td>0.168738</td>\n","      <td>0.321730</td>\n","      <td>0.354927</td>\n","      <td>0.388125</td>\n","      <td>0.388125</td>\n","      <td>0.388125</td>\n","      <td>0.283885</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>44.312520</td>\n","      <td>0.880653</td>\n","      <td>1.000000</td>\n","      <td>0.371460</td>\n","      <td>0.001787</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>21</td>\n","      <td>0</td>\n","      <td>0.043549</td>\n","      <td>0.043549</td>\n","      <td>0.043549</td>\n","      <td>0.043549</td>\n","      <td>0.268042</td>\n","      <td>0.147380</td>\n","      <td>0.095655</td>\n","      <td>0.043929</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>36.279895</td>\n","      <td>0.239246</td>\n","      <td>0.956772</td>\n","      <td>1.000000</td>\n","      <td>0.017297</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>22</td>\n","      <td>0</td>\n","      <td>0.004676</td>\n","      <td>0.111141</td>\n","      <td>0.217606</td>\n","      <td>0.292779</td>\n","      <td>0.367953</td>\n","      <td>0.333064</td>\n","      <td>0.298175</td>\n","      <td>0.201061</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>42.207121</td>\n","      <td>0.650017</td>\n","      <td>1.000000</td>\n","      <td>0.387423</td>\n","      <td>0.003739</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>23</td>\n","      <td>0</td>\n","      <td>-0.088571</td>\n","      <td>0.005714</td>\n","      <td>0.100000</td>\n","      <td>0.177143</td>\n","      <td>0.254286</td>\n","      <td>0.208571</td>\n","      <td>0.162857</td>\n","      <td>0.074286</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>5.570237</td>\n","      <td>0.695596</td>\n","      <td>1.000000</td>\n","      <td>0.009067</td>\n","      <td>0.006477</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>24</td>\n","      <td>0</td>\n","      <td>0.124931</td>\n","      <td>0.215516</td>\n","      <td>0.306102</td>\n","      <td>0.322441</td>\n","      <td>0.338780</td>\n","      <td>0.209403</td>\n","      <td>0.080027</td>\n","      <td>0.056352</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>32.478891</td>\n","      <td>0.499374</td>\n","      <td>1.000000</td>\n","      <td>0.547399</td>\n","      <td>-0.003362</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>25 rows × 2631 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d2db568-a5aa-4b9f-ada0-a3b2f4225587')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7d2db568-a5aa-4b9f-ada0-a3b2f4225587 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7d2db568-a5aa-4b9f-ada0-a3b2f4225587');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    Sample ID  Pollen  350-400 nm, t=0  350-400 nm, t=1  350-400 nm, t=2  \\\n","0           0       0        -0.010454         0.000201         0.010856   \n","1           1       0         0.119942         0.184249         0.248555   \n","2           2       0        -0.016149         0.063383         0.142915   \n","3           3       0         0.067116         0.198401         0.329687   \n","4           4       0        -0.043760         0.090762         0.225284   \n","5           5       0         0.004977         0.024748         0.044518   \n","6           6       0        -0.004771         0.002135         0.009041   \n","7           7       0        -0.034386        -0.019729        -0.005637   \n","8           8       0         0.051364         0.197967         0.344569   \n","9           9       0         0.032342         0.212160         0.391979   \n","10         10       0         0.041036         0.093508         0.145980   \n","11         11       0         0.003179         0.003709         0.004238   \n","12         12       0         0.028302         0.102404         0.176506   \n","13         13       0         0.048544         0.064725         0.080906   \n","14         14       0        -0.111416         0.037443         0.186301   \n","15         15       0         0.037859         0.084886         0.131914   \n","16         16       0        -0.008780         0.123373         0.255525   \n","17         17       0         0.102941         0.107026         0.111111   \n","18         18       0        -0.001626         0.020325         0.042276   \n","19         19       0        -0.045455         0.062500         0.170455   \n","20         20       0         0.015745         0.168738         0.321730   \n","21         21       0         0.043549         0.043549         0.043549   \n","22         22       0         0.004676         0.111141         0.217606   \n","23         23       0        -0.088571         0.005714         0.100000   \n","24         24       0         0.124931         0.215516         0.306102   \n","\n","    350-400 nm, t=3  350-400 nm, t=4  350-400 nm, t=5  350-400 nm, t=6  \\\n","0          0.114194         0.217531         0.166868         0.116204   \n","1          0.236994         0.225434         0.098988        -0.028179   \n","2          0.286637         0.430359         0.262414         0.094469   \n","3          0.366400         0.403114         0.235325         0.067536   \n","4          0.214749         0.204214         0.213128         0.222042   \n","5          0.202820         0.361123         0.254390         0.147657   \n","6          0.184957         0.360874         0.289427         0.217981   \n","7          0.249154         0.503946         0.315671         0.127396   \n","8          0.212413         0.080257         0.124131         0.168004   \n","9          0.239327         0.086675         0.124838         0.163001   \n","10         0.202825         0.259670         0.133199         0.006727   \n","11         0.141192         0.278146         0.179338         0.080530   \n","12         0.178180         0.179854         0.123554         0.067255   \n","13         0.197411         0.313916         0.319310         0.324703   \n","14         0.398174         0.610046         0.416438         0.222831   \n","15         0.239130         0.346347         0.251405         0.156463   \n","16         0.271874         0.288223         0.189525         0.090827   \n","17         0.330882         0.550654         0.347222         0.143791   \n","18         0.176016         0.309756         0.255285         0.200813   \n","19         0.217330         0.264205         0.198864         0.133523   \n","20         0.354927         0.388125         0.388125         0.388125   \n","21         0.043549         0.268042         0.147380         0.095655   \n","22         0.292779         0.367953         0.333064         0.298175   \n","23         0.177143         0.254286         0.208571         0.162857   \n","24         0.322441         0.338780         0.209403         0.080027   \n","\n","    350-400 nm, t=7  ...  angle=37.5, t=115  angle=37.5, t=116  \\\n","0          0.109168  ...           0.000000           0.000000   \n","1         -0.054191  ...           0.000000           0.000000   \n","2          0.082761  ...           0.000000           0.000000   \n","3          0.063644  ...         739.383196         740.476799   \n","4          0.133712  ...           0.000000           0.000000   \n","5          0.106180  ...           0.000000           0.000000   \n","6          0.142516  ...           0.000000           0.000000   \n","7          0.106539  ...           0.000000           0.000000   \n","8          0.113965  ...           0.000000           0.000000   \n","9          0.172057  ...           0.000000           0.000000   \n","10         0.003700  ...           0.000000           0.000000   \n","11         0.053510  ...           0.000000           0.000000   \n","12         0.030280  ...           0.000000           0.000000   \n","13         0.151564  ...           0.000000           0.000000   \n","14         0.212785  ...           0.000000           0.000000   \n","15         0.091393  ...           0.000000           0.000000   \n","16         0.055404  ...           0.000000           0.000000   \n","17         0.030229  ...           0.000000           0.000000   \n","18         0.106098  ...           0.000000           0.000000   \n","19         0.061080  ...           0.000000           0.000000   \n","20         0.283885  ...           0.000000           0.000000   \n","21         0.043929  ...           0.000000           0.000000   \n","22         0.201061  ...           0.000000           0.000000   \n","23         0.074286  ...           0.000000           0.000000   \n","24         0.056352  ...           0.000000           0.000000   \n","\n","    angle=37.5, t=117  angle=37.5, t=118  angle=37.5, t=119       size  \\\n","0             0.00000           0.000000           0.000000  12.513989   \n","1             0.00000           0.000000           0.000000  19.461646   \n","2             0.00000           0.000000           0.000000  25.726931   \n","3           600.65502         695.104062         873.792882  35.178985   \n","4             0.00000           0.000000           0.000000   4.672308   \n","5             0.00000           0.000000           0.000000  32.669015   \n","6             0.00000           0.000000           0.000000  16.917568   \n","7             0.00000           0.000000           0.000000   5.183246   \n","8             0.00000           0.000000           0.000000  10.300820   \n","9             0.00000           0.000000           0.000000  10.891347   \n","10            0.00000           0.000000           0.000000  13.280824   \n","11            0.00000           0.000000           0.000000  16.409027   \n","12            0.00000           0.000000           0.000000  34.757318   \n","13            0.00000           0.000000           0.000000  23.499978   \n","14            0.00000           0.000000           0.000000  13.441137   \n","15            0.00000           0.000000           0.000000  23.008255   \n","16            0.00000           0.000000           0.000000  19.037387   \n","17            0.00000           0.000000           0.000000   6.463340   \n","18            0.00000           0.000000           0.000000   8.009680   \n","19            0.00000           0.000000           0.000000   9.573579   \n","20            0.00000           0.000000           0.000000  44.312520   \n","21            0.00000           0.000000           0.000000  36.279895   \n","22            0.00000           0.000000           0.000000  42.207121   \n","23            0.00000           0.000000           0.000000   5.570237   \n","24            0.00000           0.000000           0.000000  32.478891   \n","\n","    lt feature 1  lt feature 2  lt feature 3  lt feature 4  \n","0       0.280202      1.000000      0.134079     -0.008439  \n","1       0.481173      1.000000      0.266975      0.140432  \n","2       0.519641      1.000000      0.145762      0.002905  \n","3       0.639556      1.000000      0.305319     -0.015814  \n","4       0.624575      1.000000      0.396259     -0.059949  \n","5       0.508910      1.000000      0.384810      0.028841  \n","6       0.528344      1.000000      0.325935     -0.021346  \n","7       0.542076      1.000000      0.058968     -0.143428  \n","8       0.487222      1.000000      0.185278      0.069306  \n","9       0.349795      1.000000      0.157729     -0.011491  \n","10      0.319376      1.000000      0.244995      0.040220  \n","11      0.332133      1.000000      0.381038      0.032803  \n","12      0.252751      1.000000      0.260605      0.000475  \n","13      0.562924      1.000000      0.369398      0.039384  \n","14      0.735643      1.000000      0.023720     -0.035268  \n","15      0.620442      1.000000      0.192139      0.014740  \n","16      0.378269      1.000000      0.249493     -0.021156  \n","17      0.673014      1.000000      0.217869      0.115342  \n","18      0.640159      1.000000      0.522061     -0.032497  \n","19      0.490219      1.000000      0.063291      0.216341  \n","20      0.880653      1.000000      0.371460      0.001787  \n","21      0.239246      0.956772      1.000000      0.017297  \n","22      0.650017      1.000000      0.387423      0.003739  \n","23      0.695596      1.000000      0.009067      0.006477  \n","24      0.499374      1.000000      0.547399     -0.003362  \n","\n","[25 rows x 2631 columns]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["results = pd.concat([labels, features],axis=1)\n","results.head(25)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":863},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1675409010588,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"CaxDvZcTwrPf","outputId":"b9e1c4c2-af7e-415d-f9f9-295eaafab0b2"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-15b4364c-cbf9-46f7-9d19-fb072179b8bd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pollen</th>\n","      <th>350-400 nm, t=0</th>\n","      <th>350-400 nm, t=1</th>\n","      <th>350-400 nm, t=2</th>\n","      <th>350-400 nm, t=3</th>\n","      <th>350-400 nm, t=4</th>\n","      <th>350-400 nm, t=5</th>\n","      <th>350-400 nm, t=6</th>\n","      <th>350-400 nm, t=7</th>\n","      <th>350-400 nm, t=8</th>\n","      <th>...</th>\n","      <th>angle=37.5, t=115</th>\n","      <th>angle=37.5, t=116</th>\n","      <th>angle=37.5, t=117</th>\n","      <th>angle=37.5, t=118</th>\n","      <th>angle=37.5, t=119</th>\n","      <th>size</th>\n","      <th>lt feature 1</th>\n","      <th>lt feature 2</th>\n","      <th>lt feature 3</th>\n","      <th>lt feature 4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>-0.010454</td>\n","      <td>0.000201</td>\n","      <td>0.010856</td>\n","      <td>0.114194</td>\n","      <td>0.217531</td>\n","      <td>0.166868</td>\n","      <td>0.116204</td>\n","      <td>0.109168</td>\n","      <td>0.102131</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>12.513989</td>\n","      <td>0.280202</td>\n","      <td>1.000000</td>\n","      <td>0.134079</td>\n","      <td>-0.008439</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0.119942</td>\n","      <td>0.184249</td>\n","      <td>0.248555</td>\n","      <td>0.236994</td>\n","      <td>0.225434</td>\n","      <td>0.098988</td>\n","      <td>-0.028179</td>\n","      <td>-0.054191</td>\n","      <td>-0.081647</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>19.461646</td>\n","      <td>0.481173</td>\n","      <td>1.000000</td>\n","      <td>0.266975</td>\n","      <td>0.140432</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>-0.016149</td>\n","      <td>0.063383</td>\n","      <td>0.142915</td>\n","      <td>0.286637</td>\n","      <td>0.430359</td>\n","      <td>0.262414</td>\n","      <td>0.094469</td>\n","      <td>0.082761</td>\n","      <td>0.071054</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>25.726931</td>\n","      <td>0.519641</td>\n","      <td>1.000000</td>\n","      <td>0.145762</td>\n","      <td>0.002905</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.067116</td>\n","      <td>0.198401</td>\n","      <td>0.329687</td>\n","      <td>0.366400</td>\n","      <td>0.403114</td>\n","      <td>0.235325</td>\n","      <td>0.067536</td>\n","      <td>0.063644</td>\n","      <td>0.059752</td>\n","      <td>...</td>\n","      <td>739.383196</td>\n","      <td>740.476799</td>\n","      <td>600.65502</td>\n","      <td>695.104062</td>\n","      <td>873.792882</td>\n","      <td>35.178985</td>\n","      <td>0.639556</td>\n","      <td>1.000000</td>\n","      <td>0.305319</td>\n","      <td>-0.015814</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>-0.043760</td>\n","      <td>0.090762</td>\n","      <td>0.225284</td>\n","      <td>0.214749</td>\n","      <td>0.204214</td>\n","      <td>0.213128</td>\n","      <td>0.222042</td>\n","      <td>0.133712</td>\n","      <td>0.044571</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>4.672308</td>\n","      <td>0.624575</td>\n","      <td>1.000000</td>\n","      <td>0.396259</td>\n","      <td>-0.059949</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0.004977</td>\n","      <td>0.024748</td>\n","      <td>0.044518</td>\n","      <td>0.202820</td>\n","      <td>0.361123</td>\n","      <td>0.254390</td>\n","      <td>0.147657</td>\n","      <td>0.106180</td>\n","      <td>0.064703</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>32.669015</td>\n","      <td>0.508910</td>\n","      <td>1.000000</td>\n","      <td>0.384810</td>\n","      <td>0.028841</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>-0.004771</td>\n","      <td>0.002135</td>\n","      <td>0.009041</td>\n","      <td>0.184957</td>\n","      <td>0.360874</td>\n","      <td>0.289427</td>\n","      <td>0.217981</td>\n","      <td>0.142516</td>\n","      <td>0.067052</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>16.917568</td>\n","      <td>0.528344</td>\n","      <td>1.000000</td>\n","      <td>0.325935</td>\n","      <td>-0.021346</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>-0.034386</td>\n","      <td>-0.019729</td>\n","      <td>-0.005637</td>\n","      <td>0.249154</td>\n","      <td>0.503946</td>\n","      <td>0.315671</td>\n","      <td>0.127396</td>\n","      <td>0.106539</td>\n","      <td>0.085682</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>5.183246</td>\n","      <td>0.542076</td>\n","      <td>1.000000</td>\n","      <td>0.058968</td>\n","      <td>-0.143428</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>0.051364</td>\n","      <td>0.197967</td>\n","      <td>0.344569</td>\n","      <td>0.212413</td>\n","      <td>0.080257</td>\n","      <td>0.124131</td>\n","      <td>0.168004</td>\n","      <td>0.113965</td>\n","      <td>0.059925</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>10.300820</td>\n","      <td>0.487222</td>\n","      <td>1.000000</td>\n","      <td>0.185278</td>\n","      <td>0.069306</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.032342</td>\n","      <td>0.212160</td>\n","      <td>0.391979</td>\n","      <td>0.239327</td>\n","      <td>0.086675</td>\n","      <td>0.124838</td>\n","      <td>0.163001</td>\n","      <td>0.172057</td>\n","      <td>0.181113</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>10.891347</td>\n","      <td>0.349795</td>\n","      <td>1.000000</td>\n","      <td>0.157729</td>\n","      <td>-0.011491</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0</td>\n","      <td>0.041036</td>\n","      <td>0.093508</td>\n","      <td>0.145980</td>\n","      <td>0.202825</td>\n","      <td>0.259670</td>\n","      <td>0.133199</td>\n","      <td>0.006727</td>\n","      <td>0.003700</td>\n","      <td>0.000673</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>13.280824</td>\n","      <td>0.319376</td>\n","      <td>1.000000</td>\n","      <td>0.244995</td>\n","      <td>0.040220</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0</td>\n","      <td>0.003179</td>\n","      <td>0.003709</td>\n","      <td>0.004238</td>\n","      <td>0.141192</td>\n","      <td>0.278146</td>\n","      <td>0.179338</td>\n","      <td>0.080530</td>\n","      <td>0.053510</td>\n","      <td>0.026490</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>16.409027</td>\n","      <td>0.332133</td>\n","      <td>1.000000</td>\n","      <td>0.381038</td>\n","      <td>0.032803</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.028302</td>\n","      <td>0.102404</td>\n","      <td>0.176506</td>\n","      <td>0.178180</td>\n","      <td>0.179854</td>\n","      <td>0.123554</td>\n","      <td>0.067255</td>\n","      <td>0.030280</td>\n","      <td>-0.006847</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>34.757318</td>\n","      <td>0.252751</td>\n","      <td>1.000000</td>\n","      <td>0.260605</td>\n","      <td>0.000475</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0</td>\n","      <td>0.048544</td>\n","      <td>0.064725</td>\n","      <td>0.080906</td>\n","      <td>0.197411</td>\n","      <td>0.313916</td>\n","      <td>0.319310</td>\n","      <td>0.324703</td>\n","      <td>0.151564</td>\n","      <td>-0.022114</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>23.499978</td>\n","      <td>0.562924</td>\n","      <td>1.000000</td>\n","      <td>0.369398</td>\n","      <td>0.039384</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0</td>\n","      <td>-0.111416</td>\n","      <td>0.037443</td>\n","      <td>0.186301</td>\n","      <td>0.398174</td>\n","      <td>0.610046</td>\n","      <td>0.416438</td>\n","      <td>0.222831</td>\n","      <td>0.212785</td>\n","      <td>0.202740</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>13.441137</td>\n","      <td>0.735643</td>\n","      <td>1.000000</td>\n","      <td>0.023720</td>\n","      <td>-0.035268</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0</td>\n","      <td>0.037859</td>\n","      <td>0.084886</td>\n","      <td>0.131914</td>\n","      <td>0.239130</td>\n","      <td>0.346347</td>\n","      <td>0.251405</td>\n","      <td>0.156463</td>\n","      <td>0.091393</td>\n","      <td>0.026324</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>23.008255</td>\n","      <td>0.620442</td>\n","      <td>1.000000</td>\n","      <td>0.192139</td>\n","      <td>0.014740</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0</td>\n","      <td>-0.008780</td>\n","      <td>0.123373</td>\n","      <td>0.255525</td>\n","      <td>0.271874</td>\n","      <td>0.288223</td>\n","      <td>0.189525</td>\n","      <td>0.090827</td>\n","      <td>0.055404</td>\n","      <td>0.019982</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>19.037387</td>\n","      <td>0.378269</td>\n","      <td>1.000000</td>\n","      <td>0.249493</td>\n","      <td>-0.021156</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0</td>\n","      <td>0.102941</td>\n","      <td>0.107026</td>\n","      <td>0.111111</td>\n","      <td>0.330882</td>\n","      <td>0.550654</td>\n","      <td>0.347222</td>\n","      <td>0.143791</td>\n","      <td>0.030229</td>\n","      <td>-0.084150</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>6.463340</td>\n","      <td>0.673014</td>\n","      <td>1.000000</td>\n","      <td>0.217869</td>\n","      <td>0.115342</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0</td>\n","      <td>-0.001626</td>\n","      <td>0.020325</td>\n","      <td>0.042276</td>\n","      <td>0.176016</td>\n","      <td>0.309756</td>\n","      <td>0.255285</td>\n","      <td>0.200813</td>\n","      <td>0.106098</td>\n","      <td>0.010976</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>8.009680</td>\n","      <td>0.640159</td>\n","      <td>1.000000</td>\n","      <td>0.522061</td>\n","      <td>-0.032497</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0</td>\n","      <td>-0.045455</td>\n","      <td>0.062500</td>\n","      <td>0.170455</td>\n","      <td>0.217330</td>\n","      <td>0.264205</td>\n","      <td>0.198864</td>\n","      <td>0.133523</td>\n","      <td>0.061080</td>\n","      <td>-0.012784</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>9.573579</td>\n","      <td>0.490219</td>\n","      <td>1.000000</td>\n","      <td>0.063291</td>\n","      <td>0.216341</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>0</td>\n","      <td>0.015745</td>\n","      <td>0.168738</td>\n","      <td>0.321730</td>\n","      <td>0.354927</td>\n","      <td>0.388125</td>\n","      <td>0.388125</td>\n","      <td>0.388125</td>\n","      <td>0.283885</td>\n","      <td>0.179645</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>44.312520</td>\n","      <td>0.880653</td>\n","      <td>1.000000</td>\n","      <td>0.371460</td>\n","      <td>0.001787</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>0</td>\n","      <td>0.043549</td>\n","      <td>0.043549</td>\n","      <td>0.043549</td>\n","      <td>0.043549</td>\n","      <td>0.268042</td>\n","      <td>0.147380</td>\n","      <td>0.095655</td>\n","      <td>0.043929</td>\n","      <td>0.023201</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>36.279895</td>\n","      <td>0.239246</td>\n","      <td>0.956772</td>\n","      <td>1.000000</td>\n","      <td>0.017297</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>0</td>\n","      <td>0.004676</td>\n","      <td>0.111141</td>\n","      <td>0.217606</td>\n","      <td>0.292779</td>\n","      <td>0.367953</td>\n","      <td>0.333064</td>\n","      <td>0.298175</td>\n","      <td>0.201061</td>\n","      <td>0.103947</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>42.207121</td>\n","      <td>0.650017</td>\n","      <td>1.000000</td>\n","      <td>0.387423</td>\n","      <td>0.003739</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>0</td>\n","      <td>-0.088571</td>\n","      <td>0.005714</td>\n","      <td>0.100000</td>\n","      <td>0.177143</td>\n","      <td>0.254286</td>\n","      <td>0.208571</td>\n","      <td>0.162857</td>\n","      <td>0.074286</td>\n","      <td>-0.015714</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>5.570237</td>\n","      <td>0.695596</td>\n","      <td>1.000000</td>\n","      <td>0.009067</td>\n","      <td>0.006477</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>0</td>\n","      <td>0.124931</td>\n","      <td>0.215516</td>\n","      <td>0.306102</td>\n","      <td>0.322441</td>\n","      <td>0.338780</td>\n","      <td>0.209403</td>\n","      <td>0.080027</td>\n","      <td>0.056352</td>\n","      <td>0.032678</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>32.478891</td>\n","      <td>0.499374</td>\n","      <td>1.000000</td>\n","      <td>0.547399</td>\n","      <td>-0.003362</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>25 rows × 2630 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15b4364c-cbf9-46f7-9d19-fb072179b8bd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-15b4364c-cbf9-46f7-9d19-fb072179b8bd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-15b4364c-cbf9-46f7-9d19-fb072179b8bd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    Pollen  350-400 nm, t=0  350-400 nm, t=1  350-400 nm, t=2  \\\n","0        0        -0.010454         0.000201         0.010856   \n","1        0         0.119942         0.184249         0.248555   \n","2        0        -0.016149         0.063383         0.142915   \n","3        0         0.067116         0.198401         0.329687   \n","4        0        -0.043760         0.090762         0.225284   \n","5        0         0.004977         0.024748         0.044518   \n","6        0        -0.004771         0.002135         0.009041   \n","7        0        -0.034386        -0.019729        -0.005637   \n","8        0         0.051364         0.197967         0.344569   \n","9        0         0.032342         0.212160         0.391979   \n","10       0         0.041036         0.093508         0.145980   \n","11       0         0.003179         0.003709         0.004238   \n","12       0         0.028302         0.102404         0.176506   \n","13       0         0.048544         0.064725         0.080906   \n","14       0        -0.111416         0.037443         0.186301   \n","15       0         0.037859         0.084886         0.131914   \n","16       0        -0.008780         0.123373         0.255525   \n","17       0         0.102941         0.107026         0.111111   \n","18       0        -0.001626         0.020325         0.042276   \n","19       0        -0.045455         0.062500         0.170455   \n","20       0         0.015745         0.168738         0.321730   \n","21       0         0.043549         0.043549         0.043549   \n","22       0         0.004676         0.111141         0.217606   \n","23       0        -0.088571         0.005714         0.100000   \n","24       0         0.124931         0.215516         0.306102   \n","\n","    350-400 nm, t=3  350-400 nm, t=4  350-400 nm, t=5  350-400 nm, t=6  \\\n","0          0.114194         0.217531         0.166868         0.116204   \n","1          0.236994         0.225434         0.098988        -0.028179   \n","2          0.286637         0.430359         0.262414         0.094469   \n","3          0.366400         0.403114         0.235325         0.067536   \n","4          0.214749         0.204214         0.213128         0.222042   \n","5          0.202820         0.361123         0.254390         0.147657   \n","6          0.184957         0.360874         0.289427         0.217981   \n","7          0.249154         0.503946         0.315671         0.127396   \n","8          0.212413         0.080257         0.124131         0.168004   \n","9          0.239327         0.086675         0.124838         0.163001   \n","10         0.202825         0.259670         0.133199         0.006727   \n","11         0.141192         0.278146         0.179338         0.080530   \n","12         0.178180         0.179854         0.123554         0.067255   \n","13         0.197411         0.313916         0.319310         0.324703   \n","14         0.398174         0.610046         0.416438         0.222831   \n","15         0.239130         0.346347         0.251405         0.156463   \n","16         0.271874         0.288223         0.189525         0.090827   \n","17         0.330882         0.550654         0.347222         0.143791   \n","18         0.176016         0.309756         0.255285         0.200813   \n","19         0.217330         0.264205         0.198864         0.133523   \n","20         0.354927         0.388125         0.388125         0.388125   \n","21         0.043549         0.268042         0.147380         0.095655   \n","22         0.292779         0.367953         0.333064         0.298175   \n","23         0.177143         0.254286         0.208571         0.162857   \n","24         0.322441         0.338780         0.209403         0.080027   \n","\n","    350-400 nm, t=7  350-400 nm, t=8  ...  angle=37.5, t=115  \\\n","0          0.109168         0.102131  ...           0.000000   \n","1         -0.054191        -0.081647  ...           0.000000   \n","2          0.082761         0.071054  ...           0.000000   \n","3          0.063644         0.059752  ...         739.383196   \n","4          0.133712         0.044571  ...           0.000000   \n","5          0.106180         0.064703  ...           0.000000   \n","6          0.142516         0.067052  ...           0.000000   \n","7          0.106539         0.085682  ...           0.000000   \n","8          0.113965         0.059925  ...           0.000000   \n","9          0.172057         0.181113  ...           0.000000   \n","10         0.003700         0.000673  ...           0.000000   \n","11         0.053510         0.026490  ...           0.000000   \n","12         0.030280        -0.006847  ...           0.000000   \n","13         0.151564        -0.022114  ...           0.000000   \n","14         0.212785         0.202740  ...           0.000000   \n","15         0.091393         0.026324  ...           0.000000   \n","16         0.055404         0.019982  ...           0.000000   \n","17         0.030229        -0.084150  ...           0.000000   \n","18         0.106098         0.010976  ...           0.000000   \n","19         0.061080        -0.012784  ...           0.000000   \n","20         0.283885         0.179645  ...           0.000000   \n","21         0.043929         0.023201  ...           0.000000   \n","22         0.201061         0.103947  ...           0.000000   \n","23         0.074286        -0.015714  ...           0.000000   \n","24         0.056352         0.032678  ...           0.000000   \n","\n","    angle=37.5, t=116  angle=37.5, t=117  angle=37.5, t=118  \\\n","0            0.000000            0.00000           0.000000   \n","1            0.000000            0.00000           0.000000   \n","2            0.000000            0.00000           0.000000   \n","3          740.476799          600.65502         695.104062   \n","4            0.000000            0.00000           0.000000   \n","5            0.000000            0.00000           0.000000   \n","6            0.000000            0.00000           0.000000   \n","7            0.000000            0.00000           0.000000   \n","8            0.000000            0.00000           0.000000   \n","9            0.000000            0.00000           0.000000   \n","10           0.000000            0.00000           0.000000   \n","11           0.000000            0.00000           0.000000   \n","12           0.000000            0.00000           0.000000   \n","13           0.000000            0.00000           0.000000   \n","14           0.000000            0.00000           0.000000   \n","15           0.000000            0.00000           0.000000   \n","16           0.000000            0.00000           0.000000   \n","17           0.000000            0.00000           0.000000   \n","18           0.000000            0.00000           0.000000   \n","19           0.000000            0.00000           0.000000   \n","20           0.000000            0.00000           0.000000   \n","21           0.000000            0.00000           0.000000   \n","22           0.000000            0.00000           0.000000   \n","23           0.000000            0.00000           0.000000   \n","24           0.000000            0.00000           0.000000   \n","\n","    angle=37.5, t=119       size  lt feature 1  lt feature 2  lt feature 3  \\\n","0            0.000000  12.513989      0.280202      1.000000      0.134079   \n","1            0.000000  19.461646      0.481173      1.000000      0.266975   \n","2            0.000000  25.726931      0.519641      1.000000      0.145762   \n","3          873.792882  35.178985      0.639556      1.000000      0.305319   \n","4            0.000000   4.672308      0.624575      1.000000      0.396259   \n","5            0.000000  32.669015      0.508910      1.000000      0.384810   \n","6            0.000000  16.917568      0.528344      1.000000      0.325935   \n","7            0.000000   5.183246      0.542076      1.000000      0.058968   \n","8            0.000000  10.300820      0.487222      1.000000      0.185278   \n","9            0.000000  10.891347      0.349795      1.000000      0.157729   \n","10           0.000000  13.280824      0.319376      1.000000      0.244995   \n","11           0.000000  16.409027      0.332133      1.000000      0.381038   \n","12           0.000000  34.757318      0.252751      1.000000      0.260605   \n","13           0.000000  23.499978      0.562924      1.000000      0.369398   \n","14           0.000000  13.441137      0.735643      1.000000      0.023720   \n","15           0.000000  23.008255      0.620442      1.000000      0.192139   \n","16           0.000000  19.037387      0.378269      1.000000      0.249493   \n","17           0.000000   6.463340      0.673014      1.000000      0.217869   \n","18           0.000000   8.009680      0.640159      1.000000      0.522061   \n","19           0.000000   9.573579      0.490219      1.000000      0.063291   \n","20           0.000000  44.312520      0.880653      1.000000      0.371460   \n","21           0.000000  36.279895      0.239246      0.956772      1.000000   \n","22           0.000000  42.207121      0.650017      1.000000      0.387423   \n","23           0.000000   5.570237      0.695596      1.000000      0.009067   \n","24           0.000000  32.478891      0.499374      1.000000      0.547399   \n","\n","    lt feature 4  \n","0      -0.008439  \n","1       0.140432  \n","2       0.002905  \n","3      -0.015814  \n","4      -0.059949  \n","5       0.028841  \n","6      -0.021346  \n","7      -0.143428  \n","8       0.069306  \n","9      -0.011491  \n","10      0.040220  \n","11      0.032803  \n","12      0.000475  \n","13      0.039384  \n","14     -0.035268  \n","15      0.014740  \n","16     -0.021156  \n","17      0.115342  \n","18     -0.032497  \n","19      0.216341  \n","20      0.001787  \n","21      0.017297  \n","22      0.003739  \n","23      0.006477  \n","24     -0.003362  \n","\n","[25 rows x 2630 columns]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["#From inspection of the csv data, it appears that pollenID is a number used to identify a specific column of data\n","#We can drop this column as it has no significance to our data analysis\n","results.drop(['Sample ID'], axis=1, inplace=True)\n","results.head(25)"]},{"cell_type":"markdown","metadata":{"id":"hBQpF_zvzP5M"},"source":["# Start EDA on the full combined dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":487},"executionInfo":{"elapsed":379,"status":"ok","timestamp":1675409010955,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"GwquHeIfy0JS","outputId":"46bc49b3-7991-447b-a1a9-e19aa441fba6"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-62ef7d6f-2929-4530-ab22-4c421ea036a5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>350-400 nm, t=0</th>\n","      <th>350-400 nm, t=1</th>\n","      <th>350-400 nm, t=2</th>\n","      <th>350-400 nm, t=3</th>\n","      <th>350-400 nm, t=4</th>\n","      <th>350-400 nm, t=5</th>\n","      <th>350-400 nm, t=6</th>\n","      <th>350-400 nm, t=7</th>\n","      <th>350-400 nm, t=8</th>\n","      <th>350-400 nm, t=9</th>\n","      <th>...</th>\n","      <th>angle=37.5, t=115</th>\n","      <th>angle=37.5, t=116</th>\n","      <th>angle=37.5, t=117</th>\n","      <th>angle=37.5, t=118</th>\n","      <th>angle=37.5, t=119</th>\n","      <th>size</th>\n","      <th>lt feature 1</th>\n","      <th>lt feature 2</th>\n","      <th>lt feature 3</th>\n","      <th>lt feature 4</th>\n","    </tr>\n","    <tr>\n","      <th>Pollen</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.039862</td>\n","      <td>0.108794</td>\n","      <td>0.176050</td>\n","      <td>0.243533</td>\n","      <td>0.314024</td>\n","      <td>0.234545</td>\n","      <td>0.155572</td>\n","      <td>0.106126</td>\n","      <td>0.058639</td>\n","      <td>0.036964</td>\n","      <td>...</td>\n","      <td>24.635581</td>\n","      <td>22.722279</td>\n","      <td>21.421931</td>\n","      <td>21.429997</td>\n","      <td>21.898276</td>\n","      <td>23.222805</td>\n","      <td>0.575525</td>\n","      <td>0.959080</td>\n","      <td>0.339958</td>\n","      <td>0.004894</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.056573</td>\n","      <td>0.119788</td>\n","      <td>0.183129</td>\n","      <td>0.249048</td>\n","      <td>0.314950</td>\n","      <td>0.226156</td>\n","      <td>0.137377</td>\n","      <td>0.091903</td>\n","      <td>0.046292</td>\n","      <td>0.025013</td>\n","      <td>...</td>\n","      <td>20.475165</td>\n","      <td>18.102172</td>\n","      <td>16.426337</td>\n","      <td>15.502402</td>\n","      <td>15.166264</td>\n","      <td>23.664796</td>\n","      <td>0.702715</td>\n","      <td>0.832613</td>\n","      <td>0.538100</td>\n","      <td>0.004522</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.073504</td>\n","      <td>0.158444</td>\n","      <td>0.245236</td>\n","      <td>0.323764</td>\n","      <td>0.412187</td>\n","      <td>0.336994</td>\n","      <td>0.261900</td>\n","      <td>0.199446</td>\n","      <td>0.138063</td>\n","      <td>0.101486</td>\n","      <td>...</td>\n","      <td>31.225781</td>\n","      <td>26.530155</td>\n","      <td>24.119289</td>\n","      <td>21.597056</td>\n","      <td>23.858187</td>\n","      <td>31.778363</td>\n","      <td>0.881947</td>\n","      <td>0.846511</td>\n","      <td>0.317620</td>\n","      <td>0.005782</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.037399</td>\n","      <td>0.105873</td>\n","      <td>0.174307</td>\n","      <td>0.243024</td>\n","      <td>0.310912</td>\n","      <td>0.236246</td>\n","      <td>0.161697</td>\n","      <td>0.114445</td>\n","      <td>0.067296</td>\n","      <td>0.045495</td>\n","      <td>...</td>\n","      <td>11.040416</td>\n","      <td>9.571376</td>\n","      <td>10.017218</td>\n","      <td>9.289107</td>\n","      <td>9.929127</td>\n","      <td>29.140169</td>\n","      <td>0.669121</td>\n","      <td>0.938635</td>\n","      <td>0.464005</td>\n","      <td>0.004640</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.044879</td>\n","      <td>0.131827</td>\n","      <td>0.219772</td>\n","      <td>0.336905</td>\n","      <td>0.455859</td>\n","      <td>0.336792</td>\n","      <td>0.217741</td>\n","      <td>0.158643</td>\n","      <td>0.099709</td>\n","      <td>0.070009</td>\n","      <td>...</td>\n","      <td>11.753044</td>\n","      <td>10.063810</td>\n","      <td>7.194079</td>\n","      <td>4.522872</td>\n","      <td>4.297533</td>\n","      <td>29.899403</td>\n","      <td>0.913416</td>\n","      <td>0.772652</td>\n","      <td>0.376390</td>\n","      <td>0.008528</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.056405</td>\n","      <td>0.135058</td>\n","      <td>0.214950</td>\n","      <td>0.287244</td>\n","      <td>0.370524</td>\n","      <td>0.296917</td>\n","      <td>0.222618</td>\n","      <td>0.164160</td>\n","      <td>0.104211</td>\n","      <td>0.073854</td>\n","      <td>...</td>\n","      <td>7.112177</td>\n","      <td>6.226718</td>\n","      <td>5.742593</td>\n","      <td>5.429945</td>\n","      <td>4.916054</td>\n","      <td>29.176515</td>\n","      <td>0.794364</td>\n","      <td>0.933875</td>\n","      <td>0.351754</td>\n","      <td>0.011383</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.041435</td>\n","      <td>0.109992</td>\n","      <td>0.178697</td>\n","      <td>0.242617</td>\n","      <td>0.310360</td>\n","      <td>0.227442</td>\n","      <td>0.144501</td>\n","      <td>0.102271</td>\n","      <td>0.060810</td>\n","      <td>0.040379</td>\n","      <td>...</td>\n","      <td>24.950251</td>\n","      <td>23.479846</td>\n","      <td>18.255061</td>\n","      <td>12.532719</td>\n","      <td>11.038118</td>\n","      <td>34.792384</td>\n","      <td>0.690533</td>\n","      <td>0.903628</td>\n","      <td>0.568830</td>\n","      <td>-0.007118</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.053201</td>\n","      <td>0.140906</td>\n","      <td>0.230827</td>\n","      <td>0.310243</td>\n","      <td>0.395126</td>\n","      <td>0.319159</td>\n","      <td>0.242127</td>\n","      <td>0.181742</td>\n","      <td>0.122389</td>\n","      <td>0.088042</td>\n","      <td>...</td>\n","      <td>2.522116</td>\n","      <td>2.394454</td>\n","      <td>2.324540</td>\n","      <td>2.323709</td>\n","      <td>2.311288</td>\n","      <td>20.281112</td>\n","      <td>0.777014</td>\n","      <td>0.958113</td>\n","      <td>0.246259</td>\n","      <td>0.003353</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.037810</td>\n","      <td>0.123450</td>\n","      <td>0.211095</td>\n","      <td>0.282686</td>\n","      <td>0.355651</td>\n","      <td>0.263665</td>\n","      <td>0.171342</td>\n","      <td>0.117625</td>\n","      <td>0.064223</td>\n","      <td>0.041281</td>\n","      <td>...</td>\n","      <td>0.289914</td>\n","      <td>0.146456</td>\n","      <td>0.106316</td>\n","      <td>0.138197</td>\n","      <td>0.358075</td>\n","      <td>21.496406</td>\n","      <td>0.722312</td>\n","      <td>0.930194</td>\n","      <td>0.507421</td>\n","      <td>0.004845</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.053028</td>\n","      <td>0.127342</td>\n","      <td>0.205098</td>\n","      <td>0.271501</td>\n","      <td>0.342880</td>\n","      <td>0.269279</td>\n","      <td>0.194298</td>\n","      <td>0.143700</td>\n","      <td>0.093285</td>\n","      <td>0.066190</td>\n","      <td>...</td>\n","      <td>18.832387</td>\n","      <td>17.081781</td>\n","      <td>15.158189</td>\n","      <td>12.755951</td>\n","      <td>12.369426</td>\n","      <td>26.147815</td>\n","      <td>0.709150</td>\n","      <td>0.952947</td>\n","      <td>0.458446</td>\n","      <td>0.011701</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.041750</td>\n","      <td>0.112086</td>\n","      <td>0.181947</td>\n","      <td>0.254107</td>\n","      <td>0.327153</td>\n","      <td>0.240291</td>\n","      <td>0.153038</td>\n","      <td>0.107378</td>\n","      <td>0.061868</td>\n","      <td>0.040887</td>\n","      <td>...</td>\n","      <td>17.172880</td>\n","      <td>16.516822</td>\n","      <td>16.447946</td>\n","      <td>15.225911</td>\n","      <td>15.981006</td>\n","      <td>25.316066</td>\n","      <td>0.688081</td>\n","      <td>0.947361</td>\n","      <td>0.506597</td>\n","      <td>0.010187</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.092178</td>\n","      <td>0.156882</td>\n","      <td>0.234031</td>\n","      <td>0.286468</td>\n","      <td>0.366222</td>\n","      <td>0.309164</td>\n","      <td>0.256068</td>\n","      <td>0.203092</td>\n","      <td>0.157316</td>\n","      <td>0.118571</td>\n","      <td>...</td>\n","      <td>4.979839</td>\n","      <td>4.184880</td>\n","      <td>4.041999</td>\n","      <td>3.773861</td>\n","      <td>4.173678</td>\n","      <td>24.936760</td>\n","      <td>0.679193</td>\n","      <td>0.942132</td>\n","      <td>0.330649</td>\n","      <td>-0.001703</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>12 rows × 2629 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62ef7d6f-2929-4530-ab22-4c421ea036a5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-62ef7d6f-2929-4530-ab22-4c421ea036a5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-62ef7d6f-2929-4530-ab22-4c421ea036a5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["        350-400 nm, t=0  350-400 nm, t=1  350-400 nm, t=2  350-400 nm, t=3  \\\n","Pollen                                                                       \n","0              0.039862         0.108794         0.176050         0.243533   \n","1              0.056573         0.119788         0.183129         0.249048   \n","2              0.073504         0.158444         0.245236         0.323764   \n","3              0.037399         0.105873         0.174307         0.243024   \n","4              0.044879         0.131827         0.219772         0.336905   \n","5              0.056405         0.135058         0.214950         0.287244   \n","6              0.041435         0.109992         0.178697         0.242617   \n","7              0.053201         0.140906         0.230827         0.310243   \n","8              0.037810         0.123450         0.211095         0.282686   \n","9              0.053028         0.127342         0.205098         0.271501   \n","10             0.041750         0.112086         0.181947         0.254107   \n","11             0.092178         0.156882         0.234031         0.286468   \n","\n","        350-400 nm, t=4  350-400 nm, t=5  350-400 nm, t=6  350-400 nm, t=7  \\\n","Pollen                                                                       \n","0              0.314024         0.234545         0.155572         0.106126   \n","1              0.314950         0.226156         0.137377         0.091903   \n","2              0.412187         0.336994         0.261900         0.199446   \n","3              0.310912         0.236246         0.161697         0.114445   \n","4              0.455859         0.336792         0.217741         0.158643   \n","5              0.370524         0.296917         0.222618         0.164160   \n","6              0.310360         0.227442         0.144501         0.102271   \n","7              0.395126         0.319159         0.242127         0.181742   \n","8              0.355651         0.263665         0.171342         0.117625   \n","9              0.342880         0.269279         0.194298         0.143700   \n","10             0.327153         0.240291         0.153038         0.107378   \n","11             0.366222         0.309164         0.256068         0.203092   \n","\n","        350-400 nm, t=8  350-400 nm, t=9  ...  angle=37.5, t=115  \\\n","Pollen                                    ...                      \n","0              0.058639         0.036964  ...          24.635581   \n","1              0.046292         0.025013  ...          20.475165   \n","2              0.138063         0.101486  ...          31.225781   \n","3              0.067296         0.045495  ...          11.040416   \n","4              0.099709         0.070009  ...          11.753044   \n","5              0.104211         0.073854  ...           7.112177   \n","6              0.060810         0.040379  ...          24.950251   \n","7              0.122389         0.088042  ...           2.522116   \n","8              0.064223         0.041281  ...           0.289914   \n","9              0.093285         0.066190  ...          18.832387   \n","10             0.061868         0.040887  ...          17.172880   \n","11             0.157316         0.118571  ...           4.979839   \n","\n","        angle=37.5, t=116  angle=37.5, t=117  angle=37.5, t=118  \\\n","Pollen                                                            \n","0               22.722279          21.421931          21.429997   \n","1               18.102172          16.426337          15.502402   \n","2               26.530155          24.119289          21.597056   \n","3                9.571376          10.017218           9.289107   \n","4               10.063810           7.194079           4.522872   \n","5                6.226718           5.742593           5.429945   \n","6               23.479846          18.255061          12.532719   \n","7                2.394454           2.324540           2.323709   \n","8                0.146456           0.106316           0.138197   \n","9               17.081781          15.158189          12.755951   \n","10              16.516822          16.447946          15.225911   \n","11               4.184880           4.041999           3.773861   \n","\n","        angle=37.5, t=119       size  lt feature 1  lt feature 2  \\\n","Pollen                                                             \n","0               21.898276  23.222805      0.575525      0.959080   \n","1               15.166264  23.664796      0.702715      0.832613   \n","2               23.858187  31.778363      0.881947      0.846511   \n","3                9.929127  29.140169      0.669121      0.938635   \n","4                4.297533  29.899403      0.913416      0.772652   \n","5                4.916054  29.176515      0.794364      0.933875   \n","6               11.038118  34.792384      0.690533      0.903628   \n","7                2.311288  20.281112      0.777014      0.958113   \n","8                0.358075  21.496406      0.722312      0.930194   \n","9               12.369426  26.147815      0.709150      0.952947   \n","10              15.981006  25.316066      0.688081      0.947361   \n","11               4.173678  24.936760      0.679193      0.942132   \n","\n","        lt feature 3  lt feature 4  \n","Pollen                              \n","0           0.339958      0.004894  \n","1           0.538100      0.004522  \n","2           0.317620      0.005782  \n","3           0.464005      0.004640  \n","4           0.376390      0.008528  \n","5           0.351754      0.011383  \n","6           0.568830     -0.007118  \n","7           0.246259      0.003353  \n","8           0.507421      0.004845  \n","9           0.458446      0.011701  \n","10          0.506597      0.010187  \n","11          0.330649     -0.001703  \n","\n","[12 rows x 2629 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["results.groupby('Pollen').mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":5194,"status":"ok","timestamp":1675409016145,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"ZIigucI706G9","outputId":"d4a3b41b-9b96-495a-beaa-25523a88e947"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n","  warnings.warn(msg, FutureWarning)\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["#We can get a visual representation below\n","for i in ['lt feature 1', 'lt feature 2', 'lt feature 3', 'lt feature 4']: #For every feature\n","    p0 = list(results[results['Pollen'] == 0][i].dropna())\n","    p1 = list(results[results['Pollen'] == 1][i].dropna())\n","    p2 = list(results[results['Pollen'] == 2][i].dropna())\n","    p3 = list(results[results['Pollen'] == 3][i].dropna())\n","    p4 = list(results[results['Pollen'] == 4][i].dropna())\n","    p5 = list(results[results['Pollen'] == 5][i].dropna())\n","    p6 = list(results[results['Pollen'] == 6][i].dropna())\n","    p7 = list(results[results['Pollen'] == 7][i].dropna())\n","    p8 = list(results[results['Pollen'] == 8][i].dropna())\n","    p9 = list(results[results['Pollen'] == 9][i].dropna())\n","    p10 = list(results[results['Pollen'] == 10][i].dropna())\n","    p11 = list(results[results['Pollen'] == 11][i].dropna())\n","    xmin = min(min(p0), min(p1), min(p2), min(p3), min(p4), min(p5), min(p6), min(p7), min(p8), min(p9), min(p10), min(p11)) #Dimensions of the plot\n","    xmax = max(max(p0), max(p1), max(p2), max(p3), max(p4), max(p5), max(p6), max(p7), max(p8), max(p9), max(p10), max(p11))\n","    width = (xmax - xmin) / 40\n","    #Draw the plots, arranging adelie as red, gentoo as green, chinstrap as blue\n","    sns.distplot(p0, kde=False, bins=np.arange(xmin, xmax, width)) \n","    sns.distplot(p1, kde=False, bins=np.arange(xmin, xmax, width))\n","    sns.distplot(p2, kde=False, bins=np.arange(xmin, xmax, width))\n","    sns.distplot(p3, kde=False, bins=np.arange(xmin, xmax, width)) \n","    sns.distplot(p4, kde=False, bins=np.arange(xmin, xmax, width))\n","    sns.distplot(p5, kde=False, bins=np.arange(xmin, xmax, width))\n","    sns.distplot(p6, kde=False, bins=np.arange(xmin, xmax, width)) \n","    sns.distplot(p7, kde=False, bins=np.arange(xmin, xmax, width))\n","    sns.distplot(p8, kde=False, bins=np.arange(xmin, xmax, width))\n","    sns.distplot(p9, kde=False, bins=np.arange(xmin, xmax, width)) \n","    sns.distplot(p10, kde=False, bins=np.arange(xmin, xmax, width))\n","    sns.distplot(p11, kde=False, bins=np.arange(xmin, xmax, width))\n","    plt.legend(['Pollen 0', 'Pollen 1', 'Pollen 2', 'Pollen 3', 'Pollen 4', 'Pollen 5', 'Pollen 6', 'Pollen 7', 'Pollen 8', 'Pollen 9', 'Pollen 10', 'Pollen 11' ]) #Legends for plot\n","    plt.title('Overlaid histogram for {}'.format(i)) #Title\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"si5h3tIc-1Ep"},"source":["Notes: There is too much different pollen types and features to plot and effectively plot and make sense of it. Might need to tweak plotting parameters? And plot by different categories of data? I.e., EDA lifetime, size, scattering, seperately and then consolidate their EDA later"]},{"cell_type":"markdown","metadata":{"id":"e9KGQK_pXuCT"},"source":["# Outlier Detection and normalization\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UESrokz9X25D"},"outputs":[],"source":["# def detect_outlier(feature, dataframe):\n","#     outliers = []\n","#     data = dataframe[feature]\n","#     mean = np.mean(data)\n","#     std =np.std(data)\n","    \n","    \n","#     for y in data:\n","#         z_score= (y - mean)/std \n","#         if np.abs(z_score) > 3: #z_score is how may std above the mean, we are checking for 3 std above the mean\n","#             outliers.append(y)\n","#     print('\\nOutlier caps for {}:'.format(feature))\n","#     print('  --95p: {:.1f} / {} values exceed that'.format(data.quantile(.95),\n","#                                                              len([i for i in data\n","#                                                                   if i > data.quantile(.95)])))\n","#     print('  --3sd: {:.1f} / {} values exceed that'.format(mean + 3*(std), len(outliers)))\n","#     print('  --99p: {:.1f} / {} values exceed that'.format(data.quantile(.99),\n","#                                                            len([i for i in data\n","#                                                                 if i > data.quantile(.99)])))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y-Wy8nrzX7cx"},"outputs":[],"source":["feature_names = []\n","for col in features.columns:\n","    feature_names.append(col)\n","# for feat in feature_names:\n","#     detect_outlier(feat,results)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S9x4BTJDYl_Y"},"outputs":[],"source":["thresh = 3\n","data = results.copy()\n","for feat in feature_names:\n","    mean = np.mean(data[feat])\n","    std = np.std(data[feat]) \n","    for x in data[feat]:\n","        z = (x-mean)/std\n","        if z > thresh:\n","            data[feat] = data[feat].replace(x,mean)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AF9eKk-Ydqe3"},"outputs":[],"source":["# data.iloc[:,:].hist(figsize=(20,10),bins=30, edgecolor='black')\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-PHB6nQDwici"},"outputs":[],"source":["y = data['Pollen'] # we are using channel as target variable\n","X = data.drop(['Pollen'], axis=1)\n","\n","\n","#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.4, random_state=42)\n","X_test, X_Val, y_test, y_Val = train_test_split(X_test, y_test, shuffle = True, test_size=0.5, random_state=42)\n","\n","scaler = StandardScaler()\n","x_train = scaler.fit_transform(X_train)\n","x_test = scaler.fit_transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1675409127550,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"HBnmDGGdxCIF","outputId":"3e3f9cca-d78e-4f3c-c392-96419451bda0"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-2136a312-09d5-44be-82b6-6f775ba25514\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>350-400 nm, t=0</th>\n","      <th>350-400 nm, t=1</th>\n","      <th>350-400 nm, t=2</th>\n","      <th>350-400 nm, t=3</th>\n","      <th>350-400 nm, t=4</th>\n","      <th>350-400 nm, t=5</th>\n","      <th>350-400 nm, t=6</th>\n","      <th>350-400 nm, t=7</th>\n","      <th>350-400 nm, t=8</th>\n","      <th>350-400 nm, t=9</th>\n","      <th>...</th>\n","      <th>angle=37.5, t=115</th>\n","      <th>angle=37.5, t=116</th>\n","      <th>angle=37.5, t=117</th>\n","      <th>angle=37.5, t=118</th>\n","      <th>angle=37.5, t=119</th>\n","      <th>size</th>\n","      <th>lt feature 1</th>\n","      <th>lt feature 2</th>\n","      <th>lt feature 3</th>\n","      <th>lt feature 4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.627708</td>\n","      <td>-1.474181</td>\n","      <td>-1.562630</td>\n","      <td>-2.269988</td>\n","      <td>-2.115761</td>\n","      <td>-1.396486</td>\n","      <td>-0.219562</td>\n","      <td>1.243089</td>\n","      <td>2.842885</td>\n","      <td>2.619373</td>\n","      <td>...</td>\n","      <td>19.237060</td>\n","      <td>3.928279</td>\n","      <td>2.935771</td>\n","      <td>6.579596</td>\n","      <td>9.997677</td>\n","      <td>2.711269</td>\n","      <td>-0.751682</td>\n","      <td>0.460240</td>\n","      <td>1.092954</td>\n","      <td>0.020641</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.152778</td>\n","      <td>0.092812</td>\n","      <td>2.276853</td>\n","      <td>0.787232</td>\n","      <td>-1.185615</td>\n","      <td>-1.178689</td>\n","      <td>-0.842455</td>\n","      <td>-0.944834</td>\n","      <td>-0.922803</td>\n","      <td>-1.333949</td>\n","      <td>...</td>\n","      <td>-0.059573</td>\n","      <td>-0.059819</td>\n","      <td>-0.053500</td>\n","      <td>-0.062068</td>\n","      <td>-0.059407</td>\n","      <td>-0.233657</td>\n","      <td>0.767222</td>\n","      <td>0.460240</td>\n","      <td>0.889126</td>\n","      <td>2.473979</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.129698</td>\n","      <td>0.559791</td>\n","      <td>0.764166</td>\n","      <td>1.264197</td>\n","      <td>1.244393</td>\n","      <td>0.329270</td>\n","      <td>-0.752834</td>\n","      <td>-0.651374</td>\n","      <td>-0.408735</td>\n","      <td>-0.543362</td>\n","      <td>...</td>\n","      <td>-0.059573</td>\n","      <td>-0.059819</td>\n","      <td>-0.053500</td>\n","      <td>-0.062068</td>\n","      <td>-0.059407</td>\n","      <td>1.150244</td>\n","      <td>1.050601</td>\n","      <td>-0.268161</td>\n","      <td>-0.635651</td>\n","      <td>-0.534035</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.314959</td>\n","      <td>-0.886741</td>\n","      <td>-0.985835</td>\n","      <td>0.158896</td>\n","      <td>1.299673</td>\n","      <td>2.242682</td>\n","      <td>2.685226</td>\n","      <td>2.970158</td>\n","      <td>2.802419</td>\n","      <td>2.490283</td>\n","      <td>...</td>\n","      <td>-0.059573</td>\n","      <td>-0.059819</td>\n","      <td>-0.053500</td>\n","      <td>-0.062068</td>\n","      <td>-0.059407</td>\n","      <td>0.901985</td>\n","      <td>1.050601</td>\n","      <td>-0.089609</td>\n","      <td>0.724235</td>\n","      <td>0.128598</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.591337</td>\n","      <td>-0.560527</td>\n","      <td>-1.083265</td>\n","      <td>-2.271781</td>\n","      <td>-2.637426</td>\n","      <td>-2.258300</td>\n","      <td>-1.222722</td>\n","      <td>-1.138645</td>\n","      <td>-0.831718</td>\n","      <td>-0.646678</td>\n","      <td>...</td>\n","      <td>-0.059573</td>\n","      <td>-0.059819</td>\n","      <td>-0.053500</td>\n","      <td>-0.062068</td>\n","      <td>-0.059407</td>\n","      <td>-0.302838</td>\n","      <td>-2.440367</td>\n","      <td>0.460240</td>\n","      <td>-0.059942</td>\n","      <td>-0.055854</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 2629 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2136a312-09d5-44be-82b6-6f775ba25514')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2136a312-09d5-44be-82b6-6f775ba25514 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2136a312-09d5-44be-82b6-6f775ba25514');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   350-400 nm, t=0  350-400 nm, t=1  350-400 nm, t=2  350-400 nm, t=3  \\\n","0        -0.627708        -1.474181        -1.562630        -2.269988   \n","1         0.152778         0.092812         2.276853         0.787232   \n","2        -0.129698         0.559791         0.764166         1.264197   \n","3        -0.314959        -0.886741        -0.985835         0.158896   \n","4         0.591337        -0.560527        -1.083265        -2.271781   \n","\n","   350-400 nm, t=4  350-400 nm, t=5  350-400 nm, t=6  350-400 nm, t=7  \\\n","0        -2.115761        -1.396486        -0.219562         1.243089   \n","1        -1.185615        -1.178689        -0.842455        -0.944834   \n","2         1.244393         0.329270        -0.752834        -0.651374   \n","3         1.299673         2.242682         2.685226         2.970158   \n","4        -2.637426        -2.258300        -1.222722        -1.138645   \n","\n","   350-400 nm, t=8  350-400 nm, t=9  ...  angle=37.5, t=115  \\\n","0         2.842885         2.619373  ...          19.237060   \n","1        -0.922803        -1.333949  ...          -0.059573   \n","2        -0.408735        -0.543362  ...          -0.059573   \n","3         2.802419         2.490283  ...          -0.059573   \n","4        -0.831718        -0.646678  ...          -0.059573   \n","\n","   angle=37.5, t=116  angle=37.5, t=117  angle=37.5, t=118  angle=37.5, t=119  \\\n","0           3.928279           2.935771           6.579596           9.997677   \n","1          -0.059819          -0.053500          -0.062068          -0.059407   \n","2          -0.059819          -0.053500          -0.062068          -0.059407   \n","3          -0.059819          -0.053500          -0.062068          -0.059407   \n","4          -0.059819          -0.053500          -0.062068          -0.059407   \n","\n","       size  lt feature 1  lt feature 2  lt feature 3  lt feature 4  \n","0  2.711269     -0.751682      0.460240      1.092954      0.020641  \n","1 -0.233657      0.767222      0.460240      0.889126      2.473979  \n","2  1.150244      1.050601     -0.268161     -0.635651     -0.534035  \n","3  0.901985      1.050601     -0.089609      0.724235      0.128598  \n","4 -0.302838     -2.440367      0.460240     -0.059942     -0.055854  \n","\n","[5 rows x 2629 columns]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["columns = X_train.columns\n","\n","standardScaler = pd.DataFrame(x_train, columns=columns)\n","\n","standardScaler.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":254},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1675409127551,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"ns03Q_mZxGBN","outputId":"0ee017f9-9242-4af4-b4d0-5502fe3c7c9d"},"outputs":[{"name":"stdout","output_type":"stream","text":["(9866, 2630)\n"]},{"data":{"text/html":["\n","  <div id=\"df-e6f8ca57-93f9-46ee-a147-11a133a411d6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pollen</th>\n","      <th>350-400 nm, t=0</th>\n","      <th>350-400 nm, t=1</th>\n","      <th>350-400 nm, t=2</th>\n","      <th>350-400 nm, t=3</th>\n","      <th>350-400 nm, t=4</th>\n","      <th>350-400 nm, t=5</th>\n","      <th>350-400 nm, t=6</th>\n","      <th>350-400 nm, t=7</th>\n","      <th>350-400 nm, t=8</th>\n","      <th>...</th>\n","      <th>angle=37.5, t=115</th>\n","      <th>angle=37.5, t=116</th>\n","      <th>angle=37.5, t=117</th>\n","      <th>angle=37.5, t=118</th>\n","      <th>angle=37.5, t=119</th>\n","      <th>size</th>\n","      <th>lt feature 1</th>\n","      <th>lt feature 2</th>\n","      <th>lt feature 3</th>\n","      <th>lt feature 4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>-0.010454</td>\n","      <td>0.000201</td>\n","      <td>0.010856</td>\n","      <td>0.114194</td>\n","      <td>0.217531</td>\n","      <td>0.166868</td>\n","      <td>0.116204</td>\n","      <td>0.109168</td>\n","      <td>0.102131</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>12.513989</td>\n","      <td>0.280202</td>\n","      <td>1.0</td>\n","      <td>0.134079</td>\n","      <td>-0.008439</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0.119942</td>\n","      <td>0.184249</td>\n","      <td>0.248555</td>\n","      <td>0.236994</td>\n","      <td>0.225434</td>\n","      <td>0.098988</td>\n","      <td>-0.028179</td>\n","      <td>-0.054191</td>\n","      <td>-0.081647</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>19.461646</td>\n","      <td>0.481173</td>\n","      <td>1.0</td>\n","      <td>0.266975</td>\n","      <td>0.140432</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>-0.016149</td>\n","      <td>0.063383</td>\n","      <td>0.142915</td>\n","      <td>0.286637</td>\n","      <td>0.430359</td>\n","      <td>0.262414</td>\n","      <td>0.094469</td>\n","      <td>0.082761</td>\n","      <td>0.071054</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>25.726931</td>\n","      <td>0.519641</td>\n","      <td>1.0</td>\n","      <td>0.145762</td>\n","      <td>0.002905</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.067116</td>\n","      <td>0.198401</td>\n","      <td>0.329687</td>\n","      <td>0.366400</td>\n","      <td>0.403114</td>\n","      <td>0.235325</td>\n","      <td>0.067536</td>\n","      <td>0.063644</td>\n","      <td>0.059752</td>\n","      <td>...</td>\n","      <td>14.088371</td>\n","      <td>12.621426</td>\n","      <td>11.445568</td>\n","      <td>10.200185</td>\n","      <td>10.393801</td>\n","      <td>35.178985</td>\n","      <td>0.639556</td>\n","      <td>1.0</td>\n","      <td>0.305319</td>\n","      <td>-0.015814</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>-0.043760</td>\n","      <td>0.090762</td>\n","      <td>0.225284</td>\n","      <td>0.214749</td>\n","      <td>0.204214</td>\n","      <td>0.213128</td>\n","      <td>0.222042</td>\n","      <td>0.133712</td>\n","      <td>0.044571</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>4.672308</td>\n","      <td>0.624575</td>\n","      <td>1.0</td>\n","      <td>0.396259</td>\n","      <td>-0.059949</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 2630 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6f8ca57-93f9-46ee-a147-11a133a411d6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e6f8ca57-93f9-46ee-a147-11a133a411d6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e6f8ca57-93f9-46ee-a147-11a133a411d6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   Pollen  350-400 nm, t=0  350-400 nm, t=1  350-400 nm, t=2  350-400 nm, t=3  \\\n","0       0        -0.010454         0.000201         0.010856         0.114194   \n","1       0         0.119942         0.184249         0.248555         0.236994   \n","2       0        -0.016149         0.063383         0.142915         0.286637   \n","3       0         0.067116         0.198401         0.329687         0.366400   \n","4       0        -0.043760         0.090762         0.225284         0.214749   \n","\n","   350-400 nm, t=4  350-400 nm, t=5  350-400 nm, t=6  350-400 nm, t=7  \\\n","0         0.217531         0.166868         0.116204         0.109168   \n","1         0.225434         0.098988        -0.028179        -0.054191   \n","2         0.430359         0.262414         0.094469         0.082761   \n","3         0.403114         0.235325         0.067536         0.063644   \n","4         0.204214         0.213128         0.222042         0.133712   \n","\n","   350-400 nm, t=8  ...  angle=37.5, t=115  angle=37.5, t=116  \\\n","0         0.102131  ...           0.000000           0.000000   \n","1        -0.081647  ...           0.000000           0.000000   \n","2         0.071054  ...           0.000000           0.000000   \n","3         0.059752  ...          14.088371          12.621426   \n","4         0.044571  ...           0.000000           0.000000   \n","\n","   angle=37.5, t=117  angle=37.5, t=118  angle=37.5, t=119       size  \\\n","0           0.000000           0.000000           0.000000  12.513989   \n","1           0.000000           0.000000           0.000000  19.461646   \n","2           0.000000           0.000000           0.000000  25.726931   \n","3          11.445568          10.200185          10.393801  35.178985   \n","4           0.000000           0.000000           0.000000   4.672308   \n","\n","   lt feature 1  lt feature 2  lt feature 3  lt feature 4  \n","0      0.280202           1.0      0.134079     -0.008439  \n","1      0.481173           1.0      0.266975      0.140432  \n","2      0.519641           1.0      0.145762      0.002905  \n","3      0.639556           1.0      0.305319     -0.015814  \n","4      0.624575           1.0      0.396259     -0.059949  \n","\n","[5 rows x 2630 columns]"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["print(data.shape)\n","data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mZtS46b9xQpP"},"outputs":[],"source":["# le = LabelEncoder()\n","# y_trainer = le.fit_transform(y_train)\n","# y_tester = le.fit_transform(y_test)\n","# n_classes = 12\n","# y_trainer = to_categorical(y_trainer, n_classes)\n","# y_tester = to_categorical(y_tester, n_classes)\n","# y_Val = le.fit_transform(y_Val)\n","# y_Val = to_categorical(y_Val, n_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n_kGwFwIxSWy"},"outputs":[],"source":["# model = Sequential()\n","# model.add(tf.keras.layers.Input(shape = 2629,))\n","# model.add(tf.keras.layers.Dense(512,activation = 'relu'))\n","# model.add(tf.keras.layers.Dense(128,activation = 'relu'))\n","# # model.add(tf.keras.layers.Dense(128,activation = 'relu'))\n","# # model.add(tf.keras.layers.Dense(64,activation = 'relu'))\n","# model.add(tf.keras.layers.Dense(12,activation = 'softmax'))\n","\n","\n","# model.compile(optimizer =SGD(lr = 0.001), loss = \"categorical_crossentropy\", metrics = [\"accuracy\", Precision(), Recall()])#metrics = [\"accuracy\", Precision(), Recall()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v4R-wOAZnugV"},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","le= LabelEncoder()\n","y_train = le.fit_transform(y_train) #https://towardsdatascience.com/what-and-why-behind-fit-transform-vs-transform-in-scikit-learn-78f915cf96fe\n","y_test = le.transform(y_test)\n","y_train = pd.DataFrame(y_train.reshape(len(y_train),1))\n","y_test = pd.DataFrame(y_test.reshape(len(y_test),1))\n","y_train = tf.keras.utils.to_categorical(y_train,12)\n","y_test = tf.keras.utils.to_categorical(y_test,12)\n","y_Val = le.fit_transform(y_Val)\n","y_Val = to_categorical(y_Val, 12)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1675409127554,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"b28fMlvAnoOY","outputId":"197b732b-c65c-4768-a165-da7782f0155e"},"outputs":[{"name":"stdout","output_type":"stream","text":["(5919, 2629)\n","(1973, 2629)\n","(1974, 2629)\n","(5919, 12)\n","(1973, 12)\n","(1974, 12)\n"]}],"source":["print(X_train.shape)\n","print(X_test.shape)\n","print(X_Val.shape)\n","print(y_train.shape)\n","print(y_test.shape)\n","print(y_Val.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rLLcfL7TmlwA"},"outputs":[],"source":["# ann = Sequential()\n","# ann.add(tf.keras.layers.Input(shape = 2629,))\n","# ann.add(tf.keras.layers.Dense(512,activation = 'relu'))\n","# ann.add(tf.keras.layers.Dense(64,activation = 'relu'))\n","# ann.add(tf.keras.layers.Dropout(0.3))\n","# ann.add(tf.keras.layers.Dense(128,activation = 'relu'))\n","# ann.add(tf.keras.layers.Dense(256,activation = 'relu'))\n","# ann.add(tf.keras.layers.Dropout(0.3))\n","# ann.add(tf.keras.layers.Dense(12,activation = 'softmax'))\n","\n","\n","#NOTE: Document our different processes and what activation algorithms and our loss functions \n","#For bookkeeping!!! It's important!!!!\n","\n","\n","# ann.compile(optimizer =SGD(lr = 0.001), loss = \"categorical_crossentropy\", metrics = [\"accuracy\", Precision(), Recall()])#metrics = [\"accuracy\", Precision(), Recall()]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HzYJtVyiq8M_"},"outputs":[],"source":["# model = Sequential()\n","# model.add(tf.keras.layers.Input(shape = 2629,))\n","# model.add(tf.keras.layers.Dense(20,activation = 'relu'))\n","# model.add(tf.keras.layers.Dense(10,activation = 'relu'))\n","# model.add(tf.keras.layers.Dense(12,activation = 'relu'))\n","# model.add(tf.keras.layers.Dropout(0.5))\n","\n","# model.add(tf.keras.layers.Dense(12,activation = 'softmax'))\n","\n","\n","# model.compile(optimizer =SGD(lr = 0.001, momentum=0.9), loss = \"categorical_crossentropy\", metrics = [\"accuracy\", Precision(), Recall()])#metrics = [\"accuracy\", Precision(), Recall()]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":267,"status":"ok","timestamp":1675409127806,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"iMGGYR9JBK_O","outputId":"75b95904-251b-40a8-cd25-482a010552e0"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n"]}],"source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Input(2629),\n","    tf.keras.layers.Dense(2048),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Dense(1024),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Activation(\"relu\"),\n","    tf.keras.layers.Dense(512),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(400),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(12, activation=\"softmax\")\n","    ])\n","model.compile(optimizer =SGD(lr = 0.001,momentum=0.9), loss = \"categorical_crossentropy\", metrics = [\"accuracy\", Precision(), Recall()])#metrics = [\"accuracy\", Precision(), Recall()]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":287,"status":"ok","timestamp":1675409128084,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"},"user_tz":300},"id":"_7lrj5DkIvV3","outputId":"e731b744-accb-406b-aae5-9de18f71f05a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 2048)              5386240   \n","                                                                 \n"," dropout (Dropout)           (None, 2048)              0         \n","                                                                 \n"," batch_normalization (BatchN  (None, 2048)             8192      \n"," ormalization)                                                   \n","                                                                 \n"," dense_1 (Dense)             (None, 1024)              2098176   \n","                                                                 \n"," dropout_1 (Dropout)         (None, 1024)              0         \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 1024)             4096      \n"," hNormalization)                                                 \n","                                                                 \n"," activation (Activation)     (None, 1024)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 512)               524800    \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 512)              2048      \n"," hNormalization)                                                 \n","                                                                 \n"," dropout_2 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 400)               205200    \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 400)              1600      \n"," hNormalization)                                                 \n","                                                                 \n"," dropout_3 (Dropout)         (None, 400)               0         \n","                                                                 \n"," dense_4 (Dense)             (None, 12)                4812      \n","                                                                 \n","=================================================================\n","Total params: 8,235,164\n","Trainable params: 8,227,196\n","Non-trainable params: 7,968\n","_________________________________________________________________\n"]}],"source":["model.summary() #Using small subset of data and scaled down neural network"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"aKlcgJblnbB0","outputId":"4aa6a1ac-859f-4233-b5b1-2896e9fc35c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10000\n","185/185 [==============================] - 16s 75ms/step - loss: 3.1229 - accuracy: 0.1749 - precision: 0.1972 - recall: 0.0759 - val_loss: 2806.5605 - val_accuracy: 0.0836 - val_precision: 0.0836 - val_recall: 0.0836\n","Epoch 2/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 2.5384 - accuracy: 0.2634 - precision: 0.3465 - recall: 0.1286 - val_loss: 2407.3679 - val_accuracy: 0.0927 - val_precision: 0.0927 - val_recall: 0.0927\n","Epoch 3/10000\n","185/185 [==============================] - 13s 70ms/step - loss: 2.2605 - accuracy: 0.3112 - precision: 0.4308 - recall: 0.1651 - val_loss: 2283.9675 - val_accuracy: 0.1018 - val_precision: 0.1018 - val_recall: 0.1018\n","Epoch 4/10000\n","185/185 [==============================] - 13s 70ms/step - loss: 2.0638 - accuracy: 0.3514 - precision: 0.4819 - recall: 0.1865 - val_loss: 2702.6975 - val_accuracy: 0.1008 - val_precision: 0.1008 - val_recall: 0.1008\n","Epoch 5/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.9592 - accuracy: 0.3739 - precision: 0.5125 - recall: 0.1967 - val_loss: 2650.1306 - val_accuracy: 0.0932 - val_precision: 0.0932 - val_recall: 0.0932\n","Epoch 6/10000\n","185/185 [==============================] - 13s 70ms/step - loss: 1.8448 - accuracy: 0.4141 - precision: 0.5613 - recall: 0.2196 - val_loss: 2282.9214 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 7/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.7725 - accuracy: 0.4165 - precision: 0.5910 - recall: 0.2342 - val_loss: 3057.7522 - val_accuracy: 0.0983 - val_precision: 0.0983 - val_recall: 0.0983\n","Epoch 8/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.7066 - accuracy: 0.4428 - precision: 0.6192 - recall: 0.2558 - val_loss: 3067.1743 - val_accuracy: 0.0932 - val_precision: 0.0932 - val_recall: 0.0932\n","Epoch 9/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.6793 - accuracy: 0.4442 - precision: 0.6283 - recall: 0.2647 - val_loss: 2684.6140 - val_accuracy: 0.0831 - val_precision: 0.0831 - val_recall: 0.0831\n","Epoch 10/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.6130 - accuracy: 0.4606 - precision: 0.6466 - recall: 0.2745 - val_loss: 3084.4443 - val_accuracy: 0.0805 - val_precision: 0.0805 - val_recall: 0.0805\n","Epoch 11/10000\n","185/185 [==============================] - 13s 70ms/step - loss: 1.5605 - accuracy: 0.4866 - precision: 0.6625 - recall: 0.2972 - val_loss: 3250.8655 - val_accuracy: 0.0998 - val_precision: 0.0998 - val_recall: 0.0998\n","Epoch 12/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.5865 - accuracy: 0.4754 - precision: 0.6528 - recall: 0.2897 - val_loss: 3203.6990 - val_accuracy: 0.1160 - val_precision: 0.1160 - val_recall: 0.1160\n","Epoch 13/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.5236 - accuracy: 0.4943 - precision: 0.6732 - recall: 0.3070 - val_loss: 2740.5610 - val_accuracy: 0.0993 - val_precision: 0.0993 - val_recall: 0.0993\n","Epoch 14/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.4912 - accuracy: 0.5155 - precision: 0.6794 - recall: 0.3126 - val_loss: 3189.1970 - val_accuracy: 0.0957 - val_precision: 0.0957 - val_recall: 0.0957\n","Epoch 15/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.4824 - accuracy: 0.5073 - precision: 0.6767 - recall: 0.3222 - val_loss: 3340.3455 - val_accuracy: 0.1028 - val_precision: 0.1028 - val_recall: 0.1028\n","Epoch 16/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.4697 - accuracy: 0.5177 - precision: 0.6868 - recall: 0.3283 - val_loss: 3780.2295 - val_accuracy: 0.0968 - val_precision: 0.0968 - val_recall: 0.0968\n","Epoch 17/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.4153 - accuracy: 0.5303 - precision: 0.7020 - recall: 0.3479 - val_loss: 3057.2488 - val_accuracy: 0.0866 - val_precision: 0.0866 - val_recall: 0.0866\n","Epoch 18/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 1.4062 - accuracy: 0.5388 - precision: 0.6951 - recall: 0.3563 - val_loss: 3438.3970 - val_accuracy: 0.0836 - val_precision: 0.0836 - val_recall: 0.0836\n","Epoch 19/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.4141 - accuracy: 0.5271 - precision: 0.6865 - recall: 0.3470 - val_loss: 3707.1833 - val_accuracy: 0.0745 - val_precision: 0.0745 - val_recall: 0.0745\n","Epoch 20/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.4000 - accuracy: 0.5315 - precision: 0.7004 - recall: 0.3578 - val_loss: 3768.0244 - val_accuracy: 0.0805 - val_precision: 0.0805 - val_recall: 0.0805\n","Epoch 21/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.3701 - accuracy: 0.5430 - precision: 0.7049 - recall: 0.3676 - val_loss: 4188.4766 - val_accuracy: 0.1008 - val_precision: 0.1008 - val_recall: 0.1008\n","Epoch 22/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 1.3476 - accuracy: 0.5631 - precision: 0.7198 - recall: 0.3842 - val_loss: 3817.9722 - val_accuracy: 0.0745 - val_precision: 0.0745 - val_recall: 0.0745\n","Epoch 23/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.3276 - accuracy: 0.5570 - precision: 0.7213 - recall: 0.3887 - val_loss: 4039.0669 - val_accuracy: 0.0907 - val_precision: 0.0907 - val_recall: 0.0907\n","Epoch 24/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.3316 - accuracy: 0.5555 - precision: 0.7138 - recall: 0.3918 - val_loss: 3978.6030 - val_accuracy: 0.0942 - val_precision: 0.0942 - val_recall: 0.0942\n","Epoch 25/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.3120 - accuracy: 0.5656 - precision: 0.7156 - recall: 0.3962 - val_loss: 3913.2527 - val_accuracy: 0.0861 - val_precision: 0.0861 - val_recall: 0.0861\n","Epoch 26/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 1.2831 - accuracy: 0.5721 - precision: 0.7319 - recall: 0.4119 - val_loss: 3535.9272 - val_accuracy: 0.1018 - val_precision: 0.1018 - val_recall: 0.1018\n","Epoch 27/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.2786 - accuracy: 0.5770 - precision: 0.7186 - recall: 0.4151 - val_loss: 3710.6323 - val_accuracy: 0.1089 - val_precision: 0.1089 - val_recall: 0.1089\n","Epoch 28/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.2708 - accuracy: 0.5776 - precision: 0.7294 - recall: 0.4241 - val_loss: 3862.8936 - val_accuracy: 0.0871 - val_precision: 0.0871 - val_recall: 0.0871\n","Epoch 29/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.2589 - accuracy: 0.5810 - precision: 0.7262 - recall: 0.4236 - val_loss: 3644.5483 - val_accuracy: 0.0937 - val_precision: 0.0937 - val_recall: 0.0937\n","Epoch 30/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 1.2479 - accuracy: 0.5827 - precision: 0.7293 - recall: 0.4315 - val_loss: 3876.1904 - val_accuracy: 0.0942 - val_precision: 0.0942 - val_recall: 0.0942\n","Epoch 31/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 1.2308 - accuracy: 0.5884 - precision: 0.7311 - recall: 0.4323 - val_loss: 3659.5408 - val_accuracy: 0.0993 - val_precision: 0.0993 - val_recall: 0.0993\n","Epoch 32/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 1.2213 - accuracy: 0.5962 - precision: 0.7349 - recall: 0.4364 - val_loss: 4382.6514 - val_accuracy: 0.0866 - val_precision: 0.0866 - val_recall: 0.0866\n","Epoch 33/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 1.2106 - accuracy: 0.5984 - precision: 0.7426 - recall: 0.4567 - val_loss: 4297.9829 - val_accuracy: 0.0922 - val_precision: 0.0922 - val_recall: 0.0922\n","Epoch 34/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 1.1793 - accuracy: 0.5989 - precision: 0.7341 - recall: 0.4492 - val_loss: 3828.3232 - val_accuracy: 0.0871 - val_precision: 0.0871 - val_recall: 0.0871\n","Epoch 35/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 1.1738 - accuracy: 0.6031 - precision: 0.7435 - recall: 0.4627 - val_loss: 4764.3247 - val_accuracy: 0.0861 - val_precision: 0.0861 - val_recall: 0.0861\n","Epoch 36/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 1.1682 - accuracy: 0.6101 - precision: 0.7364 - recall: 0.4720 - val_loss: 4087.4998 - val_accuracy: 0.0957 - val_precision: 0.0957 - val_recall: 0.0957\n","Epoch 37/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 1.1662 - accuracy: 0.6101 - precision: 0.7494 - recall: 0.4754 - val_loss: 4819.4146 - val_accuracy: 0.0780 - val_precision: 0.0780 - val_recall: 0.0780\n","Epoch 38/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.1467 - accuracy: 0.6227 - precision: 0.7551 - recall: 0.4845 - val_loss: 4128.7979 - val_accuracy: 0.0887 - val_precision: 0.0887 - val_recall: 0.0887\n","Epoch 39/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.1383 - accuracy: 0.6199 - precision: 0.7556 - recall: 0.4820 - val_loss: 4294.5562 - val_accuracy: 0.0932 - val_precision: 0.0932 - val_recall: 0.0932\n","Epoch 40/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.1370 - accuracy: 0.6226 - precision: 0.7513 - recall: 0.4884 - val_loss: 5004.5596 - val_accuracy: 0.0846 - val_precision: 0.0846 - val_recall: 0.0846\n","Epoch 41/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 1.1322 - accuracy: 0.6254 - precision: 0.7492 - recall: 0.4957 - val_loss: 3721.8105 - val_accuracy: 0.1018 - val_precision: 0.1018 - val_recall: 0.1018\n","Epoch 42/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 1.1261 - accuracy: 0.6219 - precision: 0.7501 - recall: 0.4879 - val_loss: 5015.9028 - val_accuracy: 0.0892 - val_precision: 0.0892 - val_recall: 0.0892\n","Epoch 43/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 1.0968 - accuracy: 0.6361 - precision: 0.7552 - recall: 0.5003 - val_loss: 4353.3545 - val_accuracy: 0.0963 - val_precision: 0.0963 - val_recall: 0.0963\n","Epoch 44/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 1.1234 - accuracy: 0.6265 - precision: 0.7475 - recall: 0.4992 - val_loss: 4149.6133 - val_accuracy: 0.1044 - val_precision: 0.1044 - val_recall: 0.1044\n","Epoch 45/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 1.0737 - accuracy: 0.6437 - precision: 0.7639 - recall: 0.5138 - val_loss: 4468.4912 - val_accuracy: 0.0836 - val_precision: 0.0836 - val_recall: 0.0836\n","Epoch 46/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 1.0652 - accuracy: 0.6412 - precision: 0.7626 - recall: 0.5195 - val_loss: 4514.4263 - val_accuracy: 0.1069 - val_precision: 0.1069 - val_recall: 0.1069\n","Epoch 47/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.0559 - accuracy: 0.6515 - precision: 0.7656 - recall: 0.5258 - val_loss: 4779.3027 - val_accuracy: 0.0968 - val_precision: 0.0968 - val_recall: 0.0968\n","Epoch 48/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.0594 - accuracy: 0.6503 - precision: 0.7708 - recall: 0.5334 - val_loss: 4422.8564 - val_accuracy: 0.0836 - val_precision: 0.0836 - val_recall: 0.0836\n","Epoch 49/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.0535 - accuracy: 0.6493 - precision: 0.7583 - recall: 0.5312 - val_loss: 5029.2563 - val_accuracy: 0.1003 - val_precision: 0.1003 - val_recall: 0.1003\n","Epoch 50/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.0390 - accuracy: 0.6559 - precision: 0.7722 - recall: 0.5356 - val_loss: 5187.1597 - val_accuracy: 0.0856 - val_precision: 0.0856 - val_recall: 0.0856\n","Epoch 51/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.0274 - accuracy: 0.6587 - precision: 0.7736 - recall: 0.5416 - val_loss: 4809.9854 - val_accuracy: 0.0836 - val_precision: 0.0836 - val_recall: 0.0836\n","Epoch 52/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.0098 - accuracy: 0.6562 - precision: 0.7719 - recall: 0.5408 - val_loss: 4515.8027 - val_accuracy: 0.1003 - val_precision: 0.1003 - val_recall: 0.1003\n","Epoch 53/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 1.0053 - accuracy: 0.6629 - precision: 0.7752 - recall: 0.5530 - val_loss: 4263.7021 - val_accuracy: 0.0993 - val_precision: 0.0993 - val_recall: 0.0993\n","Epoch 54/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 1.0085 - accuracy: 0.6621 - precision: 0.7790 - recall: 0.5491 - val_loss: 5031.6909 - val_accuracy: 0.0780 - val_precision: 0.0780 - val_recall: 0.0780\n","Epoch 55/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.9909 - accuracy: 0.6680 - precision: 0.7792 - recall: 0.5552 - val_loss: 5018.5825 - val_accuracy: 0.0917 - val_precision: 0.0917 - val_recall: 0.0917\n","Epoch 56/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 1.0020 - accuracy: 0.6680 - precision: 0.7773 - recall: 0.5585 - val_loss: 4953.7891 - val_accuracy: 0.0907 - val_precision: 0.0907 - val_recall: 0.0907\n","Epoch 57/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 0.9810 - accuracy: 0.6824 - precision: 0.7806 - recall: 0.5655 - val_loss: 4923.5537 - val_accuracy: 0.0947 - val_precision: 0.0947 - val_recall: 0.0947\n","Epoch 58/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.9759 - accuracy: 0.6783 - precision: 0.7812 - recall: 0.5597 - val_loss: 4494.7173 - val_accuracy: 0.1089 - val_precision: 0.1089 - val_recall: 0.1089\n","Epoch 59/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 0.9539 - accuracy: 0.6812 - precision: 0.7936 - recall: 0.5741 - val_loss: 5214.9351 - val_accuracy: 0.0932 - val_precision: 0.0932 - val_recall: 0.0932\n","Epoch 60/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 0.9534 - accuracy: 0.6817 - precision: 0.7850 - recall: 0.5822 - val_loss: 5853.7207 - val_accuracy: 0.0876 - val_precision: 0.0876 - val_recall: 0.0876\n","Epoch 61/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 0.9623 - accuracy: 0.6726 - precision: 0.7803 - recall: 0.5756 - val_loss: 3920.8655 - val_accuracy: 0.1094 - val_precision: 0.1094 - val_recall: 0.1094\n","Epoch 62/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.9506 - accuracy: 0.6825 - precision: 0.7862 - recall: 0.5829 - val_loss: 3705.8877 - val_accuracy: 0.1140 - val_precision: 0.1140 - val_recall: 0.1140\n","Epoch 63/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.9287 - accuracy: 0.6895 - precision: 0.7955 - recall: 0.5810 - val_loss: 5025.1357 - val_accuracy: 0.0937 - val_precision: 0.0937 - val_recall: 0.0937\n","Epoch 64/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.9135 - accuracy: 0.6912 - precision: 0.7929 - recall: 0.5881 - val_loss: 4821.7085 - val_accuracy: 0.1064 - val_precision: 0.1064 - val_recall: 0.1064\n","Epoch 65/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.9151 - accuracy: 0.7003 - precision: 0.7984 - recall: 0.6003 - val_loss: 3959.7224 - val_accuracy: 0.1206 - val_precision: 0.1206 - val_recall: 0.1206\n","Epoch 66/10000\n","185/185 [==============================] - 13s 71ms/step - loss: 0.9167 - accuracy: 0.7021 - precision: 0.7950 - recall: 0.6003 - val_loss: 4474.0244 - val_accuracy: 0.1135 - val_precision: 0.1135 - val_recall: 0.1135\n","Epoch 67/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.9136 - accuracy: 0.7008 - precision: 0.7939 - recall: 0.5969 - val_loss: 3717.1270 - val_accuracy: 0.1272 - val_precision: 0.1272 - val_recall: 0.1272\n","Epoch 68/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.9014 - accuracy: 0.6988 - precision: 0.7948 - recall: 0.6015 - val_loss: 4526.6021 - val_accuracy: 0.0998 - val_precision: 0.0998 - val_recall: 0.0998\n","Epoch 69/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.8943 - accuracy: 0.7072 - precision: 0.7952 - recall: 0.6094 - val_loss: 4926.6113 - val_accuracy: 0.0978 - val_precision: 0.0978 - val_recall: 0.0978\n","Epoch 70/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.8945 - accuracy: 0.7050 - precision: 0.8068 - recall: 0.6075 - val_loss: 5757.5225 - val_accuracy: 0.0811 - val_precision: 0.0811 - val_recall: 0.0811\n","Epoch 71/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.8917 - accuracy: 0.7042 - precision: 0.7999 - recall: 0.6140 - val_loss: 4943.8975 - val_accuracy: 0.1003 - val_precision: 0.1003 - val_recall: 0.1003\n","Epoch 72/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.8760 - accuracy: 0.7074 - precision: 0.8040 - recall: 0.6162 - val_loss: 4669.3457 - val_accuracy: 0.1109 - val_precision: 0.1109 - val_recall: 0.1109\n","Epoch 73/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.8734 - accuracy: 0.7092 - precision: 0.7975 - recall: 0.6136 - val_loss: 4651.8999 - val_accuracy: 0.1018 - val_precision: 0.1018 - val_recall: 0.1018\n","Epoch 74/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.8766 - accuracy: 0.7148 - precision: 0.8001 - recall: 0.6261 - val_loss: 3621.6467 - val_accuracy: 0.1251 - val_precision: 0.1251 - val_recall: 0.1251\n","Epoch 75/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.8526 - accuracy: 0.7148 - precision: 0.8085 - recall: 0.6205 - val_loss: 4875.1479 - val_accuracy: 0.1125 - val_precision: 0.1125 - val_recall: 0.1125\n","Epoch 76/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.8521 - accuracy: 0.7175 - precision: 0.8088 - recall: 0.6288 - val_loss: 5117.5391 - val_accuracy: 0.0963 - val_precision: 0.0963 - val_recall: 0.0963\n","Epoch 77/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.8450 - accuracy: 0.7185 - precision: 0.8050 - recall: 0.6319 - val_loss: 6192.8081 - val_accuracy: 0.0957 - val_precision: 0.0957 - val_recall: 0.0957\n","Epoch 78/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.8463 - accuracy: 0.7121 - precision: 0.8031 - recall: 0.6263 - val_loss: 6479.2900 - val_accuracy: 0.0795 - val_precision: 0.0795 - val_recall: 0.0795\n","Epoch 79/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.8628 - accuracy: 0.7074 - precision: 0.7977 - recall: 0.6254 - val_loss: 4754.8315 - val_accuracy: 0.1206 - val_precision: 0.1206 - val_recall: 0.1206\n","Epoch 80/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.8494 - accuracy: 0.7199 - precision: 0.8100 - recall: 0.6339 - val_loss: 5654.7446 - val_accuracy: 0.0851 - val_precision: 0.0851 - val_recall: 0.0851\n","Epoch 81/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.8222 - accuracy: 0.7241 - precision: 0.8119 - recall: 0.6390 - val_loss: 5597.1074 - val_accuracy: 0.0988 - val_precision: 0.0988 - val_recall: 0.0988\n","Epoch 82/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.8184 - accuracy: 0.7285 - precision: 0.8132 - recall: 0.6472 - val_loss: 5155.6011 - val_accuracy: 0.1033 - val_precision: 0.1033 - val_recall: 0.1033\n","Epoch 83/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.8320 - accuracy: 0.7223 - precision: 0.8081 - recall: 0.6376 - val_loss: 5417.3257 - val_accuracy: 0.0978 - val_precision: 0.0978 - val_recall: 0.0978\n","Epoch 84/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.7937 - accuracy: 0.7407 - precision: 0.8222 - recall: 0.6508 - val_loss: 4252.4741 - val_accuracy: 0.1226 - val_precision: 0.1226 - val_recall: 0.1226\n","Epoch 85/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.8008 - accuracy: 0.7275 - precision: 0.8154 - recall: 0.6530 - val_loss: 4722.1372 - val_accuracy: 0.1104 - val_precision: 0.1104 - val_recall: 0.1104\n","Epoch 86/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.7936 - accuracy: 0.7320 - precision: 0.8132 - recall: 0.6496 - val_loss: 5082.3164 - val_accuracy: 0.1074 - val_precision: 0.1074 - val_recall: 0.1074\n","Epoch 87/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.8018 - accuracy: 0.7315 - precision: 0.8202 - recall: 0.6520 - val_loss: 4078.6233 - val_accuracy: 0.1342 - val_precision: 0.1342 - val_recall: 0.1342\n","Epoch 88/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.7943 - accuracy: 0.7283 - precision: 0.8153 - recall: 0.6501 - val_loss: 5223.6323 - val_accuracy: 0.1246 - val_precision: 0.1246 - val_recall: 0.1246\n","Epoch 89/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.8044 - accuracy: 0.7320 - precision: 0.8149 - recall: 0.6545 - val_loss: 4436.9805 - val_accuracy: 0.1322 - val_precision: 0.1322 - val_recall: 0.1322\n","Epoch 90/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.7769 - accuracy: 0.7383 - precision: 0.8209 - recall: 0.6608 - val_loss: 5163.8496 - val_accuracy: 0.1190 - val_precision: 0.1190 - val_recall: 0.1190\n","Epoch 91/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.7577 - accuracy: 0.7435 - precision: 0.8245 - recall: 0.6653 - val_loss: 5013.0063 - val_accuracy: 0.1089 - val_precision: 0.1089 - val_recall: 0.1089\n","Epoch 92/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.7679 - accuracy: 0.7432 - precision: 0.8280 - recall: 0.6655 - val_loss: 5188.7720 - val_accuracy: 0.1069 - val_precision: 0.1069 - val_recall: 0.1069\n","Epoch 93/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.7283 - accuracy: 0.7589 - precision: 0.8363 - recall: 0.6837 - val_loss: 5717.5503 - val_accuracy: 0.1069 - val_precision: 0.1069 - val_recall: 0.1069\n","Epoch 94/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.7517 - accuracy: 0.7464 - precision: 0.8255 - recall: 0.6770 - val_loss: 6103.8345 - val_accuracy: 0.0993 - val_precision: 0.0993 - val_recall: 0.0993\n","Epoch 95/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.7422 - accuracy: 0.7508 - precision: 0.8223 - recall: 0.6849 - val_loss: 6311.1431 - val_accuracy: 0.0907 - val_precision: 0.0907 - val_recall: 0.0907\n","Epoch 96/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.7599 - accuracy: 0.7422 - precision: 0.8151 - recall: 0.6731 - val_loss: 5515.8066 - val_accuracy: 0.1221 - val_precision: 0.1221 - val_recall: 0.1221\n","Epoch 97/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.7302 - accuracy: 0.7500 - precision: 0.8279 - recall: 0.6793 - val_loss: 5741.8472 - val_accuracy: 0.1180 - val_precision: 0.1180 - val_recall: 0.1180\n","Epoch 98/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.7197 - accuracy: 0.7601 - precision: 0.8305 - recall: 0.6913 - val_loss: 5434.9595 - val_accuracy: 0.1185 - val_precision: 0.1185 - val_recall: 0.1185\n","Epoch 99/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.7340 - accuracy: 0.7493 - precision: 0.8234 - recall: 0.6800 - val_loss: 5610.9009 - val_accuracy: 0.1059 - val_precision: 0.1059 - val_recall: 0.1059\n","Epoch 100/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.7330 - accuracy: 0.7537 - precision: 0.8320 - recall: 0.6878 - val_loss: 5400.0977 - val_accuracy: 0.1109 - val_precision: 0.1109 - val_recall: 0.1109\n","Epoch 101/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.7339 - accuracy: 0.7550 - precision: 0.8267 - recall: 0.6841 - val_loss: 5142.8726 - val_accuracy: 0.1241 - val_precision: 0.1241 - val_recall: 0.1241\n","Epoch 102/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.7260 - accuracy: 0.7533 - precision: 0.8296 - recall: 0.6859 - val_loss: 5207.6646 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 103/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.6922 - accuracy: 0.7655 - precision: 0.8310 - recall: 0.6935 - val_loss: 4330.0811 - val_accuracy: 0.1272 - val_precision: 0.1272 - val_recall: 0.1272\n","Epoch 104/10000\n","185/185 [==============================] - 14s 73ms/step - loss: 0.6951 - accuracy: 0.7663 - precision: 0.8377 - recall: 0.7047 - val_loss: 5809.7891 - val_accuracy: 0.1196 - val_precision: 0.1196 - val_recall: 0.1196\n","Epoch 105/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.7100 - accuracy: 0.7584 - precision: 0.8305 - recall: 0.6956 - val_loss: 6108.6177 - val_accuracy: 0.1226 - val_precision: 0.1226 - val_recall: 0.1226\n","Epoch 106/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.6876 - accuracy: 0.7726 - precision: 0.8367 - recall: 0.7057 - val_loss: 6755.9004 - val_accuracy: 0.1059 - val_precision: 0.1059 - val_recall: 0.1059\n","Epoch 107/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.6901 - accuracy: 0.7734 - precision: 0.8380 - recall: 0.7027 - val_loss: 5509.7280 - val_accuracy: 0.1130 - val_precision: 0.1130 - val_recall: 0.1130\n","Epoch 108/10000\n","185/185 [==============================] - 14s 73ms/step - loss: 0.6834 - accuracy: 0.7696 - precision: 0.8358 - recall: 0.7025 - val_loss: 4477.6870 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 109/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.7039 - accuracy: 0.7667 - precision: 0.8299 - recall: 0.6991 - val_loss: 5547.9487 - val_accuracy: 0.1140 - val_precision: 0.1140 - val_recall: 0.1140\n","Epoch 110/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.6781 - accuracy: 0.7741 - precision: 0.8374 - recall: 0.7109 - val_loss: 6301.5649 - val_accuracy: 0.1089 - val_precision: 0.1089 - val_recall: 0.1089\n","Epoch 111/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.6669 - accuracy: 0.7707 - precision: 0.8398 - recall: 0.7084 - val_loss: 5548.7036 - val_accuracy: 0.1079 - val_precision: 0.1079 - val_recall: 0.1079\n","Epoch 112/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.6456 - accuracy: 0.7760 - precision: 0.8441 - recall: 0.7106 - val_loss: 5381.8184 - val_accuracy: 0.1104 - val_precision: 0.1104 - val_recall: 0.1104\n","Epoch 113/10000\n","185/185 [==============================] - 14s 73ms/step - loss: 0.6687 - accuracy: 0.7785 - precision: 0.8383 - recall: 0.7157 - val_loss: 5012.8394 - val_accuracy: 0.1236 - val_precision: 0.1236 - val_recall: 0.1236\n","Epoch 114/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.6606 - accuracy: 0.7809 - precision: 0.8440 - recall: 0.7204 - val_loss: 4452.8149 - val_accuracy: 0.1292 - val_precision: 0.1292 - val_recall: 0.1292\n","Epoch 115/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.6548 - accuracy: 0.7814 - precision: 0.8462 - recall: 0.7206 - val_loss: 5730.0547 - val_accuracy: 0.1069 - val_precision: 0.1069 - val_recall: 0.1069\n","Epoch 116/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.6491 - accuracy: 0.7816 - precision: 0.8465 - recall: 0.7260 - val_loss: 6375.9761 - val_accuracy: 0.0927 - val_precision: 0.0927 - val_recall: 0.0927\n","Epoch 117/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.6442 - accuracy: 0.7783 - precision: 0.8413 - recall: 0.7212 - val_loss: 5928.7236 - val_accuracy: 0.0932 - val_precision: 0.0932 - val_recall: 0.0932\n","Epoch 118/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.6436 - accuracy: 0.7787 - precision: 0.8434 - recall: 0.7233 - val_loss: 5775.2632 - val_accuracy: 0.1084 - val_precision: 0.1084 - val_recall: 0.1084\n","Epoch 119/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.6503 - accuracy: 0.7800 - precision: 0.8427 - recall: 0.7206 - val_loss: 5916.7280 - val_accuracy: 0.0998 - val_precision: 0.0998 - val_recall: 0.0998\n","Epoch 120/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.6319 - accuracy: 0.7883 - precision: 0.8493 - recall: 0.7304 - val_loss: 5590.8452 - val_accuracy: 0.1287 - val_precision: 0.1287 - val_recall: 0.1287\n","Epoch 121/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.6311 - accuracy: 0.7849 - precision: 0.8491 - recall: 0.7292 - val_loss: 5113.5986 - val_accuracy: 0.1266 - val_precision: 0.1266 - val_recall: 0.1266\n","Epoch 122/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.6339 - accuracy: 0.7812 - precision: 0.8366 - recall: 0.7260 - val_loss: 6105.7964 - val_accuracy: 0.1140 - val_precision: 0.1140 - val_recall: 0.1140\n","Epoch 123/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.6094 - accuracy: 0.7908 - precision: 0.8516 - recall: 0.7388 - val_loss: 4616.4756 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 124/10000\n","185/185 [==============================] - 14s 73ms/step - loss: 0.6250 - accuracy: 0.7913 - precision: 0.8483 - recall: 0.7348 - val_loss: 6135.0850 - val_accuracy: 0.1069 - val_precision: 0.1069 - val_recall: 0.1069\n","Epoch 125/10000\n","185/185 [==============================] - 14s 73ms/step - loss: 0.6304 - accuracy: 0.7861 - precision: 0.8443 - recall: 0.7358 - val_loss: 5492.0234 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 126/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.6079 - accuracy: 0.7946 - precision: 0.8530 - recall: 0.7424 - val_loss: 6337.7080 - val_accuracy: 0.1054 - val_precision: 0.1054 - val_recall: 0.1054\n","Epoch 127/10000\n","185/185 [==============================] - 14s 75ms/step - loss: 0.5983 - accuracy: 0.7995 - precision: 0.8553 - recall: 0.7420 - val_loss: 6519.9863 - val_accuracy: 0.0917 - val_precision: 0.0917 - val_recall: 0.0917\n","Epoch 128/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.6026 - accuracy: 0.7935 - precision: 0.8496 - recall: 0.7385 - val_loss: 5314.6206 - val_accuracy: 0.1074 - val_precision: 0.1074 - val_recall: 0.1074\n","Epoch 129/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.5906 - accuracy: 0.8008 - precision: 0.8555 - recall: 0.7442 - val_loss: 6556.8701 - val_accuracy: 0.1120 - val_precision: 0.1120 - val_recall: 0.1120\n","Epoch 130/10000\n","185/185 [==============================] - 14s 73ms/step - loss: 0.5927 - accuracy: 0.7952 - precision: 0.8562 - recall: 0.7476 - val_loss: 5844.3286 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 131/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.5902 - accuracy: 0.8030 - precision: 0.8485 - recall: 0.7496 - val_loss: 4915.7900 - val_accuracy: 0.1388 - val_precision: 0.1388 - val_recall: 0.1388\n","Epoch 132/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.6058 - accuracy: 0.7935 - precision: 0.8453 - recall: 0.7405 - val_loss: 5290.3438 - val_accuracy: 0.1160 - val_precision: 0.1160 - val_recall: 0.1160\n","Epoch 133/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.5930 - accuracy: 0.7946 - precision: 0.8519 - recall: 0.7515 - val_loss: 5380.7119 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 134/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.5855 - accuracy: 0.8052 - precision: 0.8594 - recall: 0.7508 - val_loss: 5860.0361 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 135/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.5704 - accuracy: 0.8067 - precision: 0.8633 - recall: 0.7555 - val_loss: 6107.3872 - val_accuracy: 0.1028 - val_precision: 0.1028 - val_recall: 0.1028\n","Epoch 136/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.5867 - accuracy: 0.8025 - precision: 0.8507 - recall: 0.7506 - val_loss: 5437.4341 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 137/10000\n","185/185 [==============================] - 14s 73ms/step - loss: 0.5772 - accuracy: 0.8037 - precision: 0.8561 - recall: 0.7567 - val_loss: 4728.8564 - val_accuracy: 0.1353 - val_precision: 0.1353 - val_recall: 0.1353\n","Epoch 138/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.5659 - accuracy: 0.8128 - precision: 0.8659 - recall: 0.7591 - val_loss: 5890.3242 - val_accuracy: 0.0963 - val_precision: 0.0963 - val_recall: 0.0963\n","Epoch 139/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.5532 - accuracy: 0.8074 - precision: 0.8612 - recall: 0.7640 - val_loss: 5465.9985 - val_accuracy: 0.1236 - val_precision: 0.1236 - val_recall: 0.1236\n","Epoch 140/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.5547 - accuracy: 0.8148 - precision: 0.8630 - recall: 0.7653 - val_loss: 7238.8335 - val_accuracy: 0.1059 - val_precision: 0.1059 - val_recall: 0.1059\n","Epoch 141/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.5489 - accuracy: 0.8160 - precision: 0.8658 - recall: 0.7674 - val_loss: 4613.0791 - val_accuracy: 0.1535 - val_precision: 0.1535 - val_recall: 0.1535\n","Epoch 142/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.5537 - accuracy: 0.8158 - precision: 0.8684 - recall: 0.7669 - val_loss: 5870.0127 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 143/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.5404 - accuracy: 0.8172 - precision: 0.8680 - recall: 0.7690 - val_loss: 6281.6987 - val_accuracy: 0.1155 - val_precision: 0.1155 - val_recall: 0.1155\n","Epoch 144/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.5720 - accuracy: 0.8094 - precision: 0.8578 - recall: 0.7613 - val_loss: 7407.4668 - val_accuracy: 0.1008 - val_precision: 0.1008 - val_recall: 0.1008\n","Epoch 145/10000\n","185/185 [==============================] - 13s 72ms/step - loss: 0.5532 - accuracy: 0.8116 - precision: 0.8595 - recall: 0.7672 - val_loss: 5217.8613 - val_accuracy: 0.1418 - val_precision: 0.1418 - val_recall: 0.1418\n","Epoch 146/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.5504 - accuracy: 0.8135 - precision: 0.8623 - recall: 0.7689 - val_loss: 5477.9312 - val_accuracy: 0.1327 - val_precision: 0.1327 - val_recall: 0.1327\n","Epoch 147/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.5343 - accuracy: 0.8155 - precision: 0.8632 - recall: 0.7679 - val_loss: 6397.5796 - val_accuracy: 0.0983 - val_precision: 0.0983 - val_recall: 0.0983\n","Epoch 148/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.5494 - accuracy: 0.8153 - precision: 0.8629 - recall: 0.7680 - val_loss: 7050.5986 - val_accuracy: 0.1160 - val_precision: 0.1160 - val_recall: 0.1160\n","Epoch 149/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.5039 - accuracy: 0.8236 - precision: 0.8777 - recall: 0.7794 - val_loss: 6666.7422 - val_accuracy: 0.1241 - val_precision: 0.1241 - val_recall: 0.1241\n","Epoch 150/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.5413 - accuracy: 0.8147 - precision: 0.8581 - recall: 0.7712 - val_loss: 6277.7725 - val_accuracy: 0.1064 - val_precision: 0.1064 - val_recall: 0.1064\n","Epoch 151/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.5342 - accuracy: 0.8157 - precision: 0.8636 - recall: 0.7753 - val_loss: 5605.0186 - val_accuracy: 0.1383 - val_precision: 0.1383 - val_recall: 0.1383\n","Epoch 152/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.5189 - accuracy: 0.8234 - precision: 0.8702 - recall: 0.7802 - val_loss: 7481.3521 - val_accuracy: 0.1049 - val_precision: 0.1049 - val_recall: 0.1049\n","Epoch 153/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.5319 - accuracy: 0.8196 - precision: 0.8652 - recall: 0.7783 - val_loss: 5818.8398 - val_accuracy: 0.1317 - val_precision: 0.1317 - val_recall: 0.1317\n","Epoch 154/10000\n","185/185 [==============================] - 13s 73ms/step - loss: 0.5110 - accuracy: 0.8243 - precision: 0.8715 - recall: 0.7834 - val_loss: 6683.0029 - val_accuracy: 0.1120 - val_precision: 0.1120 - val_recall: 0.1120\n","Epoch 155/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.5116 - accuracy: 0.8289 - precision: 0.8754 - recall: 0.7885 - val_loss: 6071.2588 - val_accuracy: 0.1282 - val_precision: 0.1282 - val_recall: 0.1282\n","Epoch 156/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.5149 - accuracy: 0.8299 - precision: 0.8752 - recall: 0.7881 - val_loss: 6105.4976 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 157/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.4908 - accuracy: 0.8331 - precision: 0.8743 - recall: 0.7934 - val_loss: 5994.9819 - val_accuracy: 0.1221 - val_precision: 0.1221 - val_recall: 0.1221\n","Epoch 158/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.5000 - accuracy: 0.8292 - precision: 0.8728 - recall: 0.7885 - val_loss: 5970.9912 - val_accuracy: 0.1231 - val_precision: 0.1231 - val_recall: 0.1231\n","Epoch 159/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.4784 - accuracy: 0.8336 - precision: 0.8827 - recall: 0.7908 - val_loss: 6744.9385 - val_accuracy: 0.1094 - val_precision: 0.1094 - val_recall: 0.1094\n","Epoch 160/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.4822 - accuracy: 0.8383 - precision: 0.8787 - recall: 0.7979 - val_loss: 8643.3838 - val_accuracy: 0.0957 - val_precision: 0.0957 - val_recall: 0.0957\n","Epoch 161/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.4981 - accuracy: 0.8319 - precision: 0.8778 - recall: 0.7886 - val_loss: 5697.4551 - val_accuracy: 0.1342 - val_precision: 0.1342 - val_recall: 0.1342\n","Epoch 162/10000\n","185/185 [==============================] - 15s 78ms/step - loss: 0.4791 - accuracy: 0.8405 - precision: 0.8758 - recall: 0.7973 - val_loss: 6887.3936 - val_accuracy: 0.1211 - val_precision: 0.1211 - val_recall: 0.1211\n","Epoch 163/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.4942 - accuracy: 0.8351 - precision: 0.8717 - recall: 0.7969 - val_loss: 6118.9507 - val_accuracy: 0.1236 - val_precision: 0.1236 - val_recall: 0.1236\n","Epoch 164/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.4775 - accuracy: 0.8387 - precision: 0.8774 - recall: 0.7959 - val_loss: 7042.3364 - val_accuracy: 0.1140 - val_precision: 0.1140 - val_recall: 0.1140\n","Epoch 165/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.4723 - accuracy: 0.8414 - precision: 0.8802 - recall: 0.8022 - val_loss: 6795.2925 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 166/10000\n","185/185 [==============================] - 14s 73ms/step - loss: 0.4977 - accuracy: 0.8348 - precision: 0.8778 - recall: 0.7946 - val_loss: 6219.6724 - val_accuracy: 0.1342 - val_precision: 0.1342 - val_recall: 0.1342\n","Epoch 167/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.4617 - accuracy: 0.8414 - precision: 0.8842 - recall: 0.8074 - val_loss: 6809.2295 - val_accuracy: 0.1120 - val_precision: 0.1120 - val_recall: 0.1120\n","Epoch 168/10000\n","185/185 [==============================] - 14s 73ms/step - loss: 0.4752 - accuracy: 0.8368 - precision: 0.8762 - recall: 0.7949 - val_loss: 6940.2383 - val_accuracy: 0.1008 - val_precision: 0.1008 - val_recall: 0.1008\n","Epoch 169/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.4720 - accuracy: 0.8415 - precision: 0.8798 - recall: 0.8027 - val_loss: 6501.5361 - val_accuracy: 0.1120 - val_precision: 0.1120 - val_recall: 0.1120\n","Epoch 170/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.4586 - accuracy: 0.8432 - precision: 0.8835 - recall: 0.8062 - val_loss: 7133.6440 - val_accuracy: 0.1079 - val_precision: 0.1079 - val_recall: 0.1079\n","Epoch 171/10000\n","185/185 [==============================] - 14s 73ms/step - loss: 0.4573 - accuracy: 0.8479 - precision: 0.8833 - recall: 0.8108 - val_loss: 6980.9058 - val_accuracy: 0.1241 - val_precision: 0.1241 - val_recall: 0.1241\n","Epoch 172/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.4727 - accuracy: 0.8375 - precision: 0.8744 - recall: 0.8033 - val_loss: 5361.6187 - val_accuracy: 0.1510 - val_precision: 0.1510 - val_recall: 0.1510\n","Epoch 173/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.4871 - accuracy: 0.8329 - precision: 0.8754 - recall: 0.7990 - val_loss: 5535.2358 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 174/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.4586 - accuracy: 0.8442 - precision: 0.8794 - recall: 0.8104 - val_loss: 5741.5615 - val_accuracy: 0.1302 - val_precision: 0.1302 - val_recall: 0.1302\n","Epoch 175/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.4401 - accuracy: 0.8473 - precision: 0.8839 - recall: 0.8126 - val_loss: 5747.8242 - val_accuracy: 0.1484 - val_precision: 0.1484 - val_recall: 0.1484\n","Epoch 176/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.4437 - accuracy: 0.8466 - precision: 0.8869 - recall: 0.8104 - val_loss: 7765.2896 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 177/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.4536 - accuracy: 0.8454 - precision: 0.8834 - recall: 0.8086 - val_loss: 6370.3423 - val_accuracy: 0.1494 - val_precision: 0.1494 - val_recall: 0.1494\n","Epoch 178/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.4343 - accuracy: 0.8498 - precision: 0.8884 - recall: 0.8153 - val_loss: 5378.0928 - val_accuracy: 0.1337 - val_precision: 0.1337 - val_recall: 0.1337\n","Epoch 179/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.4435 - accuracy: 0.8464 - precision: 0.8853 - recall: 0.8125 - val_loss: 7316.1182 - val_accuracy: 0.1069 - val_precision: 0.1069 - val_recall: 0.1069\n","Epoch 180/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.4347 - accuracy: 0.8540 - precision: 0.8859 - recall: 0.8184 - val_loss: 6810.6870 - val_accuracy: 0.1256 - val_precision: 0.1256 - val_recall: 0.1256\n","Epoch 181/10000\n","185/185 [==============================] - 14s 75ms/step - loss: 0.4416 - accuracy: 0.8542 - precision: 0.8868 - recall: 0.8209 - val_loss: 6140.9570 - val_accuracy: 0.1368 - val_precision: 0.1368 - val_recall: 0.1368\n","Epoch 182/10000\n","185/185 [==============================] - 14s 75ms/step - loss: 0.4368 - accuracy: 0.8503 - precision: 0.8850 - recall: 0.8180 - val_loss: 5735.0635 - val_accuracy: 0.1408 - val_precision: 0.1408 - val_recall: 0.1408\n","Epoch 183/10000\n","185/185 [==============================] - 14s 75ms/step - loss: 0.4285 - accuracy: 0.8554 - precision: 0.8918 - recall: 0.8255 - val_loss: 6931.8154 - val_accuracy: 0.1246 - val_precision: 0.1246 - val_recall: 0.1246\n","Epoch 184/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.4185 - accuracy: 0.8544 - precision: 0.8914 - recall: 0.8236 - val_loss: 8079.4287 - val_accuracy: 0.1114 - val_precision: 0.1114 - val_recall: 0.1114\n","Epoch 185/10000\n","185/185 [==============================] - 14s 75ms/step - loss: 0.4403 - accuracy: 0.8479 - precision: 0.8878 - recall: 0.8182 - val_loss: 6679.9604 - val_accuracy: 0.1104 - val_precision: 0.1104 - val_recall: 0.1104\n","Epoch 186/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.4319 - accuracy: 0.8520 - precision: 0.8847 - recall: 0.8169 - val_loss: 5415.9517 - val_accuracy: 0.1383 - val_precision: 0.1383 - val_recall: 0.1383\n","Epoch 187/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.4363 - accuracy: 0.8523 - precision: 0.8909 - recall: 0.8209 - val_loss: 7091.0771 - val_accuracy: 0.1342 - val_precision: 0.1342 - val_recall: 0.1342\n","Epoch 188/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.4309 - accuracy: 0.8525 - precision: 0.8896 - recall: 0.8226 - val_loss: 7346.0864 - val_accuracy: 0.1201 - val_precision: 0.1201 - val_recall: 0.1201\n","Epoch 189/10000\n","185/185 [==============================] - 14s 74ms/step - loss: 0.4178 - accuracy: 0.8576 - precision: 0.8904 - recall: 0.8250 - val_loss: 8298.9004 - val_accuracy: 0.0973 - val_precision: 0.0973 - val_recall: 0.0973\n","Epoch 190/10000\n","185/185 [==============================] - 14s 75ms/step - loss: 0.4142 - accuracy: 0.8610 - precision: 0.8956 - recall: 0.8331 - val_loss: 8260.9756 - val_accuracy: 0.1155 - val_precision: 0.1155 - val_recall: 0.1155\n","Epoch 191/10000\n","185/185 [==============================] - 14s 75ms/step - loss: 0.4160 - accuracy: 0.8593 - precision: 0.8908 - recall: 0.8297 - val_loss: 7504.7998 - val_accuracy: 0.1160 - val_precision: 0.1160 - val_recall: 0.1160\n","Epoch 192/10000\n","185/185 [==============================] - 14s 75ms/step - loss: 0.4095 - accuracy: 0.8591 - precision: 0.8892 - recall: 0.8311 - val_loss: 8175.9224 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 193/10000\n","185/185 [==============================] - 14s 75ms/step - loss: 0.4130 - accuracy: 0.8584 - precision: 0.8934 - recall: 0.8295 - val_loss: 7174.5986 - val_accuracy: 0.1266 - val_precision: 0.1266 - val_recall: 0.1266\n","Epoch 194/10000\n","185/185 [==============================] - 14s 75ms/step - loss: 0.4118 - accuracy: 0.8540 - precision: 0.8877 - recall: 0.8243 - val_loss: 7020.8047 - val_accuracy: 0.1185 - val_precision: 0.1185 - val_recall: 0.1185\n","Epoch 195/10000\n","185/185 [==============================] - 14s 75ms/step - loss: 0.3910 - accuracy: 0.8679 - precision: 0.9001 - recall: 0.8371 - val_loss: 7717.9785 - val_accuracy: 0.1033 - val_precision: 0.1033 - val_recall: 0.1033\n","Epoch 196/10000\n","185/185 [==============================] - 15s 84ms/step - loss: 0.3959 - accuracy: 0.8679 - precision: 0.8963 - recall: 0.8383 - val_loss: 5878.2871 - val_accuracy: 0.1484 - val_precision: 0.1484 - val_recall: 0.1484\n","Epoch 197/10000\n","185/185 [==============================] - 14s 75ms/step - loss: 0.3994 - accuracy: 0.8608 - precision: 0.8914 - recall: 0.8307 - val_loss: 7537.0503 - val_accuracy: 0.1241 - val_precision: 0.1241 - val_recall: 0.1241\n","Epoch 198/10000\n","185/185 [==============================] - 14s 75ms/step - loss: 0.4046 - accuracy: 0.8613 - precision: 0.8941 - recall: 0.8331 - val_loss: 6302.7227 - val_accuracy: 0.1505 - val_precision: 0.1505 - val_recall: 0.1505\n","Epoch 199/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.4172 - accuracy: 0.8542 - precision: 0.8869 - recall: 0.8267 - val_loss: 8406.9824 - val_accuracy: 0.1079 - val_precision: 0.1079 - val_recall: 0.1079\n","Epoch 200/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3912 - accuracy: 0.8674 - precision: 0.8999 - recall: 0.8371 - val_loss: 7756.6753 - val_accuracy: 0.1125 - val_precision: 0.1125 - val_recall: 0.1125\n","Epoch 201/10000\n","185/185 [==============================] - 14s 75ms/step - loss: 0.3929 - accuracy: 0.8719 - precision: 0.8973 - recall: 0.8412 - val_loss: 6075.7412 - val_accuracy: 0.1474 - val_precision: 0.1474 - val_recall: 0.1474\n","Epoch 202/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3963 - accuracy: 0.8616 - precision: 0.8942 - recall: 0.8327 - val_loss: 6912.4116 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 203/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.4082 - accuracy: 0.8608 - precision: 0.8947 - recall: 0.8336 - val_loss: 8384.5928 - val_accuracy: 0.1028 - val_precision: 0.1028 - val_recall: 0.1028\n","Epoch 204/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3754 - accuracy: 0.8733 - precision: 0.9003 - recall: 0.8452 - val_loss: 7413.7842 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 205/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3712 - accuracy: 0.8724 - precision: 0.9026 - recall: 0.8456 - val_loss: 6349.9604 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 206/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3872 - accuracy: 0.8716 - precision: 0.8998 - recall: 0.8449 - val_loss: 7301.3530 - val_accuracy: 0.1231 - val_precision: 0.1231 - val_recall: 0.1231\n","Epoch 207/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.3749 - accuracy: 0.8697 - precision: 0.9016 - recall: 0.8436 - val_loss: 5818.4980 - val_accuracy: 0.1550 - val_precision: 0.1550 - val_recall: 0.1550\n","Epoch 208/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3727 - accuracy: 0.8726 - precision: 0.9007 - recall: 0.8442 - val_loss: 7473.1436 - val_accuracy: 0.1185 - val_precision: 0.1185 - val_recall: 0.1185\n","Epoch 209/10000\n","185/185 [==============================] - 14s 75ms/step - loss: 0.3749 - accuracy: 0.8765 - precision: 0.9015 - recall: 0.8488 - val_loss: 7971.7681 - val_accuracy: 0.1226 - val_precision: 0.1226 - val_recall: 0.1226\n","Epoch 210/10000\n","185/185 [==============================] - 14s 75ms/step - loss: 0.3803 - accuracy: 0.8696 - precision: 0.8960 - recall: 0.8427 - val_loss: 9203.4580 - val_accuracy: 0.1059 - val_precision: 0.1059 - val_recall: 0.1059\n","Epoch 211/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3799 - accuracy: 0.8645 - precision: 0.8957 - recall: 0.8400 - val_loss: 7554.2354 - val_accuracy: 0.1206 - val_precision: 0.1206 - val_recall: 0.1206\n","Epoch 212/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3650 - accuracy: 0.8770 - precision: 0.9057 - recall: 0.8520 - val_loss: 8703.9756 - val_accuracy: 0.1008 - val_precision: 0.1008 - val_recall: 0.1008\n","Epoch 213/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.3579 - accuracy: 0.8775 - precision: 0.9066 - recall: 0.8474 - val_loss: 8475.3047 - val_accuracy: 0.1140 - val_precision: 0.1140 - val_recall: 0.1140\n","Epoch 214/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3713 - accuracy: 0.8768 - precision: 0.9011 - recall: 0.8517 - val_loss: 7548.6855 - val_accuracy: 0.1241 - val_precision: 0.1241 - val_recall: 0.1241\n","Epoch 215/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3831 - accuracy: 0.8731 - precision: 0.9006 - recall: 0.8515 - val_loss: 7491.8677 - val_accuracy: 0.1266 - val_precision: 0.1266 - val_recall: 0.1266\n","Epoch 216/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3559 - accuracy: 0.8770 - precision: 0.9039 - recall: 0.8513 - val_loss: 9238.9814 - val_accuracy: 0.1074 - val_precision: 0.1074 - val_recall: 0.1074\n","Epoch 217/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3641 - accuracy: 0.8777 - precision: 0.9053 - recall: 0.8491 - val_loss: 6644.3418 - val_accuracy: 0.1464 - val_precision: 0.1464 - val_recall: 0.1464\n","Epoch 218/10000\n","185/185 [==============================] - 14s 75ms/step - loss: 0.3579 - accuracy: 0.8809 - precision: 0.9060 - recall: 0.8537 - val_loss: 7066.4229 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 219/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3622 - accuracy: 0.8702 - precision: 0.9011 - recall: 0.8468 - val_loss: 8616.0996 - val_accuracy: 0.1074 - val_precision: 0.1074 - val_recall: 0.1074\n","Epoch 220/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3468 - accuracy: 0.8821 - precision: 0.9079 - recall: 0.8576 - val_loss: 8469.9385 - val_accuracy: 0.1206 - val_precision: 0.1206 - val_recall: 0.1206\n","Epoch 221/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3382 - accuracy: 0.8851 - precision: 0.9102 - recall: 0.8633 - val_loss: 8418.4775 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 222/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3649 - accuracy: 0.8746 - precision: 0.9017 - recall: 0.8537 - val_loss: 7293.9683 - val_accuracy: 0.1256 - val_precision: 0.1256 - val_recall: 0.1256\n","Epoch 223/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3458 - accuracy: 0.8816 - precision: 0.9078 - recall: 0.8552 - val_loss: 10882.5654 - val_accuracy: 0.0836 - val_precision: 0.0836 - val_recall: 0.0836\n","Epoch 224/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3514 - accuracy: 0.8802 - precision: 0.9069 - recall: 0.8537 - val_loss: 10583.5361 - val_accuracy: 0.0811 - val_precision: 0.0811 - val_recall: 0.0811\n","Epoch 225/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3319 - accuracy: 0.8905 - precision: 0.9127 - recall: 0.8650 - val_loss: 9043.7236 - val_accuracy: 0.1094 - val_precision: 0.1094 - val_recall: 0.1094\n","Epoch 226/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3309 - accuracy: 0.8868 - precision: 0.9115 - recall: 0.8650 - val_loss: 7801.3354 - val_accuracy: 0.1251 - val_precision: 0.1251 - val_recall: 0.1251\n","Epoch 227/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3369 - accuracy: 0.8849 - precision: 0.9125 - recall: 0.8638 - val_loss: 6969.7041 - val_accuracy: 0.1363 - val_precision: 0.1363 - val_recall: 0.1363\n","Epoch 228/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3424 - accuracy: 0.8814 - precision: 0.9051 - recall: 0.8591 - val_loss: 6436.5996 - val_accuracy: 0.1565 - val_precision: 0.1565 - val_recall: 0.1565\n","Epoch 229/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.3396 - accuracy: 0.8821 - precision: 0.9065 - recall: 0.8599 - val_loss: 8586.2500 - val_accuracy: 0.1059 - val_precision: 0.1059 - val_recall: 0.1059\n","Epoch 230/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3491 - accuracy: 0.8789 - precision: 0.9039 - recall: 0.8550 - val_loss: 7839.2417 - val_accuracy: 0.1079 - val_precision: 0.1079 - val_recall: 0.1079\n","Epoch 231/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3322 - accuracy: 0.8829 - precision: 0.9090 - recall: 0.8638 - val_loss: 7996.7046 - val_accuracy: 0.1049 - val_precision: 0.1049 - val_recall: 0.1049\n","Epoch 232/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3318 - accuracy: 0.8909 - precision: 0.9109 - recall: 0.8669 - val_loss: 6609.9136 - val_accuracy: 0.1418 - val_precision: 0.1418 - val_recall: 0.1418\n","Epoch 233/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.3360 - accuracy: 0.8828 - precision: 0.9076 - recall: 0.8599 - val_loss: 7810.3809 - val_accuracy: 0.1297 - val_precision: 0.1297 - val_recall: 0.1297\n","Epoch 234/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.3313 - accuracy: 0.8868 - precision: 0.9088 - recall: 0.8674 - val_loss: 8562.1660 - val_accuracy: 0.1130 - val_precision: 0.1130 - val_recall: 0.1130\n","Epoch 235/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3251 - accuracy: 0.8892 - precision: 0.9126 - recall: 0.8692 - val_loss: 7781.7124 - val_accuracy: 0.1322 - val_precision: 0.1322 - val_recall: 0.1322\n","Epoch 236/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.3199 - accuracy: 0.8925 - precision: 0.9151 - recall: 0.8746 - val_loss: 6787.8584 - val_accuracy: 0.1378 - val_precision: 0.1378 - val_recall: 0.1378\n","Epoch 237/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3219 - accuracy: 0.8841 - precision: 0.9058 - recall: 0.8606 - val_loss: 9721.9141 - val_accuracy: 0.0866 - val_precision: 0.0866 - val_recall: 0.0866\n","Epoch 238/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.3306 - accuracy: 0.8910 - precision: 0.9111 - recall: 0.8709 - val_loss: 7338.1699 - val_accuracy: 0.1302 - val_precision: 0.1302 - val_recall: 0.1302\n","Epoch 239/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3277 - accuracy: 0.8924 - precision: 0.9121 - recall: 0.8726 - val_loss: 6842.5181 - val_accuracy: 0.1246 - val_precision: 0.1246 - val_recall: 0.1246\n","Epoch 240/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3268 - accuracy: 0.8841 - precision: 0.9069 - recall: 0.8659 - val_loss: 9365.3320 - val_accuracy: 0.1054 - val_precision: 0.1054 - val_recall: 0.1054\n","Epoch 241/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2929 - accuracy: 0.9015 - precision: 0.9245 - recall: 0.8838 - val_loss: 7800.4155 - val_accuracy: 0.1099 - val_precision: 0.1099 - val_recall: 0.1099\n","Epoch 242/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.3113 - accuracy: 0.8931 - precision: 0.9138 - recall: 0.8735 - val_loss: 7661.3838 - val_accuracy: 0.1241 - val_precision: 0.1241 - val_recall: 0.1241\n","Epoch 243/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.3234 - accuracy: 0.8941 - precision: 0.9177 - recall: 0.8719 - val_loss: 8938.1162 - val_accuracy: 0.1099 - val_precision: 0.1099 - val_recall: 0.1099\n","Epoch 244/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.3070 - accuracy: 0.8953 - precision: 0.9152 - recall: 0.8773 - val_loss: 8728.4688 - val_accuracy: 0.1114 - val_precision: 0.1114 - val_recall: 0.1114\n","Epoch 245/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.3180 - accuracy: 0.8876 - precision: 0.9071 - recall: 0.8694 - val_loss: 9304.8350 - val_accuracy: 0.0917 - val_precision: 0.0917 - val_recall: 0.0917\n","Epoch 246/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.3254 - accuracy: 0.8909 - precision: 0.9126 - recall: 0.8699 - val_loss: 8613.5967 - val_accuracy: 0.1049 - val_precision: 0.1049 - val_recall: 0.1049\n","Epoch 247/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.3054 - accuracy: 0.8937 - precision: 0.9153 - recall: 0.8748 - val_loss: 7634.7461 - val_accuracy: 0.1297 - val_precision: 0.1297 - val_recall: 0.1297\n","Epoch 248/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3160 - accuracy: 0.8910 - precision: 0.9156 - recall: 0.8708 - val_loss: 8990.5732 - val_accuracy: 0.1206 - val_precision: 0.1206 - val_recall: 0.1206\n","Epoch 249/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3078 - accuracy: 0.8942 - precision: 0.9171 - recall: 0.8751 - val_loss: 8874.7578 - val_accuracy: 0.1074 - val_precision: 0.1074 - val_recall: 0.1074\n","Epoch 250/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3102 - accuracy: 0.8941 - precision: 0.9155 - recall: 0.8750 - val_loss: 8031.9463 - val_accuracy: 0.1201 - val_precision: 0.1201 - val_recall: 0.1201\n","Epoch 251/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.2958 - accuracy: 0.9022 - precision: 0.9240 - recall: 0.8811 - val_loss: 8933.4062 - val_accuracy: 0.1049 - val_precision: 0.1049 - val_recall: 0.1049\n","Epoch 252/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.3098 - accuracy: 0.8949 - precision: 0.9156 - recall: 0.8773 - val_loss: 8148.9380 - val_accuracy: 0.1185 - val_precision: 0.1185 - val_recall: 0.1185\n","Epoch 253/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2837 - accuracy: 0.9025 - precision: 0.9221 - recall: 0.8839 - val_loss: 8271.0391 - val_accuracy: 0.1246 - val_precision: 0.1246 - val_recall: 0.1246\n","Epoch 254/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.3007 - accuracy: 0.8976 - precision: 0.9174 - recall: 0.8795 - val_loss: 8335.8828 - val_accuracy: 0.1114 - val_precision: 0.1114 - val_recall: 0.1114\n","Epoch 255/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.2952 - accuracy: 0.9007 - precision: 0.9221 - recall: 0.8821 - val_loss: 9185.9678 - val_accuracy: 0.1256 - val_precision: 0.1256 - val_recall: 0.1256\n","Epoch 256/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.2917 - accuracy: 0.9013 - precision: 0.9214 - recall: 0.8838 - val_loss: 8950.6367 - val_accuracy: 0.1079 - val_precision: 0.1079 - val_recall: 0.1079\n","Epoch 257/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2989 - accuracy: 0.8964 - precision: 0.9167 - recall: 0.8799 - val_loss: 7487.7671 - val_accuracy: 0.1322 - val_precision: 0.1322 - val_recall: 0.1322\n","Epoch 258/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2917 - accuracy: 0.9005 - precision: 0.9219 - recall: 0.8829 - val_loss: 7178.9487 - val_accuracy: 0.1510 - val_precision: 0.1510 - val_recall: 0.1510\n","Epoch 259/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.3019 - accuracy: 0.9002 - precision: 0.9192 - recall: 0.8822 - val_loss: 7191.4980 - val_accuracy: 0.1434 - val_precision: 0.1434 - val_recall: 0.1434\n","Epoch 260/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.2887 - accuracy: 0.9029 - precision: 0.9218 - recall: 0.8843 - val_loss: 8206.5420 - val_accuracy: 0.1180 - val_precision: 0.1180 - val_recall: 0.1180\n","Epoch 261/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.2964 - accuracy: 0.8983 - precision: 0.9159 - recall: 0.8792 - val_loss: 7466.9536 - val_accuracy: 0.1596 - val_precision: 0.1596 - val_recall: 0.1596\n","Epoch 262/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2877 - accuracy: 0.9020 - precision: 0.9202 - recall: 0.8849 - val_loss: 8370.4590 - val_accuracy: 0.1190 - val_precision: 0.1190 - val_recall: 0.1190\n","Epoch 263/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.2804 - accuracy: 0.9047 - precision: 0.9209 - recall: 0.8868 - val_loss: 8115.7139 - val_accuracy: 0.1368 - val_precision: 0.1368 - val_recall: 0.1368\n","Epoch 264/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2745 - accuracy: 0.9108 - precision: 0.9271 - recall: 0.8939 - val_loss: 7968.3120 - val_accuracy: 0.1302 - val_precision: 0.1302 - val_recall: 0.1302\n","Epoch 265/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2750 - accuracy: 0.9062 - precision: 0.9258 - recall: 0.8893 - val_loss: 9182.5801 - val_accuracy: 0.1130 - val_precision: 0.1130 - val_recall: 0.1130\n","Epoch 266/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2749 - accuracy: 0.9029 - precision: 0.9236 - recall: 0.8858 - val_loss: 9109.1660 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 267/10000\n","185/185 [==============================] - 14s 76ms/step - loss: 0.2582 - accuracy: 0.9138 - precision: 0.9312 - recall: 0.8968 - val_loss: 7799.2007 - val_accuracy: 0.1292 - val_precision: 0.1292 - val_recall: 0.1292\n","Epoch 268/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2707 - accuracy: 0.9042 - precision: 0.9208 - recall: 0.8900 - val_loss: 10323.2188 - val_accuracy: 0.1013 - val_precision: 0.1013 - val_recall: 0.1013\n","Epoch 269/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2726 - accuracy: 0.9062 - precision: 0.9242 - recall: 0.8914 - val_loss: 10385.6592 - val_accuracy: 0.1044 - val_precision: 0.1044 - val_recall: 0.1044\n","Epoch 270/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2749 - accuracy: 0.9069 - precision: 0.9237 - recall: 0.8934 - val_loss: 8940.8877 - val_accuracy: 0.1084 - val_precision: 0.1084 - val_recall: 0.1084\n","Epoch 271/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2652 - accuracy: 0.9111 - precision: 0.9294 - recall: 0.8958 - val_loss: 8082.3867 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 272/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2616 - accuracy: 0.9076 - precision: 0.9242 - recall: 0.8920 - val_loss: 8143.7378 - val_accuracy: 0.1241 - val_precision: 0.1241 - val_recall: 0.1241\n","Epoch 273/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2692 - accuracy: 0.9081 - precision: 0.9248 - recall: 0.8910 - val_loss: 9117.6172 - val_accuracy: 0.1408 - val_precision: 0.1408 - val_recall: 0.1408\n","Epoch 274/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2467 - accuracy: 0.9142 - precision: 0.9326 - recall: 0.8993 - val_loss: 8949.7471 - val_accuracy: 0.1231 - val_precision: 0.1231 - val_recall: 0.1231\n","Epoch 275/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2623 - accuracy: 0.9106 - precision: 0.9264 - recall: 0.8927 - val_loss: 8586.2686 - val_accuracy: 0.1327 - val_precision: 0.1327 - val_recall: 0.1327\n","Epoch 276/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2571 - accuracy: 0.9088 - precision: 0.9281 - recall: 0.8944 - val_loss: 9288.0605 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 277/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2644 - accuracy: 0.9084 - precision: 0.9276 - recall: 0.8934 - val_loss: 9538.0420 - val_accuracy: 0.1044 - val_precision: 0.1044 - val_recall: 0.1044\n","Epoch 278/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2524 - accuracy: 0.9108 - precision: 0.9277 - recall: 0.8947 - val_loss: 8113.9360 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 279/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.2607 - accuracy: 0.9106 - precision: 0.9282 - recall: 0.8953 - val_loss: 7581.0137 - val_accuracy: 0.1530 - val_precision: 0.1530 - val_recall: 0.1530\n","Epoch 280/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2515 - accuracy: 0.9118 - precision: 0.9296 - recall: 0.8988 - val_loss: 8223.2627 - val_accuracy: 0.1398 - val_precision: 0.1398 - val_recall: 0.1398\n","Epoch 281/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2512 - accuracy: 0.9137 - precision: 0.9284 - recall: 0.8956 - val_loss: 8497.2686 - val_accuracy: 0.1185 - val_precision: 0.1185 - val_recall: 0.1185\n","Epoch 282/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2415 - accuracy: 0.9208 - precision: 0.9351 - recall: 0.9051 - val_loss: 9428.1953 - val_accuracy: 0.1135 - val_precision: 0.1135 - val_recall: 0.1135\n","Epoch 283/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2419 - accuracy: 0.9219 - precision: 0.9355 - recall: 0.9069 - val_loss: 8848.8926 - val_accuracy: 0.1185 - val_precision: 0.1185 - val_recall: 0.1185\n","Epoch 284/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2587 - accuracy: 0.9116 - precision: 0.9257 - recall: 0.8961 - val_loss: 9397.2461 - val_accuracy: 0.1074 - val_precision: 0.1074 - val_recall: 0.1074\n","Epoch 285/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2540 - accuracy: 0.9089 - precision: 0.9262 - recall: 0.8966 - val_loss: 9237.2998 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 286/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2587 - accuracy: 0.9149 - precision: 0.9305 - recall: 0.9000 - val_loss: 11627.9111 - val_accuracy: 0.1018 - val_precision: 0.1018 - val_recall: 0.1018\n","Epoch 287/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2565 - accuracy: 0.9143 - precision: 0.9309 - recall: 0.8985 - val_loss: 9343.2812 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 288/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2597 - accuracy: 0.9115 - precision: 0.9259 - recall: 0.8978 - val_loss: 8688.1104 - val_accuracy: 0.1307 - val_precision: 0.1307 - val_recall: 0.1307\n","Epoch 289/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2583 - accuracy: 0.9135 - precision: 0.9286 - recall: 0.8993 - val_loss: 9895.0879 - val_accuracy: 0.1201 - val_precision: 0.1201 - val_recall: 0.1201\n","Epoch 290/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2631 - accuracy: 0.9160 - precision: 0.9320 - recall: 0.8978 - val_loss: 8598.0469 - val_accuracy: 0.1266 - val_precision: 0.1266 - val_recall: 0.1266\n","Epoch 291/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2604 - accuracy: 0.9123 - precision: 0.9294 - recall: 0.9005 - val_loss: 9575.1670 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 292/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2569 - accuracy: 0.9093 - precision: 0.9265 - recall: 0.8969 - val_loss: 10280.7422 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 293/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2394 - accuracy: 0.9191 - precision: 0.9310 - recall: 0.9025 - val_loss: 9891.9990 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 294/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2431 - accuracy: 0.9199 - precision: 0.9335 - recall: 0.9066 - val_loss: 8471.8525 - val_accuracy: 0.1282 - val_precision: 0.1282 - val_recall: 0.1282\n","Epoch 295/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2421 - accuracy: 0.9170 - precision: 0.9297 - recall: 0.9005 - val_loss: 8650.8887 - val_accuracy: 0.1104 - val_precision: 0.1104 - val_recall: 0.1104\n","Epoch 296/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.2502 - accuracy: 0.9105 - precision: 0.9276 - recall: 0.8961 - val_loss: 8674.2617 - val_accuracy: 0.1104 - val_precision: 0.1104 - val_recall: 0.1104\n","Epoch 297/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2411 - accuracy: 0.9179 - precision: 0.9323 - recall: 0.9056 - val_loss: 8534.6982 - val_accuracy: 0.1368 - val_precision: 0.1368 - val_recall: 0.1368\n","Epoch 298/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2461 - accuracy: 0.9150 - precision: 0.9276 - recall: 0.9005 - val_loss: 8538.5459 - val_accuracy: 0.1272 - val_precision: 0.1272 - val_recall: 0.1272\n","Epoch 299/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2415 - accuracy: 0.9152 - precision: 0.9291 - recall: 0.8985 - val_loss: 9044.1328 - val_accuracy: 0.1251 - val_precision: 0.1251 - val_recall: 0.1251\n","Epoch 300/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2458 - accuracy: 0.9145 - precision: 0.9291 - recall: 0.9017 - val_loss: 10389.3926 - val_accuracy: 0.1104 - val_precision: 0.1104 - val_recall: 0.1104\n","Epoch 301/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2493 - accuracy: 0.9127 - precision: 0.9270 - recall: 0.9015 - val_loss: 9487.5381 - val_accuracy: 0.1160 - val_precision: 0.1160 - val_recall: 0.1160\n","Epoch 302/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2571 - accuracy: 0.9121 - precision: 0.9259 - recall: 0.8968 - val_loss: 8571.4434 - val_accuracy: 0.1302 - val_precision: 0.1302 - val_recall: 0.1302\n","Epoch 303/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2329 - accuracy: 0.9186 - precision: 0.9344 - recall: 0.9051 - val_loss: 8671.5879 - val_accuracy: 0.1140 - val_precision: 0.1140 - val_recall: 0.1140\n","Epoch 304/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2279 - accuracy: 0.9199 - precision: 0.9324 - recall: 0.9071 - val_loss: 9283.3936 - val_accuracy: 0.1140 - val_precision: 0.1140 - val_recall: 0.1140\n","Epoch 305/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2289 - accuracy: 0.9263 - precision: 0.9383 - recall: 0.9115 - val_loss: 8977.3594 - val_accuracy: 0.1312 - val_precision: 0.1312 - val_recall: 0.1312\n","Epoch 306/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2243 - accuracy: 0.9216 - precision: 0.9340 - recall: 0.9116 - val_loss: 10440.8740 - val_accuracy: 0.1018 - val_precision: 0.1018 - val_recall: 0.1018\n","Epoch 307/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2200 - accuracy: 0.9241 - precision: 0.9367 - recall: 0.9100 - val_loss: 8757.2803 - val_accuracy: 0.1266 - val_precision: 0.1266 - val_recall: 0.1266\n","Epoch 308/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2236 - accuracy: 0.9246 - precision: 0.9354 - recall: 0.9120 - val_loss: 8637.7451 - val_accuracy: 0.1292 - val_precision: 0.1292 - val_recall: 0.1292\n","Epoch 309/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2216 - accuracy: 0.9233 - precision: 0.9369 - recall: 0.9111 - val_loss: 8852.4961 - val_accuracy: 0.1221 - val_precision: 0.1221 - val_recall: 0.1221\n","Epoch 310/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2331 - accuracy: 0.9226 - precision: 0.9365 - recall: 0.9071 - val_loss: 9543.7070 - val_accuracy: 0.1033 - val_precision: 0.1033 - val_recall: 0.1033\n","Epoch 311/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2353 - accuracy: 0.9181 - precision: 0.9312 - recall: 0.9062 - val_loss: 7707.5225 - val_accuracy: 0.1393 - val_precision: 0.1393 - val_recall: 0.1393\n","Epoch 312/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.2400 - accuracy: 0.9152 - precision: 0.9275 - recall: 0.9040 - val_loss: 10327.1475 - val_accuracy: 0.1044 - val_precision: 0.1044 - val_recall: 0.1044\n","Epoch 313/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2144 - accuracy: 0.9279 - precision: 0.9379 - recall: 0.9181 - val_loss: 9839.6641 - val_accuracy: 0.1044 - val_precision: 0.1044 - val_recall: 0.1044\n","Epoch 314/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2283 - accuracy: 0.9230 - precision: 0.9393 - recall: 0.9120 - val_loss: 8592.0977 - val_accuracy: 0.1591 - val_precision: 0.1591 - val_recall: 0.1591\n","Epoch 315/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2096 - accuracy: 0.9302 - precision: 0.9426 - recall: 0.9208 - val_loss: 10246.1260 - val_accuracy: 0.0993 - val_precision: 0.0993 - val_recall: 0.0993\n","Epoch 316/10000\n","185/185 [==============================] - 14s 77ms/step - loss: 0.2192 - accuracy: 0.9231 - precision: 0.9340 - recall: 0.9127 - val_loss: 8085.1909 - val_accuracy: 0.1246 - val_precision: 0.1246 - val_recall: 0.1246\n","Epoch 317/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2269 - accuracy: 0.9221 - precision: 0.9350 - recall: 0.9116 - val_loss: 9064.1045 - val_accuracy: 0.1353 - val_precision: 0.1353 - val_recall: 0.1353\n","Epoch 318/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2134 - accuracy: 0.9302 - precision: 0.9426 - recall: 0.9214 - val_loss: 9425.4570 - val_accuracy: 0.1094 - val_precision: 0.1094 - val_recall: 0.1094\n","Epoch 319/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2203 - accuracy: 0.9268 - precision: 0.9404 - recall: 0.9143 - val_loss: 9700.7627 - val_accuracy: 0.1211 - val_precision: 0.1211 - val_recall: 0.1211\n","Epoch 320/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2017 - accuracy: 0.9282 - precision: 0.9444 - recall: 0.9160 - val_loss: 11360.4277 - val_accuracy: 0.0927 - val_precision: 0.0927 - val_recall: 0.0927\n","Epoch 321/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2187 - accuracy: 0.9270 - precision: 0.9391 - recall: 0.9169 - val_loss: 9569.1641 - val_accuracy: 0.1317 - val_precision: 0.1317 - val_recall: 0.1317\n","Epoch 322/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.2179 - accuracy: 0.9253 - precision: 0.9380 - recall: 0.9128 - val_loss: 9370.4639 - val_accuracy: 0.1226 - val_precision: 0.1226 - val_recall: 0.1226\n","Epoch 323/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.2170 - accuracy: 0.9211 - precision: 0.9357 - recall: 0.9100 - val_loss: 10082.8711 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 324/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.1996 - accuracy: 0.9326 - precision: 0.9426 - recall: 0.9218 - val_loss: 9576.1416 - val_accuracy: 0.1251 - val_precision: 0.1251 - val_recall: 0.1251\n","Epoch 325/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.2097 - accuracy: 0.9270 - precision: 0.9400 - recall: 0.9160 - val_loss: 10101.8418 - val_accuracy: 0.0922 - val_precision: 0.0922 - val_recall: 0.0922\n","Epoch 326/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.2152 - accuracy: 0.9257 - precision: 0.9368 - recall: 0.9135 - val_loss: 9048.1006 - val_accuracy: 0.1332 - val_precision: 0.1332 - val_recall: 0.1332\n","Epoch 327/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2144 - accuracy: 0.9250 - precision: 0.9332 - recall: 0.9137 - val_loss: 10552.8271 - val_accuracy: 0.1206 - val_precision: 0.1206 - val_recall: 0.1206\n","Epoch 328/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2082 - accuracy: 0.9282 - precision: 0.9405 - recall: 0.9187 - val_loss: 10021.6582 - val_accuracy: 0.1185 - val_precision: 0.1185 - val_recall: 0.1185\n","Epoch 329/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.2220 - accuracy: 0.9225 - precision: 0.9373 - recall: 0.9138 - val_loss: 8325.3320 - val_accuracy: 0.1373 - val_precision: 0.1373 - val_recall: 0.1373\n","Epoch 330/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2024 - accuracy: 0.9306 - precision: 0.9412 - recall: 0.9194 - val_loss: 10464.2363 - val_accuracy: 0.1201 - val_precision: 0.1201 - val_recall: 0.1201\n","Epoch 331/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2211 - accuracy: 0.9231 - precision: 0.9352 - recall: 0.9118 - val_loss: 9786.6768 - val_accuracy: 0.1272 - val_precision: 0.1272 - val_recall: 0.1272\n","Epoch 332/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2112 - accuracy: 0.9302 - precision: 0.9405 - recall: 0.9191 - val_loss: 9867.2178 - val_accuracy: 0.1155 - val_precision: 0.1155 - val_recall: 0.1155\n","Epoch 333/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2076 - accuracy: 0.9279 - precision: 0.9405 - recall: 0.9184 - val_loss: 12208.7119 - val_accuracy: 0.0957 - val_precision: 0.0957 - val_recall: 0.0957\n","Epoch 334/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.2167 - accuracy: 0.9292 - precision: 0.9399 - recall: 0.9169 - val_loss: 10389.4375 - val_accuracy: 0.0998 - val_precision: 0.0998 - val_recall: 0.0998\n","Epoch 335/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.1990 - accuracy: 0.9324 - precision: 0.9432 - recall: 0.9206 - val_loss: 10797.0723 - val_accuracy: 0.1241 - val_precision: 0.1241 - val_recall: 0.1241\n","Epoch 336/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.1999 - accuracy: 0.9326 - precision: 0.9430 - recall: 0.9218 - val_loss: 8498.6436 - val_accuracy: 0.1292 - val_precision: 0.1292 - val_recall: 0.1292\n","Epoch 337/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.1994 - accuracy: 0.9299 - precision: 0.9445 - recall: 0.9233 - val_loss: 8242.7139 - val_accuracy: 0.1413 - val_precision: 0.1413 - val_recall: 0.1413\n","Epoch 338/10000\n","185/185 [==============================] - 15s 78ms/step - loss: 0.2048 - accuracy: 0.9299 - precision: 0.9418 - recall: 0.9194 - val_loss: 9502.7773 - val_accuracy: 0.1332 - val_precision: 0.1332 - val_recall: 0.1332\n","Epoch 339/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.1921 - accuracy: 0.9360 - precision: 0.9475 - recall: 0.9262 - val_loss: 9771.0225 - val_accuracy: 0.1282 - val_precision: 0.1282 - val_recall: 0.1282\n","Epoch 340/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1855 - accuracy: 0.9341 - precision: 0.9444 - recall: 0.9236 - val_loss: 10958.0781 - val_accuracy: 0.1084 - val_precision: 0.1084 - val_recall: 0.1084\n","Epoch 341/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.2014 - accuracy: 0.9265 - precision: 0.9401 - recall: 0.9169 - val_loss: 11228.2764 - val_accuracy: 0.1180 - val_precision: 0.1180 - val_recall: 0.1180\n","Epoch 342/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.2014 - accuracy: 0.9314 - precision: 0.9421 - recall: 0.9216 - val_loss: 7678.2153 - val_accuracy: 0.1677 - val_precision: 0.1677 - val_recall: 0.1677\n","Epoch 343/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.2078 - accuracy: 0.9328 - precision: 0.9437 - recall: 0.9235 - val_loss: 8805.8047 - val_accuracy: 0.1474 - val_precision: 0.1474 - val_recall: 0.1474\n","Epoch 344/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1973 - accuracy: 0.9311 - precision: 0.9424 - recall: 0.9203 - val_loss: 10786.4658 - val_accuracy: 0.1221 - val_precision: 0.1221 - val_recall: 0.1221\n","Epoch 345/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.1941 - accuracy: 0.9311 - precision: 0.9427 - recall: 0.9208 - val_loss: 8756.7236 - val_accuracy: 0.1403 - val_precision: 0.1403 - val_recall: 0.1403\n","Epoch 346/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1970 - accuracy: 0.9328 - precision: 0.9432 - recall: 0.9223 - val_loss: 10071.0527 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 347/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1858 - accuracy: 0.9334 - precision: 0.9450 - recall: 0.9231 - val_loss: 11009.9434 - val_accuracy: 0.1120 - val_precision: 0.1120 - val_recall: 0.1120\n","Epoch 348/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1988 - accuracy: 0.9321 - precision: 0.9416 - recall: 0.9230 - val_loss: 10429.0371 - val_accuracy: 0.1246 - val_precision: 0.1246 - val_recall: 0.1246\n","Epoch 349/10000\n","185/185 [==============================] - 15s 78ms/step - loss: 0.1965 - accuracy: 0.9333 - precision: 0.9402 - recall: 0.9248 - val_loss: 10411.4795 - val_accuracy: 0.0968 - val_precision: 0.0968 - val_recall: 0.0968\n","Epoch 350/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1937 - accuracy: 0.9329 - precision: 0.9428 - recall: 0.9218 - val_loss: 9343.8164 - val_accuracy: 0.1261 - val_precision: 0.1261 - val_recall: 0.1261\n","Epoch 351/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1808 - accuracy: 0.9363 - precision: 0.9470 - recall: 0.9263 - val_loss: 10845.7617 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 352/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1866 - accuracy: 0.9356 - precision: 0.9475 - recall: 0.9263 - val_loss: 9081.9209 - val_accuracy: 0.1140 - val_precision: 0.1140 - val_recall: 0.1140\n","Epoch 353/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.1887 - accuracy: 0.9350 - precision: 0.9468 - recall: 0.9284 - val_loss: 10416.8057 - val_accuracy: 0.1135 - val_precision: 0.1135 - val_recall: 0.1135\n","Epoch 354/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1911 - accuracy: 0.9351 - precision: 0.9443 - recall: 0.9275 - val_loss: 9708.5645 - val_accuracy: 0.1221 - val_precision: 0.1221 - val_recall: 0.1221\n","Epoch 355/10000\n","185/185 [==============================] - 14s 78ms/step - loss: 0.1943 - accuracy: 0.9358 - precision: 0.9444 - recall: 0.9263 - val_loss: 9581.4639 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 356/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1835 - accuracy: 0.9388 - precision: 0.9492 - recall: 0.9304 - val_loss: 10700.5391 - val_accuracy: 0.1246 - val_precision: 0.1246 - val_recall: 0.1246\n","Epoch 357/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1899 - accuracy: 0.9360 - precision: 0.9458 - recall: 0.9282 - val_loss: 10540.4688 - val_accuracy: 0.1246 - val_precision: 0.1246 - val_recall: 0.1246\n","Epoch 358/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1861 - accuracy: 0.9392 - precision: 0.9486 - recall: 0.9294 - val_loss: 8874.5801 - val_accuracy: 0.1403 - val_precision: 0.1403 - val_recall: 0.1403\n","Epoch 359/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1842 - accuracy: 0.9317 - precision: 0.9441 - recall: 0.9243 - val_loss: 9672.4561 - val_accuracy: 0.1201 - val_precision: 0.1201 - val_recall: 0.1201\n","Epoch 360/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1952 - accuracy: 0.9285 - precision: 0.9420 - recall: 0.9216 - val_loss: 9639.0996 - val_accuracy: 0.1332 - val_precision: 0.1332 - val_recall: 0.1332\n","Epoch 361/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.1757 - accuracy: 0.9436 - precision: 0.9530 - recall: 0.9353 - val_loss: 10764.0225 - val_accuracy: 0.1140 - val_precision: 0.1140 - val_recall: 0.1140\n","Epoch 362/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1815 - accuracy: 0.9366 - precision: 0.9463 - recall: 0.9297 - val_loss: 9483.0449 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 363/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1839 - accuracy: 0.9397 - precision: 0.9477 - recall: 0.9316 - val_loss: 9218.1289 - val_accuracy: 0.1353 - val_precision: 0.1353 - val_recall: 0.1353\n","Epoch 364/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1890 - accuracy: 0.9399 - precision: 0.9492 - recall: 0.9309 - val_loss: 9201.4678 - val_accuracy: 0.1484 - val_precision: 0.1484 - val_recall: 0.1484\n","Epoch 365/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1685 - accuracy: 0.9417 - precision: 0.9507 - recall: 0.9348 - val_loss: 10796.5400 - val_accuracy: 0.1104 - val_precision: 0.1104 - val_recall: 0.1104\n","Epoch 366/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1864 - accuracy: 0.9388 - precision: 0.9479 - recall: 0.9316 - val_loss: 10009.2197 - val_accuracy: 0.1256 - val_precision: 0.1256 - val_recall: 0.1256\n","Epoch 367/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1695 - accuracy: 0.9421 - precision: 0.9520 - recall: 0.9346 - val_loss: 13144.5195 - val_accuracy: 0.0897 - val_precision: 0.0897 - val_recall: 0.0897\n","Epoch 368/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1815 - accuracy: 0.9348 - precision: 0.9471 - recall: 0.9262 - val_loss: 9330.2861 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 369/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1746 - accuracy: 0.9387 - precision: 0.9498 - recall: 0.9329 - val_loss: 10840.4609 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 370/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1840 - accuracy: 0.9323 - precision: 0.9421 - recall: 0.9235 - val_loss: 9339.5068 - val_accuracy: 0.1418 - val_precision: 0.1418 - val_recall: 0.1418\n","Epoch 371/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1783 - accuracy: 0.9382 - precision: 0.9454 - recall: 0.9295 - val_loss: 12353.7539 - val_accuracy: 0.0957 - val_precision: 0.0957 - val_recall: 0.0957\n","Epoch 372/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1761 - accuracy: 0.9415 - precision: 0.9523 - recall: 0.9336 - val_loss: 8922.4375 - val_accuracy: 0.1251 - val_precision: 0.1251 - val_recall: 0.1251\n","Epoch 373/10000\n","185/185 [==============================] - 15s 78ms/step - loss: 0.1711 - accuracy: 0.9419 - precision: 0.9521 - recall: 0.9341 - val_loss: 11902.3672 - val_accuracy: 0.0988 - val_precision: 0.0988 - val_recall: 0.0988\n","Epoch 374/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1750 - accuracy: 0.9397 - precision: 0.9493 - recall: 0.9299 - val_loss: 9852.3896 - val_accuracy: 0.1322 - val_precision: 0.1322 - val_recall: 0.1322\n","Epoch 375/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1699 - accuracy: 0.9397 - precision: 0.9504 - recall: 0.9321 - val_loss: 10861.6123 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 376/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1817 - accuracy: 0.9372 - precision: 0.9479 - recall: 0.9287 - val_loss: 9505.6650 - val_accuracy: 0.1221 - val_precision: 0.1221 - val_recall: 0.1221\n","Epoch 377/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1931 - accuracy: 0.9312 - precision: 0.9443 - recall: 0.9221 - val_loss: 9912.1387 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 378/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.1591 - accuracy: 0.9441 - precision: 0.9537 - recall: 0.9363 - val_loss: 12340.7168 - val_accuracy: 0.1135 - val_precision: 0.1135 - val_recall: 0.1135\n","Epoch 379/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1751 - accuracy: 0.9434 - precision: 0.9515 - recall: 0.9353 - val_loss: 10079.4365 - val_accuracy: 0.1408 - val_precision: 0.1408 - val_recall: 0.1408\n","Epoch 380/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1743 - accuracy: 0.9421 - precision: 0.9498 - recall: 0.9333 - val_loss: 11326.4209 - val_accuracy: 0.1094 - val_precision: 0.1094 - val_recall: 0.1094\n","Epoch 381/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1850 - accuracy: 0.9368 - precision: 0.9450 - recall: 0.9314 - val_loss: 12711.4990 - val_accuracy: 0.1003 - val_precision: 0.1003 - val_recall: 0.1003\n","Epoch 382/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1817 - accuracy: 0.9360 - precision: 0.9456 - recall: 0.9277 - val_loss: 10802.6514 - val_accuracy: 0.1226 - val_precision: 0.1226 - val_recall: 0.1226\n","Epoch 383/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1782 - accuracy: 0.9393 - precision: 0.9480 - recall: 0.9329 - val_loss: 10138.0781 - val_accuracy: 0.1403 - val_precision: 0.1403 - val_recall: 0.1403\n","Epoch 384/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1601 - accuracy: 0.9473 - precision: 0.9546 - recall: 0.9387 - val_loss: 11366.5049 - val_accuracy: 0.1201 - val_precision: 0.1201 - val_recall: 0.1201\n","Epoch 385/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1617 - accuracy: 0.9422 - precision: 0.9505 - recall: 0.9344 - val_loss: 9988.7549 - val_accuracy: 0.1266 - val_precision: 0.1266 - val_recall: 0.1266\n","Epoch 386/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1641 - accuracy: 0.9458 - precision: 0.9527 - recall: 0.9368 - val_loss: 10008.5146 - val_accuracy: 0.1302 - val_precision: 0.1302 - val_recall: 0.1302\n","Epoch 387/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1651 - accuracy: 0.9404 - precision: 0.9499 - recall: 0.9350 - val_loss: 11725.0098 - val_accuracy: 0.1114 - val_precision: 0.1114 - val_recall: 0.1114\n","Epoch 388/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1645 - accuracy: 0.9439 - precision: 0.9501 - recall: 0.9351 - val_loss: 9636.8096 - val_accuracy: 0.1231 - val_precision: 0.1231 - val_recall: 0.1231\n","Epoch 389/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1621 - accuracy: 0.9426 - precision: 0.9507 - recall: 0.9350 - val_loss: 10142.5586 - val_accuracy: 0.1201 - val_precision: 0.1201 - val_recall: 0.1201\n","Epoch 390/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1574 - accuracy: 0.9466 - precision: 0.9552 - recall: 0.9393 - val_loss: 9805.4668 - val_accuracy: 0.1332 - val_precision: 0.1332 - val_recall: 0.1332\n","Epoch 391/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1690 - accuracy: 0.9466 - precision: 0.9547 - recall: 0.9393 - val_loss: 8991.2061 - val_accuracy: 0.1489 - val_precision: 0.1489 - val_recall: 0.1489\n","Epoch 392/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1722 - accuracy: 0.9409 - precision: 0.9493 - recall: 0.9334 - val_loss: 9556.9922 - val_accuracy: 0.1322 - val_precision: 0.1322 - val_recall: 0.1322\n","Epoch 393/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1500 - accuracy: 0.9491 - precision: 0.9544 - recall: 0.9412 - val_loss: 8252.3203 - val_accuracy: 0.1499 - val_precision: 0.1499 - val_recall: 0.1499\n","Epoch 394/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.1503 - accuracy: 0.9495 - precision: 0.9572 - recall: 0.9417 - val_loss: 8795.8496 - val_accuracy: 0.1515 - val_precision: 0.1515 - val_recall: 0.1515\n","Epoch 395/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1687 - accuracy: 0.9458 - precision: 0.9542 - recall: 0.9373 - val_loss: 9272.0918 - val_accuracy: 0.1545 - val_precision: 0.1545 - val_recall: 0.1545\n","Epoch 396/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1473 - accuracy: 0.9491 - precision: 0.9577 - recall: 0.9405 - val_loss: 10753.5703 - val_accuracy: 0.1337 - val_precision: 0.1337 - val_recall: 0.1337\n","Epoch 397/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1627 - accuracy: 0.9417 - precision: 0.9521 - recall: 0.9344 - val_loss: 11487.6387 - val_accuracy: 0.1044 - val_precision: 0.1044 - val_recall: 0.1044\n","Epoch 398/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1585 - accuracy: 0.9483 - precision: 0.9557 - recall: 0.9404 - val_loss: 10431.9434 - val_accuracy: 0.1327 - val_precision: 0.1327 - val_recall: 0.1327\n","Epoch 399/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1684 - accuracy: 0.9414 - precision: 0.9504 - recall: 0.9323 - val_loss: 10207.9600 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 400/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1535 - accuracy: 0.9451 - precision: 0.9555 - recall: 0.9395 - val_loss: 10532.3320 - val_accuracy: 0.1418 - val_precision: 0.1418 - val_recall: 0.1418\n","Epoch 401/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1451 - accuracy: 0.9517 - precision: 0.9583 - recall: 0.9468 - val_loss: 10287.5586 - val_accuracy: 0.1282 - val_precision: 0.1282 - val_recall: 0.1282\n","Epoch 402/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1684 - accuracy: 0.9410 - precision: 0.9506 - recall: 0.9365 - val_loss: 8784.0742 - val_accuracy: 0.1494 - val_precision: 0.1494 - val_recall: 0.1494\n","Epoch 403/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1622 - accuracy: 0.9419 - precision: 0.9518 - recall: 0.9346 - val_loss: 10613.9131 - val_accuracy: 0.1282 - val_precision: 0.1282 - val_recall: 0.1282\n","Epoch 404/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1641 - accuracy: 0.9456 - precision: 0.9539 - recall: 0.9399 - val_loss: 10573.6592 - val_accuracy: 0.1196 - val_precision: 0.1196 - val_recall: 0.1196\n","Epoch 405/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1609 - accuracy: 0.9434 - precision: 0.9497 - recall: 0.9385 - val_loss: 9926.7197 - val_accuracy: 0.1246 - val_precision: 0.1246 - val_recall: 0.1246\n","Epoch 406/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1443 - accuracy: 0.9485 - precision: 0.9569 - recall: 0.9419 - val_loss: 10482.1094 - val_accuracy: 0.1337 - val_precision: 0.1337 - val_recall: 0.1337\n","Epoch 407/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1555 - accuracy: 0.9475 - precision: 0.9547 - recall: 0.9397 - val_loss: 9655.4717 - val_accuracy: 0.1261 - val_precision: 0.1261 - val_recall: 0.1261\n","Epoch 408/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1540 - accuracy: 0.9473 - precision: 0.9544 - recall: 0.9399 - val_loss: 9727.6846 - val_accuracy: 0.1403 - val_precision: 0.1403 - val_recall: 0.1403\n","Epoch 409/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1635 - accuracy: 0.9422 - precision: 0.9497 - recall: 0.9348 - val_loss: 9976.7598 - val_accuracy: 0.1226 - val_precision: 0.1226 - val_recall: 0.1226\n","Epoch 410/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.1563 - accuracy: 0.9481 - precision: 0.9568 - recall: 0.9419 - val_loss: 12253.0322 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 411/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1823 - accuracy: 0.9393 - precision: 0.9463 - recall: 0.9328 - val_loss: 12502.2891 - val_accuracy: 0.0917 - val_precision: 0.0917 - val_recall: 0.0917\n","Epoch 412/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1606 - accuracy: 0.9476 - precision: 0.9546 - recall: 0.9415 - val_loss: 12217.0596 - val_accuracy: 0.1099 - val_precision: 0.1099 - val_recall: 0.1099\n","Epoch 413/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1489 - accuracy: 0.9481 - precision: 0.9554 - recall: 0.9410 - val_loss: 10909.2734 - val_accuracy: 0.1221 - val_precision: 0.1221 - val_recall: 0.1221\n","Epoch 414/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1622 - accuracy: 0.9464 - precision: 0.9541 - recall: 0.9383 - val_loss: 10474.1318 - val_accuracy: 0.1418 - val_precision: 0.1418 - val_recall: 0.1418\n","Epoch 415/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1435 - accuracy: 0.9512 - precision: 0.9579 - recall: 0.9446 - val_loss: 9555.0752 - val_accuracy: 0.1393 - val_precision: 0.1393 - val_recall: 0.1393\n","Epoch 416/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1496 - accuracy: 0.9488 - precision: 0.9571 - recall: 0.9417 - val_loss: 10982.9795 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 417/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1607 - accuracy: 0.9437 - precision: 0.9510 - recall: 0.9368 - val_loss: 9330.6230 - val_accuracy: 0.1434 - val_precision: 0.1434 - val_recall: 0.1434\n","Epoch 418/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1432 - accuracy: 0.9518 - precision: 0.9587 - recall: 0.9461 - val_loss: 9294.8350 - val_accuracy: 0.1342 - val_precision: 0.1342 - val_recall: 0.1342\n","Epoch 419/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1392 - accuracy: 0.9488 - precision: 0.9572 - recall: 0.9439 - val_loss: 11300.2959 - val_accuracy: 0.1114 - val_precision: 0.1114 - val_recall: 0.1114\n","Epoch 420/10000\n","185/185 [==============================] - 15s 79ms/step - loss: 0.1493 - accuracy: 0.9505 - precision: 0.9560 - recall: 0.9442 - val_loss: 8645.1035 - val_accuracy: 0.1434 - val_precision: 0.1434 - val_recall: 0.1434\n","Epoch 421/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1509 - accuracy: 0.9517 - precision: 0.9582 - recall: 0.9449 - val_loss: 12702.7793 - val_accuracy: 0.1069 - val_precision: 0.1069 - val_recall: 0.1069\n","Epoch 422/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1422 - accuracy: 0.9500 - precision: 0.9569 - recall: 0.9444 - val_loss: 11532.3213 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 423/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1514 - accuracy: 0.9448 - precision: 0.9519 - recall: 0.9393 - val_loss: 9984.3799 - val_accuracy: 0.1545 - val_precision: 0.1545 - val_recall: 0.1545\n","Epoch 424/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1433 - accuracy: 0.9493 - precision: 0.9560 - recall: 0.9437 - val_loss: 10465.4365 - val_accuracy: 0.1494 - val_precision: 0.1494 - val_recall: 0.1494\n","Epoch 425/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1401 - accuracy: 0.9534 - precision: 0.9598 - recall: 0.9473 - val_loss: 10253.5850 - val_accuracy: 0.1302 - val_precision: 0.1302 - val_recall: 0.1302\n","Epoch 426/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1546 - accuracy: 0.9468 - precision: 0.9540 - recall: 0.9424 - val_loss: 10063.7607 - val_accuracy: 0.1307 - val_precision: 0.1307 - val_recall: 0.1307\n","Epoch 427/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.1365 - accuracy: 0.9566 - precision: 0.9625 - recall: 0.9493 - val_loss: 11236.0859 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 428/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1336 - accuracy: 0.9542 - precision: 0.9593 - recall: 0.9488 - val_loss: 9724.8135 - val_accuracy: 0.1499 - val_precision: 0.1499 - val_recall: 0.1499\n","Epoch 429/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1656 - accuracy: 0.9426 - precision: 0.9499 - recall: 0.9378 - val_loss: 11200.3223 - val_accuracy: 0.1378 - val_precision: 0.1378 - val_recall: 0.1378\n","Epoch 430/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1422 - accuracy: 0.9564 - precision: 0.9632 - recall: 0.9497 - val_loss: 11263.2139 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 431/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1490 - accuracy: 0.9473 - precision: 0.9526 - recall: 0.9395 - val_loss: 10043.2705 - val_accuracy: 0.1307 - val_precision: 0.1307 - val_recall: 0.1307\n","Epoch 432/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1592 - accuracy: 0.9473 - precision: 0.9559 - recall: 0.9405 - val_loss: 10279.3945 - val_accuracy: 0.1348 - val_precision: 0.1348 - val_recall: 0.1348\n","Epoch 433/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1511 - accuracy: 0.9478 - precision: 0.9560 - recall: 0.9424 - val_loss: 10251.6729 - val_accuracy: 0.1297 - val_precision: 0.1297 - val_recall: 0.1297\n","Epoch 434/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1474 - accuracy: 0.9490 - precision: 0.9578 - recall: 0.9424 - val_loss: 11421.2646 - val_accuracy: 0.1251 - val_precision: 0.1251 - val_recall: 0.1251\n","Epoch 435/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1360 - accuracy: 0.9540 - precision: 0.9601 - recall: 0.9480 - val_loss: 10647.3037 - val_accuracy: 0.1368 - val_precision: 0.1368 - val_recall: 0.1368\n","Epoch 436/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1395 - accuracy: 0.9525 - precision: 0.9585 - recall: 0.9480 - val_loss: 10100.0059 - val_accuracy: 0.1373 - val_precision: 0.1373 - val_recall: 0.1373\n","Epoch 437/10000\n","185/185 [==============================] - 15s 80ms/step - loss: 0.1416 - accuracy: 0.9515 - precision: 0.9566 - recall: 0.9451 - val_loss: 11644.0986 - val_accuracy: 0.1373 - val_precision: 0.1373 - val_recall: 0.1373\n","Epoch 438/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1420 - accuracy: 0.9481 - precision: 0.9554 - recall: 0.9414 - val_loss: 10696.1807 - val_accuracy: 0.1327 - val_precision: 0.1327 - val_recall: 0.1327\n","Epoch 439/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1373 - accuracy: 0.9532 - precision: 0.9604 - recall: 0.9495 - val_loss: 10767.5283 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 440/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1337 - accuracy: 0.9544 - precision: 0.9592 - recall: 0.9486 - val_loss: 11025.7100 - val_accuracy: 0.1302 - val_precision: 0.1302 - val_recall: 0.1302\n","Epoch 441/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1403 - accuracy: 0.9502 - precision: 0.9566 - recall: 0.9448 - val_loss: 9387.8916 - val_accuracy: 0.1586 - val_precision: 0.1586 - val_recall: 0.1586\n","Epoch 442/10000\n","185/185 [==============================] - 15s 84ms/step - loss: 0.1264 - accuracy: 0.9595 - precision: 0.9678 - recall: 0.9546 - val_loss: 10851.5439 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 443/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.1341 - accuracy: 0.9542 - precision: 0.9595 - recall: 0.9488 - val_loss: 12260.1318 - val_accuracy: 0.1206 - val_precision: 0.1206 - val_recall: 0.1206\n","Epoch 444/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1391 - accuracy: 0.9537 - precision: 0.9595 - recall: 0.9495 - val_loss: 9818.6162 - val_accuracy: 0.1266 - val_precision: 0.1266 - val_recall: 0.1266\n","Epoch 445/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1416 - accuracy: 0.9491 - precision: 0.9555 - recall: 0.9426 - val_loss: 12480.2666 - val_accuracy: 0.1114 - val_precision: 0.1114 - val_recall: 0.1114\n","Epoch 446/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1419 - accuracy: 0.9530 - precision: 0.9581 - recall: 0.9476 - val_loss: 10225.6289 - val_accuracy: 0.1408 - val_precision: 0.1408 - val_recall: 0.1408\n","Epoch 447/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1402 - accuracy: 0.9502 - precision: 0.9559 - recall: 0.9448 - val_loss: 11864.6875 - val_accuracy: 0.1266 - val_precision: 0.1266 - val_recall: 0.1266\n","Epoch 448/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1313 - accuracy: 0.9557 - precision: 0.9623 - recall: 0.9498 - val_loss: 11523.4111 - val_accuracy: 0.1272 - val_precision: 0.1272 - val_recall: 0.1272\n","Epoch 449/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1351 - accuracy: 0.9546 - precision: 0.9600 - recall: 0.9490 - val_loss: 10137.4336 - val_accuracy: 0.1272 - val_precision: 0.1272 - val_recall: 0.1272\n","Epoch 450/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1154 - accuracy: 0.9605 - precision: 0.9669 - recall: 0.9566 - val_loss: 11030.9092 - val_accuracy: 0.1378 - val_precision: 0.1378 - val_recall: 0.1378\n","Epoch 451/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1393 - accuracy: 0.9535 - precision: 0.9578 - recall: 0.9466 - val_loss: 11713.2217 - val_accuracy: 0.1241 - val_precision: 0.1241 - val_recall: 0.1241\n","Epoch 452/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1538 - accuracy: 0.9486 - precision: 0.9549 - recall: 0.9437 - val_loss: 10806.9824 - val_accuracy: 0.1342 - val_precision: 0.1342 - val_recall: 0.1342\n","Epoch 453/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1405 - accuracy: 0.9513 - precision: 0.9568 - recall: 0.9461 - val_loss: 9461.7178 - val_accuracy: 0.1383 - val_precision: 0.1383 - val_recall: 0.1383\n","Epoch 454/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1291 - accuracy: 0.9549 - precision: 0.9604 - recall: 0.9507 - val_loss: 9674.3613 - val_accuracy: 0.1393 - val_precision: 0.1393 - val_recall: 0.1393\n","Epoch 455/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1391 - accuracy: 0.9520 - precision: 0.9570 - recall: 0.9476 - val_loss: 12899.8271 - val_accuracy: 0.1069 - val_precision: 0.1069 - val_recall: 0.1069\n","Epoch 456/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1365 - accuracy: 0.9515 - precision: 0.9576 - recall: 0.9454 - val_loss: 9394.2764 - val_accuracy: 0.1489 - val_precision: 0.1489 - val_recall: 0.1489\n","Epoch 457/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1316 - accuracy: 0.9552 - precision: 0.9609 - recall: 0.9498 - val_loss: 13005.3398 - val_accuracy: 0.1109 - val_precision: 0.1109 - val_recall: 0.1109\n","Epoch 458/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1305 - accuracy: 0.9581 - precision: 0.9638 - recall: 0.9544 - val_loss: 12312.7617 - val_accuracy: 0.1008 - val_precision: 0.1008 - val_recall: 0.1008\n","Epoch 459/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.1235 - accuracy: 0.9586 - precision: 0.9633 - recall: 0.9542 - val_loss: 11547.6299 - val_accuracy: 0.1211 - val_precision: 0.1211 - val_recall: 0.1211\n","Epoch 460/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1250 - accuracy: 0.9561 - precision: 0.9604 - recall: 0.9512 - val_loss: 9763.5352 - val_accuracy: 0.1353 - val_precision: 0.1353 - val_recall: 0.1353\n","Epoch 461/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1205 - accuracy: 0.9579 - precision: 0.9621 - recall: 0.9522 - val_loss: 11555.8613 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 462/10000\n","185/185 [==============================] - 15s 81ms/step - loss: 0.1402 - accuracy: 0.9525 - precision: 0.9593 - recall: 0.9473 - val_loss: 11162.5029 - val_accuracy: 0.1241 - val_precision: 0.1241 - val_recall: 0.1241\n","Epoch 463/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1219 - accuracy: 0.9566 - precision: 0.9624 - recall: 0.9508 - val_loss: 11510.7676 - val_accuracy: 0.1109 - val_precision: 0.1109 - val_recall: 0.1109\n","Epoch 464/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1236 - accuracy: 0.9566 - precision: 0.9631 - recall: 0.9517 - val_loss: 11124.2236 - val_accuracy: 0.1368 - val_precision: 0.1368 - val_recall: 0.1368\n","Epoch 465/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1285 - accuracy: 0.9544 - precision: 0.9616 - recall: 0.9510 - val_loss: 11046.7871 - val_accuracy: 0.1201 - val_precision: 0.1201 - val_recall: 0.1201\n","Epoch 466/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1458 - accuracy: 0.9500 - precision: 0.9559 - recall: 0.9449 - val_loss: 10370.5410 - val_accuracy: 0.1256 - val_precision: 0.1256 - val_recall: 0.1256\n","Epoch 467/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1331 - accuracy: 0.9540 - precision: 0.9601 - recall: 0.9478 - val_loss: 9956.3848 - val_accuracy: 0.1434 - val_precision: 0.1434 - val_recall: 0.1434\n","Epoch 468/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1338 - accuracy: 0.9554 - precision: 0.9607 - recall: 0.9508 - val_loss: 10771.1943 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 469/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1320 - accuracy: 0.9552 - precision: 0.9606 - recall: 0.9470 - val_loss: 11745.2334 - val_accuracy: 0.1206 - val_precision: 0.1206 - val_recall: 0.1206\n","Epoch 470/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1289 - accuracy: 0.9559 - precision: 0.9621 - recall: 0.9520 - val_loss: 11720.7188 - val_accuracy: 0.1135 - val_precision: 0.1135 - val_recall: 0.1135\n","Epoch 471/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1155 - accuracy: 0.9605 - precision: 0.9635 - recall: 0.9554 - val_loss: 10285.3262 - val_accuracy: 0.1378 - val_precision: 0.1378 - val_recall: 0.1378\n","Epoch 472/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1203 - accuracy: 0.9581 - precision: 0.9662 - recall: 0.9527 - val_loss: 10585.3438 - val_accuracy: 0.1418 - val_precision: 0.1418 - val_recall: 0.1418\n","Epoch 473/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1215 - accuracy: 0.9601 - precision: 0.9665 - recall: 0.9557 - val_loss: 10943.5615 - val_accuracy: 0.1206 - val_precision: 0.1206 - val_recall: 0.1206\n","Epoch 474/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1176 - accuracy: 0.9583 - precision: 0.9636 - recall: 0.9535 - val_loss: 12208.1074 - val_accuracy: 0.1074 - val_precision: 0.1074 - val_recall: 0.1074\n","Epoch 475/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.1228 - accuracy: 0.9562 - precision: 0.9615 - recall: 0.9529 - val_loss: 12430.0010 - val_accuracy: 0.1190 - val_precision: 0.1190 - val_recall: 0.1190\n","Epoch 476/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1344 - accuracy: 0.9556 - precision: 0.9609 - recall: 0.9502 - val_loss: 11498.6406 - val_accuracy: 0.1287 - val_precision: 0.1287 - val_recall: 0.1287\n","Epoch 477/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1274 - accuracy: 0.9583 - precision: 0.9627 - recall: 0.9539 - val_loss: 11926.3838 - val_accuracy: 0.1302 - val_precision: 0.1302 - val_recall: 0.1302\n","Epoch 478/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1391 - accuracy: 0.9517 - precision: 0.9562 - recall: 0.9471 - val_loss: 14236.8223 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 479/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1262 - accuracy: 0.9556 - precision: 0.9609 - recall: 0.9508 - val_loss: 13245.0273 - val_accuracy: 0.1256 - val_precision: 0.1256 - val_recall: 0.1256\n","Epoch 480/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1141 - accuracy: 0.9622 - precision: 0.9676 - recall: 0.9581 - val_loss: 13651.6953 - val_accuracy: 0.1231 - val_precision: 0.1231 - val_recall: 0.1231\n","Epoch 481/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1187 - accuracy: 0.9598 - precision: 0.9638 - recall: 0.9549 - val_loss: 11453.1709 - val_accuracy: 0.1251 - val_precision: 0.1251 - val_recall: 0.1251\n","Epoch 482/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1176 - accuracy: 0.9613 - precision: 0.9663 - recall: 0.9584 - val_loss: 11534.8828 - val_accuracy: 0.1327 - val_precision: 0.1327 - val_recall: 0.1327\n","Epoch 483/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1196 - accuracy: 0.9595 - precision: 0.9648 - recall: 0.9537 - val_loss: 11798.1152 - val_accuracy: 0.1155 - val_precision: 0.1155 - val_recall: 0.1155\n","Epoch 484/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1235 - accuracy: 0.9598 - precision: 0.9634 - recall: 0.9552 - val_loss: 9873.1084 - val_accuracy: 0.1444 - val_precision: 0.1444 - val_recall: 0.1444\n","Epoch 485/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1305 - accuracy: 0.9549 - precision: 0.9605 - recall: 0.9495 - val_loss: 10903.4697 - val_accuracy: 0.1261 - val_precision: 0.1261 - val_recall: 0.1261\n","Epoch 486/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1155 - accuracy: 0.9586 - precision: 0.9647 - recall: 0.9549 - val_loss: 11275.1582 - val_accuracy: 0.1236 - val_precision: 0.1236 - val_recall: 0.1236\n","Epoch 487/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1090 - accuracy: 0.9635 - precision: 0.9680 - recall: 0.9606 - val_loss: 9776.9102 - val_accuracy: 0.1454 - val_precision: 0.1454 - val_recall: 0.1454\n","Epoch 488/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1143 - accuracy: 0.9616 - precision: 0.9657 - recall: 0.9574 - val_loss: 10329.9463 - val_accuracy: 0.1388 - val_precision: 0.1388 - val_recall: 0.1388\n","Epoch 489/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1287 - accuracy: 0.9540 - precision: 0.9607 - recall: 0.9490 - val_loss: 11522.7559 - val_accuracy: 0.1297 - val_precision: 0.1297 - val_recall: 0.1297\n","Epoch 490/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1275 - accuracy: 0.9562 - precision: 0.9606 - recall: 0.9515 - val_loss: 11644.3848 - val_accuracy: 0.1180 - val_precision: 0.1180 - val_recall: 0.1180\n","Epoch 491/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.1106 - accuracy: 0.9645 - precision: 0.9679 - recall: 0.9589 - val_loss: 12043.8320 - val_accuracy: 0.1190 - val_precision: 0.1190 - val_recall: 0.1190\n","Epoch 492/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1147 - accuracy: 0.9603 - precision: 0.9654 - recall: 0.9562 - val_loss: 10530.7598 - val_accuracy: 0.1398 - val_precision: 0.1398 - val_recall: 0.1398\n","Epoch 493/10000\n","185/185 [==============================] - 15s 84ms/step - loss: 0.1311 - accuracy: 0.9571 - precision: 0.9611 - recall: 0.9529 - val_loss: 13467.1475 - val_accuracy: 0.1109 - val_precision: 0.1109 - val_recall: 0.1109\n","Epoch 494/10000\n","185/185 [==============================] - 15s 84ms/step - loss: 0.1154 - accuracy: 0.9603 - precision: 0.9633 - recall: 0.9566 - val_loss: 12039.9043 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 495/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1140 - accuracy: 0.9606 - precision: 0.9644 - recall: 0.9579 - val_loss: 10486.6357 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 496/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1207 - accuracy: 0.9606 - precision: 0.9635 - recall: 0.9546 - val_loss: 11699.1104 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 497/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1041 - accuracy: 0.9640 - precision: 0.9680 - recall: 0.9605 - val_loss: 11502.7061 - val_accuracy: 0.1196 - val_precision: 0.1196 - val_recall: 0.1196\n","Epoch 498/10000\n","185/185 [==============================] - 15s 84ms/step - loss: 0.1216 - accuracy: 0.9559 - precision: 0.9603 - recall: 0.9518 - val_loss: 13593.5596 - val_accuracy: 0.0947 - val_precision: 0.0947 - val_recall: 0.0947\n","Epoch 499/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1149 - accuracy: 0.9613 - precision: 0.9652 - recall: 0.9573 - val_loss: 11988.9033 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 500/10000\n","185/185 [==============================] - 15s 84ms/step - loss: 0.1218 - accuracy: 0.9569 - precision: 0.9625 - recall: 0.9534 - val_loss: 13074.2314 - val_accuracy: 0.1089 - val_precision: 0.1089 - val_recall: 0.1089\n","Epoch 501/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.1116 - accuracy: 0.9625 - precision: 0.9660 - recall: 0.9593 - val_loss: 11220.7695 - val_accuracy: 0.1251 - val_precision: 0.1251 - val_recall: 0.1251\n","Epoch 502/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.1238 - accuracy: 0.9569 - precision: 0.9631 - recall: 0.9530 - val_loss: 12986.1680 - val_accuracy: 0.1049 - val_precision: 0.1049 - val_recall: 0.1049\n","Epoch 503/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.1195 - accuracy: 0.9589 - precision: 0.9646 - recall: 0.9532 - val_loss: 10253.7686 - val_accuracy: 0.1353 - val_precision: 0.1353 - val_recall: 0.1353\n","Epoch 504/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.1110 - accuracy: 0.9635 - precision: 0.9679 - recall: 0.9586 - val_loss: 13782.9023 - val_accuracy: 0.0917 - val_precision: 0.0917 - val_recall: 0.0917\n","Epoch 505/10000\n","185/185 [==============================] - 15s 84ms/step - loss: 0.1230 - accuracy: 0.9584 - precision: 0.9649 - recall: 0.9532 - val_loss: 13237.9971 - val_accuracy: 0.1013 - val_precision: 0.1013 - val_recall: 0.1013\n","Epoch 506/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1238 - accuracy: 0.9595 - precision: 0.9661 - recall: 0.9540 - val_loss: 11696.2598 - val_accuracy: 0.1241 - val_precision: 0.1241 - val_recall: 0.1241\n","Epoch 507/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 0.1098 - accuracy: 0.9598 - precision: 0.9652 - recall: 0.9552 - val_loss: 12118.1875 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 508/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0991 - accuracy: 0.9672 - precision: 0.9719 - recall: 0.9628 - val_loss: 11711.9619 - val_accuracy: 0.1125 - val_precision: 0.1125 - val_recall: 0.1125\n","Epoch 509/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.1126 - accuracy: 0.9601 - precision: 0.9661 - recall: 0.9571 - val_loss: 12864.1338 - val_accuracy: 0.1018 - val_precision: 0.1018 - val_recall: 0.1018\n","Epoch 510/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1109 - accuracy: 0.9595 - precision: 0.9645 - recall: 0.9561 - val_loss: 12568.0801 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 511/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.0924 - accuracy: 0.9679 - precision: 0.9714 - recall: 0.9637 - val_loss: 11926.1289 - val_accuracy: 0.1180 - val_precision: 0.1180 - val_recall: 0.1180\n","Epoch 512/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1130 - accuracy: 0.9628 - precision: 0.9666 - recall: 0.9589 - val_loss: 12424.0059 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 513/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1062 - accuracy: 0.9618 - precision: 0.9666 - recall: 0.9584 - val_loss: 12052.6855 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 514/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1247 - accuracy: 0.9556 - precision: 0.9604 - recall: 0.9503 - val_loss: 11955.6758 - val_accuracy: 0.1211 - val_precision: 0.1211 - val_recall: 0.1211\n","Epoch 515/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1221 - accuracy: 0.9567 - precision: 0.9602 - recall: 0.9529 - val_loss: 12124.9971 - val_accuracy: 0.1140 - val_precision: 0.1140 - val_recall: 0.1140\n","Epoch 516/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1145 - accuracy: 0.9630 - precision: 0.9669 - recall: 0.9583 - val_loss: 10645.6699 - val_accuracy: 0.1373 - val_precision: 0.1373 - val_recall: 0.1373\n","Epoch 517/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1210 - accuracy: 0.9605 - precision: 0.9645 - recall: 0.9556 - val_loss: 11435.0469 - val_accuracy: 0.1261 - val_precision: 0.1261 - val_recall: 0.1261\n","Epoch 518/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1076 - accuracy: 0.9638 - precision: 0.9676 - recall: 0.9600 - val_loss: 12522.2285 - val_accuracy: 0.1236 - val_precision: 0.1236 - val_recall: 0.1236\n","Epoch 519/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1068 - accuracy: 0.9650 - precision: 0.9684 - recall: 0.9615 - val_loss: 12440.2910 - val_accuracy: 0.1180 - val_precision: 0.1180 - val_recall: 0.1180\n","Epoch 520/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1180 - accuracy: 0.9584 - precision: 0.9629 - recall: 0.9556 - val_loss: 11032.5088 - val_accuracy: 0.1226 - val_precision: 0.1226 - val_recall: 0.1226\n","Epoch 521/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1069 - accuracy: 0.9635 - precision: 0.9682 - recall: 0.9608 - val_loss: 15981.7852 - val_accuracy: 0.0831 - val_precision: 0.0831 - val_recall: 0.0831\n","Epoch 522/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1052 - accuracy: 0.9645 - precision: 0.9677 - recall: 0.9605 - val_loss: 15970.7471 - val_accuracy: 0.0846 - val_precision: 0.0846 - val_recall: 0.0846\n","Epoch 523/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.1120 - accuracy: 0.9623 - precision: 0.9669 - recall: 0.9578 - val_loss: 17421.7617 - val_accuracy: 0.0811 - val_precision: 0.0811 - val_recall: 0.0811\n","Epoch 524/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1141 - accuracy: 0.9615 - precision: 0.9667 - recall: 0.9556 - val_loss: 12252.0459 - val_accuracy: 0.1044 - val_precision: 0.1044 - val_recall: 0.1044\n","Epoch 525/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1054 - accuracy: 0.9659 - precision: 0.9688 - recall: 0.9610 - val_loss: 13170.4824 - val_accuracy: 0.1084 - val_precision: 0.1084 - val_recall: 0.1084\n","Epoch 526/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1087 - accuracy: 0.9625 - precision: 0.9661 - recall: 0.9589 - val_loss: 11478.8916 - val_accuracy: 0.1388 - val_precision: 0.1388 - val_recall: 0.1388\n","Epoch 527/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1071 - accuracy: 0.9606 - precision: 0.9664 - recall: 0.9571 - val_loss: 12177.0479 - val_accuracy: 0.1089 - val_precision: 0.1089 - val_recall: 0.1089\n","Epoch 528/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1074 - accuracy: 0.9620 - precision: 0.9653 - recall: 0.9576 - val_loss: 10726.8877 - val_accuracy: 0.1342 - val_precision: 0.1342 - val_recall: 0.1342\n","Epoch 529/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1108 - accuracy: 0.9645 - precision: 0.9690 - recall: 0.9598 - val_loss: 10278.5078 - val_accuracy: 0.1403 - val_precision: 0.1403 - val_recall: 0.1403\n","Epoch 530/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1115 - accuracy: 0.9615 - precision: 0.9664 - recall: 0.9578 - val_loss: 12041.9043 - val_accuracy: 0.1327 - val_precision: 0.1327 - val_recall: 0.1327\n","Epoch 531/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.0959 - accuracy: 0.9654 - precision: 0.9688 - recall: 0.9637 - val_loss: 10551.4395 - val_accuracy: 0.1297 - val_precision: 0.1297 - val_recall: 0.1297\n","Epoch 532/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1061 - accuracy: 0.9596 - precision: 0.9652 - recall: 0.9571 - val_loss: 11849.5850 - val_accuracy: 0.1069 - val_precision: 0.1069 - val_recall: 0.1069\n","Epoch 533/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1143 - accuracy: 0.9622 - precision: 0.9664 - recall: 0.9566 - val_loss: 10802.6289 - val_accuracy: 0.1312 - val_precision: 0.1312 - val_recall: 0.1312\n","Epoch 534/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1077 - accuracy: 0.9627 - precision: 0.9671 - recall: 0.9589 - val_loss: 12110.8408 - val_accuracy: 0.1185 - val_precision: 0.1185 - val_recall: 0.1185\n","Epoch 535/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1048 - accuracy: 0.9588 - precision: 0.9645 - recall: 0.9556 - val_loss: 10219.0352 - val_accuracy: 0.1540 - val_precision: 0.1540 - val_recall: 0.1540\n","Epoch 536/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1050 - accuracy: 0.9649 - precision: 0.9686 - recall: 0.9603 - val_loss: 10495.9395 - val_accuracy: 0.1494 - val_precision: 0.1494 - val_recall: 0.1494\n","Epoch 537/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1102 - accuracy: 0.9642 - precision: 0.9691 - recall: 0.9603 - val_loss: 10125.4365 - val_accuracy: 0.1499 - val_precision: 0.1499 - val_recall: 0.1499\n","Epoch 538/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1144 - accuracy: 0.9601 - precision: 0.9643 - recall: 0.9573 - val_loss: 10149.0566 - val_accuracy: 0.1520 - val_precision: 0.1520 - val_recall: 0.1520\n","Epoch 539/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0938 - accuracy: 0.9689 - precision: 0.9731 - recall: 0.9665 - val_loss: 10257.3457 - val_accuracy: 0.1327 - val_precision: 0.1327 - val_recall: 0.1327\n","Epoch 540/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1065 - accuracy: 0.9655 - precision: 0.9682 - recall: 0.9632 - val_loss: 13025.9805 - val_accuracy: 0.1109 - val_precision: 0.1109 - val_recall: 0.1109\n","Epoch 541/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1018 - accuracy: 0.9649 - precision: 0.9683 - recall: 0.9613 - val_loss: 13510.8721 - val_accuracy: 0.1206 - val_precision: 0.1206 - val_recall: 0.1206\n","Epoch 542/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1108 - accuracy: 0.9616 - precision: 0.9653 - recall: 0.9578 - val_loss: 12589.5703 - val_accuracy: 0.1094 - val_precision: 0.1094 - val_recall: 0.1094\n","Epoch 543/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.0949 - accuracy: 0.9687 - precision: 0.9724 - recall: 0.9655 - val_loss: 11361.9844 - val_accuracy: 0.1256 - val_precision: 0.1256 - val_recall: 0.1256\n","Epoch 544/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1134 - accuracy: 0.9601 - precision: 0.9664 - recall: 0.9564 - val_loss: 10121.7549 - val_accuracy: 0.1434 - val_precision: 0.1434 - val_recall: 0.1434\n","Epoch 545/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1062 - accuracy: 0.9637 - precision: 0.9671 - recall: 0.9593 - val_loss: 10772.3721 - val_accuracy: 0.1454 - val_precision: 0.1454 - val_recall: 0.1454\n","Epoch 546/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0949 - accuracy: 0.9677 - precision: 0.9712 - recall: 0.9630 - val_loss: 11631.2871 - val_accuracy: 0.1358 - val_precision: 0.1358 - val_recall: 0.1358\n","Epoch 547/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.0899 - accuracy: 0.9708 - precision: 0.9730 - recall: 0.9681 - val_loss: 14150.7266 - val_accuracy: 0.0998 - val_precision: 0.0998 - val_recall: 0.0998\n","Epoch 548/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0984 - accuracy: 0.9676 - precision: 0.9713 - recall: 0.9649 - val_loss: 12138.2510 - val_accuracy: 0.1327 - val_precision: 0.1327 - val_recall: 0.1327\n","Epoch 549/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1041 - accuracy: 0.9637 - precision: 0.9691 - recall: 0.9605 - val_loss: 12192.0918 - val_accuracy: 0.1368 - val_precision: 0.1368 - val_recall: 0.1368\n","Epoch 550/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1177 - accuracy: 0.9603 - precision: 0.9647 - recall: 0.9561 - val_loss: 11597.5244 - val_accuracy: 0.1307 - val_precision: 0.1307 - val_recall: 0.1307\n","Epoch 551/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0952 - accuracy: 0.9689 - precision: 0.9731 - recall: 0.9660 - val_loss: 13308.8613 - val_accuracy: 0.1054 - val_precision: 0.1054 - val_recall: 0.1054\n","Epoch 552/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0977 - accuracy: 0.9654 - precision: 0.9692 - recall: 0.9623 - val_loss: 12239.9834 - val_accuracy: 0.1084 - val_precision: 0.1084 - val_recall: 0.1084\n","Epoch 553/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0927 - accuracy: 0.9674 - precision: 0.9721 - recall: 0.9642 - val_loss: 11624.1602 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 554/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.1079 - accuracy: 0.9647 - precision: 0.9677 - recall: 0.9623 - val_loss: 12835.4834 - val_accuracy: 0.1130 - val_precision: 0.1130 - val_recall: 0.1130\n","Epoch 555/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.0996 - accuracy: 0.9664 - precision: 0.9694 - recall: 0.9633 - val_loss: 11726.6885 - val_accuracy: 0.1297 - val_precision: 0.1297 - val_recall: 0.1297\n","Epoch 556/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1111 - accuracy: 0.9595 - precision: 0.9648 - recall: 0.9552 - val_loss: 13858.0850 - val_accuracy: 0.1013 - val_precision: 0.1013 - val_recall: 0.1013\n","Epoch 557/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1084 - accuracy: 0.9657 - precision: 0.9685 - recall: 0.9622 - val_loss: 12665.7256 - val_accuracy: 0.1282 - val_precision: 0.1282 - val_recall: 0.1282\n","Epoch 558/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1175 - accuracy: 0.9589 - precision: 0.9639 - recall: 0.9551 - val_loss: 11605.3271 - val_accuracy: 0.1449 - val_precision: 0.1449 - val_recall: 0.1449\n","Epoch 559/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.0999 - accuracy: 0.9630 - precision: 0.9672 - recall: 0.9603 - val_loss: 10645.4893 - val_accuracy: 0.1418 - val_precision: 0.1418 - val_recall: 0.1418\n","Epoch 560/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0973 - accuracy: 0.9679 - precision: 0.9706 - recall: 0.9638 - val_loss: 11849.3418 - val_accuracy: 0.1261 - val_precision: 0.1261 - val_recall: 0.1261\n","Epoch 561/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1075 - accuracy: 0.9622 - precision: 0.9660 - recall: 0.9589 - val_loss: 11529.1279 - val_accuracy: 0.1403 - val_precision: 0.1403 - val_recall: 0.1403\n","Epoch 562/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1082 - accuracy: 0.9637 - precision: 0.9667 - recall: 0.9613 - val_loss: 12123.7520 - val_accuracy: 0.1454 - val_precision: 0.1454 - val_recall: 0.1454\n","Epoch 563/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1071 - accuracy: 0.9654 - precision: 0.9697 - recall: 0.9611 - val_loss: 13018.1650 - val_accuracy: 0.1342 - val_precision: 0.1342 - val_recall: 0.1342\n","Epoch 564/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1107 - accuracy: 0.9605 - precision: 0.9644 - recall: 0.9566 - val_loss: 12578.2422 - val_accuracy: 0.1236 - val_precision: 0.1236 - val_recall: 0.1236\n","Epoch 565/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.0860 - accuracy: 0.9708 - precision: 0.9760 - recall: 0.9676 - val_loss: 12710.3184 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 566/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0986 - accuracy: 0.9669 - precision: 0.9704 - recall: 0.9628 - val_loss: 12784.9209 - val_accuracy: 0.1069 - val_precision: 0.1069 - val_recall: 0.1069\n","Epoch 567/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0947 - accuracy: 0.9676 - precision: 0.9718 - recall: 0.9649 - val_loss: 11118.4258 - val_accuracy: 0.1221 - val_precision: 0.1221 - val_recall: 0.1221\n","Epoch 568/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1003 - accuracy: 0.9650 - precision: 0.9692 - recall: 0.9616 - val_loss: 12291.7578 - val_accuracy: 0.1297 - val_precision: 0.1297 - val_recall: 0.1297\n","Epoch 569/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.0957 - accuracy: 0.9662 - precision: 0.9692 - recall: 0.9627 - val_loss: 10900.1367 - val_accuracy: 0.1266 - val_precision: 0.1266 - val_recall: 0.1266\n","Epoch 570/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.0967 - accuracy: 0.9676 - precision: 0.9712 - recall: 0.9632 - val_loss: 11017.9014 - val_accuracy: 0.1393 - val_precision: 0.1393 - val_recall: 0.1393\n","Epoch 571/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0962 - accuracy: 0.9657 - precision: 0.9692 - recall: 0.9625 - val_loss: 12863.5391 - val_accuracy: 0.1018 - val_precision: 0.1018 - val_recall: 0.1018\n","Epoch 572/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0960 - accuracy: 0.9679 - precision: 0.9718 - recall: 0.9655 - val_loss: 11824.7012 - val_accuracy: 0.1185 - val_precision: 0.1185 - val_recall: 0.1185\n","Epoch 573/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.0972 - accuracy: 0.9677 - precision: 0.9721 - recall: 0.9647 - val_loss: 10842.8896 - val_accuracy: 0.1353 - val_precision: 0.1353 - val_recall: 0.1353\n","Epoch 574/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.0823 - accuracy: 0.9713 - precision: 0.9750 - recall: 0.9676 - val_loss: 13197.0762 - val_accuracy: 0.1089 - val_precision: 0.1089 - val_recall: 0.1089\n","Epoch 575/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1020 - accuracy: 0.9650 - precision: 0.9682 - recall: 0.9630 - val_loss: 13717.7832 - val_accuracy: 0.1079 - val_precision: 0.1079 - val_recall: 0.1079\n","Epoch 576/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1026 - accuracy: 0.9649 - precision: 0.9703 - recall: 0.9600 - val_loss: 13088.9404 - val_accuracy: 0.1180 - val_precision: 0.1180 - val_recall: 0.1180\n","Epoch 577/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.0966 - accuracy: 0.9669 - precision: 0.9708 - recall: 0.9645 - val_loss: 12194.8701 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 578/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.1001 - accuracy: 0.9649 - precision: 0.9679 - recall: 0.9623 - val_loss: 11892.1113 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 579/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0988 - accuracy: 0.9638 - precision: 0.9683 - recall: 0.9608 - val_loss: 11219.7510 - val_accuracy: 0.1226 - val_precision: 0.1226 - val_recall: 0.1226\n","Epoch 580/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0983 - accuracy: 0.9660 - precision: 0.9701 - recall: 0.9635 - val_loss: 12714.1836 - val_accuracy: 0.1160 - val_precision: 0.1160 - val_recall: 0.1160\n","Epoch 581/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.0893 - accuracy: 0.9711 - precision: 0.9725 - recall: 0.9682 - val_loss: 13272.7080 - val_accuracy: 0.1287 - val_precision: 0.1287 - val_recall: 0.1287\n","Epoch 582/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1008 - accuracy: 0.9657 - precision: 0.9690 - recall: 0.9623 - val_loss: 12650.2656 - val_accuracy: 0.1388 - val_precision: 0.1388 - val_recall: 0.1388\n","Epoch 583/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0904 - accuracy: 0.9703 - precision: 0.9728 - recall: 0.9667 - val_loss: 12018.9385 - val_accuracy: 0.1378 - val_precision: 0.1378 - val_recall: 0.1378\n","Epoch 584/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0884 - accuracy: 0.9672 - precision: 0.9701 - recall: 0.9642 - val_loss: 12483.9121 - val_accuracy: 0.1322 - val_precision: 0.1322 - val_recall: 0.1322\n","Epoch 585/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.0833 - accuracy: 0.9726 - precision: 0.9757 - recall: 0.9686 - val_loss: 14121.6543 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 586/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0825 - accuracy: 0.9738 - precision: 0.9774 - recall: 0.9711 - val_loss: 11602.9639 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 587/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0875 - accuracy: 0.9704 - precision: 0.9741 - recall: 0.9676 - val_loss: 14430.6943 - val_accuracy: 0.1044 - val_precision: 0.1044 - val_recall: 0.1044\n","Epoch 588/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0915 - accuracy: 0.9691 - precision: 0.9730 - recall: 0.9664 - val_loss: 15824.7402 - val_accuracy: 0.0932 - val_precision: 0.0932 - val_recall: 0.0932\n","Epoch 589/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.0908 - accuracy: 0.9706 - precision: 0.9743 - recall: 0.9659 - val_loss: 11259.6807 - val_accuracy: 0.1439 - val_precision: 0.1439 - val_recall: 0.1439\n","Epoch 590/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.0846 - accuracy: 0.9720 - precision: 0.9758 - recall: 0.9693 - val_loss: 11061.1729 - val_accuracy: 0.1434 - val_precision: 0.1434 - val_recall: 0.1434\n","Epoch 591/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0911 - accuracy: 0.9691 - precision: 0.9729 - recall: 0.9650 - val_loss: 13134.3184 - val_accuracy: 0.1231 - val_precision: 0.1231 - val_recall: 0.1231\n","Epoch 592/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.0940 - accuracy: 0.9687 - precision: 0.9730 - recall: 0.9664 - val_loss: 10697.7002 - val_accuracy: 0.1322 - val_precision: 0.1322 - val_recall: 0.1322\n","Epoch 593/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.0981 - accuracy: 0.9693 - precision: 0.9731 - recall: 0.9664 - val_loss: 13379.4316 - val_accuracy: 0.1044 - val_precision: 0.1044 - val_recall: 0.1044\n","Epoch 594/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1016 - accuracy: 0.9654 - precision: 0.9677 - recall: 0.9620 - val_loss: 12679.0283 - val_accuracy: 0.1201 - val_precision: 0.1201 - val_recall: 0.1201\n","Epoch 595/10000\n","185/185 [==============================] - 15s 82ms/step - loss: 0.0958 - accuracy: 0.9667 - precision: 0.9692 - recall: 0.9637 - val_loss: 13766.5713 - val_accuracy: 0.0993 - val_precision: 0.0993 - val_recall: 0.0993\n","Epoch 596/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0817 - accuracy: 0.9689 - precision: 0.9738 - recall: 0.9677 - val_loss: 13395.4492 - val_accuracy: 0.1140 - val_precision: 0.1140 - val_recall: 0.1140\n","Epoch 597/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0886 - accuracy: 0.9713 - precision: 0.9729 - recall: 0.9687 - val_loss: 11690.9014 - val_accuracy: 0.1211 - val_precision: 0.1211 - val_recall: 0.1211\n","Epoch 598/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0820 - accuracy: 0.9704 - precision: 0.9735 - recall: 0.9681 - val_loss: 13441.9766 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 599/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0907 - accuracy: 0.9686 - precision: 0.9721 - recall: 0.9659 - val_loss: 11930.8135 - val_accuracy: 0.1023 - val_precision: 0.1023 - val_recall: 0.1023\n","Epoch 600/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0979 - accuracy: 0.9677 - precision: 0.9709 - recall: 0.9647 - val_loss: 12658.7646 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 601/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0884 - accuracy: 0.9696 - precision: 0.9731 - recall: 0.9671 - val_loss: 14503.3066 - val_accuracy: 0.1049 - val_precision: 0.1049 - val_recall: 0.1049\n","Epoch 602/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0938 - accuracy: 0.9654 - precision: 0.9700 - recall: 0.9620 - val_loss: 12975.3594 - val_accuracy: 0.1044 - val_precision: 0.1044 - val_recall: 0.1044\n","Epoch 603/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0853 - accuracy: 0.9704 - precision: 0.9743 - recall: 0.9674 - val_loss: 12389.9609 - val_accuracy: 0.1211 - val_precision: 0.1211 - val_recall: 0.1211\n","Epoch 604/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0915 - accuracy: 0.9665 - precision: 0.9696 - recall: 0.9647 - val_loss: 14337.7471 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 605/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0834 - accuracy: 0.9720 - precision: 0.9740 - recall: 0.9689 - val_loss: 11429.1885 - val_accuracy: 0.1403 - val_precision: 0.1403 - val_recall: 0.1403\n","Epoch 606/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0919 - accuracy: 0.9686 - precision: 0.9718 - recall: 0.9665 - val_loss: 10983.0752 - val_accuracy: 0.1418 - val_precision: 0.1418 - val_recall: 0.1418\n","Epoch 607/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0977 - accuracy: 0.9665 - precision: 0.9697 - recall: 0.9632 - val_loss: 12899.1855 - val_accuracy: 0.1287 - val_precision: 0.1287 - val_recall: 0.1287\n","Epoch 608/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0870 - accuracy: 0.9703 - precision: 0.9733 - recall: 0.9672 - val_loss: 12353.3457 - val_accuracy: 0.1140 - val_precision: 0.1140 - val_recall: 0.1140\n","Epoch 609/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0767 - accuracy: 0.9709 - precision: 0.9732 - recall: 0.9677 - val_loss: 13994.8857 - val_accuracy: 0.1201 - val_precision: 0.1201 - val_recall: 0.1201\n","Epoch 610/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0843 - accuracy: 0.9714 - precision: 0.9735 - recall: 0.9689 - val_loss: 11380.5723 - val_accuracy: 0.1418 - val_precision: 0.1418 - val_recall: 0.1418\n","Epoch 611/10000\n","185/185 [==============================] - 15s 84ms/step - loss: 0.0966 - accuracy: 0.9654 - precision: 0.9676 - recall: 0.9627 - val_loss: 13483.0215 - val_accuracy: 0.1185 - val_precision: 0.1185 - val_recall: 0.1185\n","Epoch 612/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0938 - accuracy: 0.9686 - precision: 0.9724 - recall: 0.9659 - val_loss: 12703.1836 - val_accuracy: 0.1160 - val_precision: 0.1160 - val_recall: 0.1160\n","Epoch 613/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0915 - accuracy: 0.9704 - precision: 0.9730 - recall: 0.9665 - val_loss: 12784.4102 - val_accuracy: 0.1241 - val_precision: 0.1241 - val_recall: 0.1241\n","Epoch 614/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0938 - accuracy: 0.9664 - precision: 0.9702 - recall: 0.9637 - val_loss: 11664.2852 - val_accuracy: 0.1236 - val_precision: 0.1236 - val_recall: 0.1236\n","Epoch 615/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0891 - accuracy: 0.9691 - precision: 0.9718 - recall: 0.9662 - val_loss: 12626.2383 - val_accuracy: 0.1089 - val_precision: 0.1089 - val_recall: 0.1089\n","Epoch 616/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.0908 - accuracy: 0.9701 - precision: 0.9728 - recall: 0.9674 - val_loss: 11585.2832 - val_accuracy: 0.1297 - val_precision: 0.1297 - val_recall: 0.1297\n","Epoch 617/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0865 - accuracy: 0.9731 - precision: 0.9764 - recall: 0.9709 - val_loss: 13675.1807 - val_accuracy: 0.1084 - val_precision: 0.1084 - val_recall: 0.1084\n","Epoch 618/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1053 - accuracy: 0.9650 - precision: 0.9681 - recall: 0.9627 - val_loss: 12591.4717 - val_accuracy: 0.1120 - val_precision: 0.1120 - val_recall: 0.1120\n","Epoch 619/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1033 - accuracy: 0.9642 - precision: 0.9680 - recall: 0.9601 - val_loss: 12123.9570 - val_accuracy: 0.1398 - val_precision: 0.1398 - val_recall: 0.1398\n","Epoch 620/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0959 - accuracy: 0.9677 - precision: 0.9721 - recall: 0.9650 - val_loss: 13245.5654 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 621/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0923 - accuracy: 0.9699 - precision: 0.9731 - recall: 0.9667 - val_loss: 15981.5361 - val_accuracy: 0.0983 - val_precision: 0.0983 - val_recall: 0.0983\n","Epoch 622/10000\n","185/185 [==============================] - 15s 84ms/step - loss: 0.0978 - accuracy: 0.9647 - precision: 0.9682 - recall: 0.9622 - val_loss: 12202.8418 - val_accuracy: 0.1211 - val_precision: 0.1211 - val_recall: 0.1211\n","Epoch 623/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.1022 - accuracy: 0.9645 - precision: 0.9685 - recall: 0.9618 - val_loss: 13882.4980 - val_accuracy: 0.1292 - val_precision: 0.1292 - val_recall: 0.1292\n","Epoch 624/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0945 - accuracy: 0.9694 - precision: 0.9735 - recall: 0.9665 - val_loss: 13438.2979 - val_accuracy: 0.1049 - val_precision: 0.1049 - val_recall: 0.1049\n","Epoch 625/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0975 - accuracy: 0.9684 - precision: 0.9722 - recall: 0.9647 - val_loss: 12449.8965 - val_accuracy: 0.1388 - val_precision: 0.1388 - val_recall: 0.1388\n","Epoch 626/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0918 - accuracy: 0.9699 - precision: 0.9735 - recall: 0.9679 - val_loss: 13842.5928 - val_accuracy: 0.0998 - val_precision: 0.0998 - val_recall: 0.0998\n","Epoch 627/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0961 - accuracy: 0.9681 - precision: 0.9721 - recall: 0.9654 - val_loss: 11925.1318 - val_accuracy: 0.1459 - val_precision: 0.1459 - val_recall: 0.1459\n","Epoch 628/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0886 - accuracy: 0.9684 - precision: 0.9713 - recall: 0.9652 - val_loss: 14614.3291 - val_accuracy: 0.1109 - val_precision: 0.1109 - val_recall: 0.1109\n","Epoch 629/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0809 - accuracy: 0.9713 - precision: 0.9752 - recall: 0.9693 - val_loss: 12347.3848 - val_accuracy: 0.1185 - val_precision: 0.1185 - val_recall: 0.1185\n","Epoch 630/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0915 - accuracy: 0.9694 - precision: 0.9731 - recall: 0.9674 - val_loss: 13960.6191 - val_accuracy: 0.0957 - val_precision: 0.0957 - val_recall: 0.0957\n","Epoch 631/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 0.0945 - accuracy: 0.9677 - precision: 0.9708 - recall: 0.9664 - val_loss: 11711.5615 - val_accuracy: 0.1206 - val_precision: 0.1206 - val_recall: 0.1206\n","Epoch 632/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0951 - accuracy: 0.9662 - precision: 0.9702 - recall: 0.9638 - val_loss: 12111.1787 - val_accuracy: 0.1125 - val_precision: 0.1125 - val_recall: 0.1125\n","Epoch 633/10000\n","185/185 [==============================] - 15s 84ms/step - loss: 0.1054 - accuracy: 0.9652 - precision: 0.9676 - recall: 0.9633 - val_loss: 11392.7178 - val_accuracy: 0.1196 - val_precision: 0.1196 - val_recall: 0.1196\n","Epoch 634/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0845 - accuracy: 0.9703 - precision: 0.9725 - recall: 0.9677 - val_loss: 11674.1924 - val_accuracy: 0.1353 - val_precision: 0.1353 - val_recall: 0.1353\n","Epoch 635/10000\n","185/185 [==============================] - 15s 84ms/step - loss: 0.0730 - accuracy: 0.9750 - precision: 0.9774 - recall: 0.9730 - val_loss: 11259.7217 - val_accuracy: 0.1383 - val_precision: 0.1383 - val_recall: 0.1383\n","Epoch 636/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0872 - accuracy: 0.9682 - precision: 0.9718 - recall: 0.9655 - val_loss: 13558.5498 - val_accuracy: 0.1211 - val_precision: 0.1211 - val_recall: 0.1211\n","Epoch 637/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0894 - accuracy: 0.9713 - precision: 0.9738 - recall: 0.9681 - val_loss: 13096.2803 - val_accuracy: 0.1033 - val_precision: 0.1033 - val_recall: 0.1033\n","Epoch 638/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0924 - accuracy: 0.9679 - precision: 0.9711 - recall: 0.9649 - val_loss: 13293.5654 - val_accuracy: 0.1155 - val_precision: 0.1155 - val_recall: 0.1155\n","Epoch 639/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0752 - accuracy: 0.9742 - precision: 0.9776 - recall: 0.9718 - val_loss: 13440.7617 - val_accuracy: 0.1120 - val_precision: 0.1120 - val_recall: 0.1120\n","Epoch 640/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0966 - accuracy: 0.9701 - precision: 0.9730 - recall: 0.9664 - val_loss: 12822.7920 - val_accuracy: 0.1190 - val_precision: 0.1190 - val_recall: 0.1190\n","Epoch 641/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0824 - accuracy: 0.9714 - precision: 0.9745 - recall: 0.9696 - val_loss: 12628.0127 - val_accuracy: 0.1413 - val_precision: 0.1413 - val_recall: 0.1413\n","Epoch 642/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0842 - accuracy: 0.9691 - precision: 0.9728 - recall: 0.9667 - val_loss: 10781.1230 - val_accuracy: 0.1403 - val_precision: 0.1403 - val_recall: 0.1403\n","Epoch 643/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0734 - accuracy: 0.9731 - precision: 0.9752 - recall: 0.9714 - val_loss: 11924.9600 - val_accuracy: 0.1251 - val_precision: 0.1251 - val_recall: 0.1251\n","Epoch 644/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0735 - accuracy: 0.9740 - precision: 0.9772 - recall: 0.9709 - val_loss: 14095.3145 - val_accuracy: 0.1114 - val_precision: 0.1114 - val_recall: 0.1114\n","Epoch 645/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0777 - accuracy: 0.9733 - precision: 0.9761 - recall: 0.9711 - val_loss: 13176.1973 - val_accuracy: 0.1125 - val_precision: 0.1125 - val_recall: 0.1125\n","Epoch 646/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 0.0817 - accuracy: 0.9714 - precision: 0.9749 - recall: 0.9708 - val_loss: 14074.7988 - val_accuracy: 0.1003 - val_precision: 0.1003 - val_recall: 0.1003\n","Epoch 647/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0863 - accuracy: 0.9689 - precision: 0.9716 - recall: 0.9659 - val_loss: 11240.1191 - val_accuracy: 0.1363 - val_precision: 0.1363 - val_recall: 0.1363\n","Epoch 648/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0888 - accuracy: 0.9687 - precision: 0.9706 - recall: 0.9664 - val_loss: 10542.4902 - val_accuracy: 0.1459 - val_precision: 0.1459 - val_recall: 0.1459\n","Epoch 649/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0796 - accuracy: 0.9709 - precision: 0.9750 - recall: 0.9694 - val_loss: 11839.7207 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 650/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0833 - accuracy: 0.9718 - precision: 0.9757 - recall: 0.9687 - val_loss: 10308.1855 - val_accuracy: 0.1434 - val_precision: 0.1434 - val_recall: 0.1434\n","Epoch 651/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0923 - accuracy: 0.9694 - precision: 0.9722 - recall: 0.9672 - val_loss: 10801.6162 - val_accuracy: 0.1282 - val_precision: 0.1282 - val_recall: 0.1282\n","Epoch 652/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0951 - accuracy: 0.9655 - precision: 0.9702 - recall: 0.9635 - val_loss: 14197.9746 - val_accuracy: 0.1049 - val_precision: 0.1049 - val_recall: 0.1049\n","Epoch 653/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0870 - accuracy: 0.9716 - precision: 0.9735 - recall: 0.9684 - val_loss: 12831.0088 - val_accuracy: 0.1114 - val_precision: 0.1114 - val_recall: 0.1114\n","Epoch 654/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0781 - accuracy: 0.9748 - precision: 0.9777 - recall: 0.9716 - val_loss: 14263.3115 - val_accuracy: 0.0988 - val_precision: 0.0988 - val_recall: 0.0988\n","Epoch 655/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0870 - accuracy: 0.9720 - precision: 0.9749 - recall: 0.9699 - val_loss: 13644.1699 - val_accuracy: 0.1003 - val_precision: 0.1003 - val_recall: 0.1003\n","Epoch 656/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0828 - accuracy: 0.9730 - precision: 0.9758 - recall: 0.9689 - val_loss: 13298.3271 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 657/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0891 - accuracy: 0.9713 - precision: 0.9740 - recall: 0.9689 - val_loss: 12930.3760 - val_accuracy: 0.1094 - val_precision: 0.1094 - val_recall: 0.1094\n","Epoch 658/10000\n","185/185 [==============================] - 15s 84ms/step - loss: 0.0873 - accuracy: 0.9714 - precision: 0.9745 - recall: 0.9686 - val_loss: 13758.8877 - val_accuracy: 0.1039 - val_precision: 0.1039 - val_recall: 0.1039\n","Epoch 659/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0785 - accuracy: 0.9730 - precision: 0.9752 - recall: 0.9706 - val_loss: 12376.3701 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 660/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0741 - accuracy: 0.9757 - precision: 0.9784 - recall: 0.9735 - val_loss: 12126.4033 - val_accuracy: 0.1282 - val_precision: 0.1282 - val_recall: 0.1282\n","Epoch 661/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 0.0926 - accuracy: 0.9691 - precision: 0.9726 - recall: 0.9672 - val_loss: 15176.9072 - val_accuracy: 0.0957 - val_precision: 0.0957 - val_recall: 0.0957\n","Epoch 662/10000\n","185/185 [==============================] - 15s 83ms/step - loss: 0.0750 - accuracy: 0.9733 - precision: 0.9759 - recall: 0.9711 - val_loss: 11894.5449 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 663/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0863 - accuracy: 0.9720 - precision: 0.9737 - recall: 0.9693 - val_loss: 11696.0830 - val_accuracy: 0.1190 - val_precision: 0.1190 - val_recall: 0.1190\n","Epoch 664/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0826 - accuracy: 0.9748 - precision: 0.9771 - recall: 0.9728 - val_loss: 13776.4375 - val_accuracy: 0.1206 - val_precision: 0.1206 - val_recall: 0.1206\n","Epoch 665/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0856 - accuracy: 0.9721 - precision: 0.9745 - recall: 0.9699 - val_loss: 14665.3340 - val_accuracy: 0.1099 - val_precision: 0.1099 - val_recall: 0.1099\n","Epoch 666/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0839 - accuracy: 0.9726 - precision: 0.9764 - recall: 0.9703 - val_loss: 14462.1572 - val_accuracy: 0.1008 - val_precision: 0.1008 - val_recall: 0.1008\n","Epoch 667/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0886 - accuracy: 0.9698 - precision: 0.9743 - recall: 0.9677 - val_loss: 12056.1035 - val_accuracy: 0.1160 - val_precision: 0.1160 - val_recall: 0.1160\n","Epoch 668/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0977 - accuracy: 0.9671 - precision: 0.9696 - recall: 0.9640 - val_loss: 15899.6904 - val_accuracy: 0.0907 - val_precision: 0.0907 - val_recall: 0.0907\n","Epoch 669/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0772 - accuracy: 0.9733 - precision: 0.9757 - recall: 0.9711 - val_loss: 12937.1240 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 670/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0722 - accuracy: 0.9774 - precision: 0.9790 - recall: 0.9753 - val_loss: 12712.1143 - val_accuracy: 0.1160 - val_precision: 0.1160 - val_recall: 0.1160\n","Epoch 671/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0875 - accuracy: 0.9687 - precision: 0.9728 - recall: 0.9669 - val_loss: 10324.3545 - val_accuracy: 0.1363 - val_precision: 0.1363 - val_recall: 0.1363\n","Epoch 672/10000\n","185/185 [==============================] - 15s 84ms/step - loss: 0.0720 - accuracy: 0.9758 - precision: 0.9781 - recall: 0.9738 - val_loss: 12736.7725 - val_accuracy: 0.1196 - val_precision: 0.1196 - val_recall: 0.1196\n","Epoch 673/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0752 - accuracy: 0.9742 - precision: 0.9759 - recall: 0.9713 - val_loss: 11646.9854 - val_accuracy: 0.1302 - val_precision: 0.1302 - val_recall: 0.1302\n","Epoch 674/10000\n","185/185 [==============================] - 15s 84ms/step - loss: 0.0841 - accuracy: 0.9723 - precision: 0.9745 - recall: 0.9701 - val_loss: 14048.5957 - val_accuracy: 0.0968 - val_precision: 0.0968 - val_recall: 0.0968\n","Epoch 675/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0729 - accuracy: 0.9738 - precision: 0.9766 - recall: 0.9716 - val_loss: 12364.4043 - val_accuracy: 0.1322 - val_precision: 0.1322 - val_recall: 0.1322\n","Epoch 676/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 0.0813 - accuracy: 0.9728 - precision: 0.9760 - recall: 0.9703 - val_loss: 13625.3906 - val_accuracy: 0.1069 - val_precision: 0.1069 - val_recall: 0.1069\n","Epoch 677/10000\n","185/185 [==============================] - 15s 84ms/step - loss: 0.0793 - accuracy: 0.9706 - precision: 0.9730 - recall: 0.9684 - val_loss: 12955.8398 - val_accuracy: 0.1201 - val_precision: 0.1201 - val_recall: 0.1201\n","Epoch 678/10000\n","185/185 [==============================] - 15s 84ms/step - loss: 0.0820 - accuracy: 0.9738 - precision: 0.9759 - recall: 0.9718 - val_loss: 12899.5459 - val_accuracy: 0.1135 - val_precision: 0.1135 - val_recall: 0.1135\n","Epoch 679/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0812 - accuracy: 0.9716 - precision: 0.9747 - recall: 0.9693 - val_loss: 11731.1943 - val_accuracy: 0.1322 - val_precision: 0.1322 - val_recall: 0.1322\n","Epoch 680/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0776 - accuracy: 0.9736 - precision: 0.9784 - recall: 0.9709 - val_loss: 13553.3135 - val_accuracy: 0.1125 - val_precision: 0.1125 - val_recall: 0.1125\n","Epoch 681/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0795 - accuracy: 0.9718 - precision: 0.9734 - recall: 0.9696 - val_loss: 12096.6475 - val_accuracy: 0.1327 - val_precision: 0.1327 - val_recall: 0.1327\n","Epoch 682/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.0778 - accuracy: 0.9733 - precision: 0.9759 - recall: 0.9716 - val_loss: 13969.6797 - val_accuracy: 0.1180 - val_precision: 0.1180 - val_recall: 0.1180\n","Epoch 683/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0834 - accuracy: 0.9721 - precision: 0.9752 - recall: 0.9706 - val_loss: 13758.7725 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 684/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0769 - accuracy: 0.9733 - precision: 0.9764 - recall: 0.9718 - val_loss: 12484.5947 - val_accuracy: 0.1302 - val_precision: 0.1302 - val_recall: 0.1302\n","Epoch 685/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0857 - accuracy: 0.9716 - precision: 0.9740 - recall: 0.9701 - val_loss: 10468.5391 - val_accuracy: 0.1474 - val_precision: 0.1474 - val_recall: 0.1474\n","Epoch 686/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0850 - accuracy: 0.9730 - precision: 0.9754 - recall: 0.9714 - val_loss: 11816.3711 - val_accuracy: 0.1398 - val_precision: 0.1398 - val_recall: 0.1398\n","Epoch 687/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0796 - accuracy: 0.9735 - precision: 0.9757 - recall: 0.9718 - val_loss: 12780.4258 - val_accuracy: 0.1236 - val_precision: 0.1236 - val_recall: 0.1236\n","Epoch 688/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0698 - accuracy: 0.9757 - precision: 0.9783 - recall: 0.9735 - val_loss: 12633.2236 - val_accuracy: 0.1231 - val_precision: 0.1231 - val_recall: 0.1231\n","Epoch 689/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0843 - accuracy: 0.9706 - precision: 0.9727 - recall: 0.9689 - val_loss: 11987.5664 - val_accuracy: 0.1332 - val_precision: 0.1332 - val_recall: 0.1332\n","Epoch 690/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 0.0770 - accuracy: 0.9723 - precision: 0.9754 - recall: 0.9703 - val_loss: 13031.4629 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 691/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0821 - accuracy: 0.9738 - precision: 0.9757 - recall: 0.9711 - val_loss: 11387.1914 - val_accuracy: 0.1444 - val_precision: 0.1444 - val_recall: 0.1444\n","Epoch 692/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0684 - accuracy: 0.9763 - precision: 0.9779 - recall: 0.9740 - val_loss: 12681.4141 - val_accuracy: 0.1353 - val_precision: 0.1353 - val_recall: 0.1353\n","Epoch 693/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0833 - accuracy: 0.9728 - precision: 0.9744 - recall: 0.9706 - val_loss: 10836.3418 - val_accuracy: 0.1434 - val_precision: 0.1434 - val_recall: 0.1434\n","Epoch 694/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0758 - accuracy: 0.9765 - precision: 0.9784 - recall: 0.9736 - val_loss: 11263.2910 - val_accuracy: 0.1540 - val_precision: 0.1540 - val_recall: 0.1540\n","Epoch 695/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0719 - accuracy: 0.9765 - precision: 0.9783 - recall: 0.9743 - val_loss: 12987.2930 - val_accuracy: 0.1429 - val_precision: 0.1429 - val_recall: 0.1429\n","Epoch 696/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0723 - accuracy: 0.9794 - precision: 0.9817 - recall: 0.9775 - val_loss: 13509.3818 - val_accuracy: 0.1099 - val_precision: 0.1099 - val_recall: 0.1099\n","Epoch 697/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0753 - accuracy: 0.9731 - precision: 0.9757 - recall: 0.9706 - val_loss: 12792.8750 - val_accuracy: 0.1069 - val_precision: 0.1069 - val_recall: 0.1069\n","Epoch 698/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0816 - accuracy: 0.9714 - precision: 0.9739 - recall: 0.9703 - val_loss: 14381.4941 - val_accuracy: 0.0983 - val_precision: 0.0983 - val_recall: 0.0983\n","Epoch 699/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0863 - accuracy: 0.9716 - precision: 0.9744 - recall: 0.9701 - val_loss: 14458.2793 - val_accuracy: 0.1059 - val_precision: 0.1059 - val_recall: 0.1059\n","Epoch 700/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0741 - accuracy: 0.9742 - precision: 0.9764 - recall: 0.9723 - val_loss: 12319.8311 - val_accuracy: 0.1246 - val_precision: 0.1246 - val_recall: 0.1246\n","Epoch 701/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0786 - accuracy: 0.9760 - precision: 0.9784 - recall: 0.9742 - val_loss: 12550.9961 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 702/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0705 - accuracy: 0.9760 - precision: 0.9783 - recall: 0.9735 - val_loss: 12799.2217 - val_accuracy: 0.1332 - val_precision: 0.1332 - val_recall: 0.1332\n","Epoch 703/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0844 - accuracy: 0.9733 - precision: 0.9752 - recall: 0.9713 - val_loss: 13607.3301 - val_accuracy: 0.1196 - val_precision: 0.1196 - val_recall: 0.1196\n","Epoch 704/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0735 - accuracy: 0.9740 - precision: 0.9762 - recall: 0.9714 - val_loss: 11864.2139 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 705/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 0.0680 - accuracy: 0.9762 - precision: 0.9789 - recall: 0.9736 - val_loss: 14329.3330 - val_accuracy: 0.1104 - val_precision: 0.1104 - val_recall: 0.1104\n","Epoch 706/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0666 - accuracy: 0.9750 - precision: 0.9774 - recall: 0.9738 - val_loss: 12652.5977 - val_accuracy: 0.1221 - val_precision: 0.1221 - val_recall: 0.1221\n","Epoch 707/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0786 - accuracy: 0.9718 - precision: 0.9743 - recall: 0.9686 - val_loss: 12590.1494 - val_accuracy: 0.1160 - val_precision: 0.1160 - val_recall: 0.1160\n","Epoch 708/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0791 - accuracy: 0.9730 - precision: 0.9762 - recall: 0.9714 - val_loss: 13801.9570 - val_accuracy: 0.1246 - val_precision: 0.1246 - val_recall: 0.1246\n","Epoch 709/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0649 - accuracy: 0.9758 - precision: 0.9775 - recall: 0.9742 - val_loss: 13525.8369 - val_accuracy: 0.1018 - val_precision: 0.1018 - val_recall: 0.1018\n","Epoch 710/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0771 - accuracy: 0.9760 - precision: 0.9788 - recall: 0.9740 - val_loss: 12827.3584 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 711/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0696 - accuracy: 0.9770 - precision: 0.9785 - recall: 0.9755 - val_loss: 15549.5479 - val_accuracy: 0.1094 - val_precision: 0.1094 - val_recall: 0.1094\n","Epoch 712/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0712 - accuracy: 0.9750 - precision: 0.9774 - recall: 0.9721 - val_loss: 15583.0381 - val_accuracy: 0.0998 - val_precision: 0.0998 - val_recall: 0.0998\n","Epoch 713/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0685 - accuracy: 0.9779 - precision: 0.9798 - recall: 0.9767 - val_loss: 12407.2139 - val_accuracy: 0.1089 - val_precision: 0.1089 - val_recall: 0.1089\n","Epoch 714/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0728 - accuracy: 0.9752 - precision: 0.9779 - recall: 0.9736 - val_loss: 14515.9658 - val_accuracy: 0.1018 - val_precision: 0.1018 - val_recall: 0.1018\n","Epoch 715/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0718 - accuracy: 0.9762 - precision: 0.9778 - recall: 0.9742 - val_loss: 13396.9961 - val_accuracy: 0.1196 - val_precision: 0.1196 - val_recall: 0.1196\n","Epoch 716/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0787 - accuracy: 0.9720 - precision: 0.9740 - recall: 0.9701 - val_loss: 13797.2139 - val_accuracy: 0.1226 - val_precision: 0.1226 - val_recall: 0.1226\n","Epoch 717/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0691 - accuracy: 0.9780 - precision: 0.9798 - recall: 0.9763 - val_loss: 12510.4736 - val_accuracy: 0.1231 - val_precision: 0.1231 - val_recall: 0.1231\n","Epoch 718/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0763 - accuracy: 0.9750 - precision: 0.9774 - recall: 0.9735 - val_loss: 13740.6426 - val_accuracy: 0.1104 - val_precision: 0.1104 - val_recall: 0.1104\n","Epoch 719/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 0.0744 - accuracy: 0.9736 - precision: 0.9764 - recall: 0.9716 - val_loss: 13378.4062 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 720/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0712 - accuracy: 0.9760 - precision: 0.9791 - recall: 0.9743 - val_loss: 15251.2148 - val_accuracy: 0.0983 - val_precision: 0.0983 - val_recall: 0.0983\n","Epoch 721/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0819 - accuracy: 0.9720 - precision: 0.9742 - recall: 0.9706 - val_loss: 13732.3760 - val_accuracy: 0.1236 - val_precision: 0.1236 - val_recall: 0.1236\n","Epoch 722/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0821 - accuracy: 0.9757 - precision: 0.9776 - recall: 0.9723 - val_loss: 14463.0205 - val_accuracy: 0.1064 - val_precision: 0.1064 - val_recall: 0.1064\n","Epoch 723/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0731 - accuracy: 0.9763 - precision: 0.9788 - recall: 0.9742 - val_loss: 12958.8438 - val_accuracy: 0.1261 - val_precision: 0.1261 - val_recall: 0.1261\n","Epoch 724/10000\n","185/185 [==============================] - 16s 84ms/step - loss: 0.0689 - accuracy: 0.9755 - precision: 0.9776 - recall: 0.9742 - val_loss: 11230.7881 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 725/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0621 - accuracy: 0.9777 - precision: 0.9798 - recall: 0.9748 - val_loss: 13134.3203 - val_accuracy: 0.1332 - val_precision: 0.1332 - val_recall: 0.1332\n","Epoch 726/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0744 - accuracy: 0.9750 - precision: 0.9771 - recall: 0.9730 - val_loss: 11777.4707 - val_accuracy: 0.1413 - val_precision: 0.1413 - val_recall: 0.1413\n","Epoch 727/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0721 - accuracy: 0.9750 - precision: 0.9774 - recall: 0.9735 - val_loss: 11635.4619 - val_accuracy: 0.1272 - val_precision: 0.1272 - val_recall: 0.1272\n","Epoch 728/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0762 - accuracy: 0.9738 - precision: 0.9757 - recall: 0.9718 - val_loss: 12774.1709 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 729/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0691 - accuracy: 0.9747 - precision: 0.9768 - recall: 0.9735 - val_loss: 11923.3877 - val_accuracy: 0.1454 - val_precision: 0.1454 - val_recall: 0.1454\n","Epoch 730/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0651 - accuracy: 0.9777 - precision: 0.9795 - recall: 0.9750 - val_loss: 10910.8623 - val_accuracy: 0.1439 - val_precision: 0.1439 - val_recall: 0.1439\n","Epoch 731/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0676 - accuracy: 0.9763 - precision: 0.9779 - recall: 0.9738 - val_loss: 13496.4043 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 732/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0703 - accuracy: 0.9765 - precision: 0.9783 - recall: 0.9735 - val_loss: 13769.4971 - val_accuracy: 0.1155 - val_precision: 0.1155 - val_recall: 0.1155\n","Epoch 733/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 0.0631 - accuracy: 0.9796 - precision: 0.9810 - recall: 0.9777 - val_loss: 13713.9854 - val_accuracy: 0.0988 - val_precision: 0.0988 - val_recall: 0.0988\n","Epoch 734/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0780 - accuracy: 0.9740 - precision: 0.9758 - recall: 0.9726 - val_loss: 13200.8555 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 735/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0718 - accuracy: 0.9743 - precision: 0.9767 - recall: 0.9720 - val_loss: 14075.3018 - val_accuracy: 0.1018 - val_precision: 0.1018 - val_recall: 0.1018\n","Epoch 736/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0672 - accuracy: 0.9763 - precision: 0.9783 - recall: 0.9750 - val_loss: 13114.7646 - val_accuracy: 0.1104 - val_precision: 0.1104 - val_recall: 0.1104\n","Epoch 737/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0651 - accuracy: 0.9767 - precision: 0.9786 - recall: 0.9748 - val_loss: 11400.4854 - val_accuracy: 0.1434 - val_precision: 0.1434 - val_recall: 0.1434\n","Epoch 738/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0600 - accuracy: 0.9802 - precision: 0.9820 - recall: 0.9780 - val_loss: 14071.7783 - val_accuracy: 0.0968 - val_precision: 0.0968 - val_recall: 0.0968\n","Epoch 739/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0691 - accuracy: 0.9774 - precision: 0.9795 - recall: 0.9762 - val_loss: 12897.7832 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 740/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0776 - accuracy: 0.9728 - precision: 0.9759 - recall: 0.9709 - val_loss: 13791.6309 - val_accuracy: 0.1130 - val_precision: 0.1130 - val_recall: 0.1130\n","Epoch 741/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0717 - accuracy: 0.9760 - precision: 0.9785 - recall: 0.9747 - val_loss: 12825.6738 - val_accuracy: 0.1287 - val_precision: 0.1287 - val_recall: 0.1287\n","Epoch 742/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0574 - accuracy: 0.9807 - precision: 0.9825 - recall: 0.9792 - val_loss: 13034.0049 - val_accuracy: 0.1190 - val_precision: 0.1190 - val_recall: 0.1190\n","Epoch 743/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0609 - accuracy: 0.9794 - precision: 0.9819 - recall: 0.9780 - val_loss: 12432.8135 - val_accuracy: 0.1383 - val_precision: 0.1383 - val_recall: 0.1383\n","Epoch 744/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0662 - accuracy: 0.9784 - precision: 0.9798 - recall: 0.9762 - val_loss: 12522.3076 - val_accuracy: 0.1489 - val_precision: 0.1489 - val_recall: 0.1489\n","Epoch 745/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0708 - accuracy: 0.9757 - precision: 0.9779 - recall: 0.9733 - val_loss: 13798.9639 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 746/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0670 - accuracy: 0.9767 - precision: 0.9803 - recall: 0.9740 - val_loss: 12662.1064 - val_accuracy: 0.1373 - val_precision: 0.1373 - val_recall: 0.1373\n","Epoch 747/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 0.0627 - accuracy: 0.9811 - precision: 0.9830 - recall: 0.9784 - val_loss: 12385.5469 - val_accuracy: 0.1342 - val_precision: 0.1342 - val_recall: 0.1342\n","Epoch 748/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0696 - accuracy: 0.9760 - precision: 0.9765 - recall: 0.9738 - val_loss: 11142.7822 - val_accuracy: 0.1464 - val_precision: 0.1464 - val_recall: 0.1464\n","Epoch 749/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0642 - accuracy: 0.9775 - precision: 0.9793 - recall: 0.9762 - val_loss: 10284.6133 - val_accuracy: 0.1606 - val_precision: 0.1606 - val_recall: 0.1606\n","Epoch 750/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0747 - accuracy: 0.9740 - precision: 0.9769 - recall: 0.9721 - val_loss: 12923.7861 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 751/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0864 - accuracy: 0.9740 - precision: 0.9767 - recall: 0.9716 - val_loss: 11661.6719 - val_accuracy: 0.1297 - val_precision: 0.1297 - val_recall: 0.1297\n","Epoch 752/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0840 - accuracy: 0.9713 - precision: 0.9745 - recall: 0.9698 - val_loss: 13137.7764 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 753/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0682 - accuracy: 0.9758 - precision: 0.9781 - recall: 0.9748 - val_loss: 12164.7344 - val_accuracy: 0.1474 - val_precision: 0.1474 - val_recall: 0.1474\n","Epoch 754/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0615 - accuracy: 0.9787 - precision: 0.9800 - recall: 0.9767 - val_loss: 11680.2949 - val_accuracy: 0.1575 - val_precision: 0.1575 - val_recall: 0.1575\n","Epoch 755/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0631 - accuracy: 0.9780 - precision: 0.9797 - recall: 0.9765 - val_loss: 12071.4277 - val_accuracy: 0.1231 - val_precision: 0.1231 - val_recall: 0.1231\n","Epoch 756/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0610 - accuracy: 0.9796 - precision: 0.9820 - recall: 0.9775 - val_loss: 13091.3213 - val_accuracy: 0.1201 - val_precision: 0.1201 - val_recall: 0.1201\n","Epoch 757/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0628 - accuracy: 0.9777 - precision: 0.9808 - recall: 0.9770 - val_loss: 13606.7070 - val_accuracy: 0.1221 - val_precision: 0.1221 - val_recall: 0.1221\n","Epoch 758/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0550 - accuracy: 0.9806 - precision: 0.9832 - recall: 0.9784 - val_loss: 12933.1465 - val_accuracy: 0.1292 - val_precision: 0.1292 - val_recall: 0.1292\n","Epoch 759/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0666 - accuracy: 0.9775 - precision: 0.9792 - recall: 0.9762 - val_loss: 13474.6904 - val_accuracy: 0.1221 - val_precision: 0.1221 - val_recall: 0.1221\n","Epoch 760/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0561 - accuracy: 0.9819 - precision: 0.9839 - recall: 0.9799 - val_loss: 14565.1514 - val_accuracy: 0.1140 - val_precision: 0.1140 - val_recall: 0.1140\n","Epoch 761/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 0.0606 - accuracy: 0.9811 - precision: 0.9824 - recall: 0.9801 - val_loss: 15085.6240 - val_accuracy: 0.1049 - val_precision: 0.1049 - val_recall: 0.1049\n","Epoch 762/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0670 - accuracy: 0.9780 - precision: 0.9797 - recall: 0.9760 - val_loss: 13512.1943 - val_accuracy: 0.1155 - val_precision: 0.1155 - val_recall: 0.1155\n","Epoch 763/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0727 - accuracy: 0.9743 - precision: 0.9789 - recall: 0.9721 - val_loss: 13711.0254 - val_accuracy: 0.1140 - val_precision: 0.1140 - val_recall: 0.1140\n","Epoch 764/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0742 - accuracy: 0.9757 - precision: 0.9776 - recall: 0.9738 - val_loss: 14737.3887 - val_accuracy: 0.1104 - val_precision: 0.1104 - val_recall: 0.1104\n","Epoch 765/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0675 - accuracy: 0.9775 - precision: 0.9793 - recall: 0.9755 - val_loss: 16117.5205 - val_accuracy: 0.1013 - val_precision: 0.1013 - val_recall: 0.1013\n","Epoch 766/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0639 - accuracy: 0.9801 - precision: 0.9815 - recall: 0.9792 - val_loss: 16339.4258 - val_accuracy: 0.0963 - val_precision: 0.0963 - val_recall: 0.0963\n","Epoch 767/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0626 - accuracy: 0.9811 - precision: 0.9821 - recall: 0.9801 - val_loss: 14230.7842 - val_accuracy: 0.1109 - val_precision: 0.1109 - val_recall: 0.1109\n","Epoch 768/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0595 - accuracy: 0.9792 - precision: 0.9807 - recall: 0.9779 - val_loss: 14524.8574 - val_accuracy: 0.1190 - val_precision: 0.1190 - val_recall: 0.1190\n","Epoch 769/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0749 - accuracy: 0.9753 - precision: 0.9770 - recall: 0.9745 - val_loss: 14631.0215 - val_accuracy: 0.1104 - val_precision: 0.1104 - val_recall: 0.1104\n","Epoch 770/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0634 - accuracy: 0.9782 - precision: 0.9800 - recall: 0.9765 - val_loss: 13090.1445 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 771/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0657 - accuracy: 0.9765 - precision: 0.9786 - recall: 0.9742 - val_loss: 11855.8047 - val_accuracy: 0.1353 - val_precision: 0.1353 - val_recall: 0.1353\n","Epoch 772/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0686 - accuracy: 0.9770 - precision: 0.9791 - recall: 0.9755 - val_loss: 13645.5049 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 773/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0750 - accuracy: 0.9747 - precision: 0.9764 - recall: 0.9728 - val_loss: 13033.2402 - val_accuracy: 0.1190 - val_precision: 0.1190 - val_recall: 0.1190\n","Epoch 774/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0658 - accuracy: 0.9765 - precision: 0.9785 - recall: 0.9748 - val_loss: 16065.2480 - val_accuracy: 0.0922 - val_precision: 0.0922 - val_recall: 0.0922\n","Epoch 775/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.0665 - accuracy: 0.9774 - precision: 0.9788 - recall: 0.9763 - val_loss: 14223.4414 - val_accuracy: 0.1074 - val_precision: 0.1074 - val_recall: 0.1074\n","Epoch 776/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0713 - accuracy: 0.9743 - precision: 0.9769 - recall: 0.9725 - val_loss: 15435.2158 - val_accuracy: 0.0978 - val_precision: 0.0978 - val_recall: 0.0978\n","Epoch 777/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0694 - accuracy: 0.9765 - precision: 0.9800 - recall: 0.9750 - val_loss: 14542.7793 - val_accuracy: 0.1013 - val_precision: 0.1013 - val_recall: 0.1013\n","Epoch 778/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0665 - accuracy: 0.9779 - precision: 0.9800 - recall: 0.9767 - val_loss: 14073.9824 - val_accuracy: 0.1089 - val_precision: 0.1089 - val_recall: 0.1089\n","Epoch 779/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0629 - accuracy: 0.9797 - precision: 0.9817 - recall: 0.9777 - val_loss: 14791.0254 - val_accuracy: 0.1109 - val_precision: 0.1109 - val_recall: 0.1109\n","Epoch 780/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0799 - accuracy: 0.9735 - precision: 0.9757 - recall: 0.9720 - val_loss: 13763.0361 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 781/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0691 - accuracy: 0.9748 - precision: 0.9764 - recall: 0.9731 - val_loss: 15838.2324 - val_accuracy: 0.0927 - val_precision: 0.0927 - val_recall: 0.0927\n","Epoch 782/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0726 - accuracy: 0.9752 - precision: 0.9770 - recall: 0.9747 - val_loss: 13134.6924 - val_accuracy: 0.1135 - val_precision: 0.1135 - val_recall: 0.1135\n","Epoch 783/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0660 - accuracy: 0.9782 - precision: 0.9802 - recall: 0.9763 - val_loss: 13992.7637 - val_accuracy: 0.1140 - val_precision: 0.1140 - val_recall: 0.1140\n","Epoch 784/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0656 - accuracy: 0.9772 - precision: 0.9795 - recall: 0.9752 - val_loss: 14409.3828 - val_accuracy: 0.1160 - val_precision: 0.1160 - val_recall: 0.1160\n","Epoch 785/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0656 - accuracy: 0.9794 - precision: 0.9818 - recall: 0.9777 - val_loss: 13728.6943 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 786/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0640 - accuracy: 0.9789 - precision: 0.9800 - recall: 0.9777 - val_loss: 12687.0684 - val_accuracy: 0.1358 - val_precision: 0.1358 - val_recall: 0.1358\n","Epoch 787/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0528 - accuracy: 0.9833 - precision: 0.9844 - recall: 0.9816 - val_loss: 12659.8740 - val_accuracy: 0.1292 - val_precision: 0.1292 - val_recall: 0.1292\n","Epoch 788/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0685 - accuracy: 0.9755 - precision: 0.9770 - recall: 0.9748 - val_loss: 14491.0068 - val_accuracy: 0.1039 - val_precision: 0.1039 - val_recall: 0.1039\n","Epoch 789/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.0714 - accuracy: 0.9767 - precision: 0.9781 - recall: 0.9753 - val_loss: 13497.9082 - val_accuracy: 0.1251 - val_precision: 0.1251 - val_recall: 0.1251\n","Epoch 790/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0616 - accuracy: 0.9770 - precision: 0.9798 - recall: 0.9755 - val_loss: 14861.6953 - val_accuracy: 0.1130 - val_precision: 0.1130 - val_recall: 0.1130\n","Epoch 791/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0701 - accuracy: 0.9787 - precision: 0.9803 - recall: 0.9774 - val_loss: 14569.9287 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 792/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0698 - accuracy: 0.9767 - precision: 0.9785 - recall: 0.9745 - val_loss: 13134.7627 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 793/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0653 - accuracy: 0.9767 - precision: 0.9786 - recall: 0.9736 - val_loss: 13365.7715 - val_accuracy: 0.1155 - val_precision: 0.1155 - val_recall: 0.1155\n","Epoch 794/10000\n","185/185 [==============================] - 16s 85ms/step - loss: 0.0584 - accuracy: 0.9796 - precision: 0.9812 - recall: 0.9780 - val_loss: 13591.2461 - val_accuracy: 0.1064 - val_precision: 0.1064 - val_recall: 0.1064\n","Epoch 795/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0615 - accuracy: 0.9816 - precision: 0.9822 - recall: 0.9806 - val_loss: 13512.9707 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 796/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0599 - accuracy: 0.9796 - precision: 0.9815 - recall: 0.9777 - val_loss: 11048.9150 - val_accuracy: 0.1282 - val_precision: 0.1282 - val_recall: 0.1282\n","Epoch 797/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0626 - accuracy: 0.9797 - precision: 0.9812 - recall: 0.9770 - val_loss: 16115.9160 - val_accuracy: 0.0947 - val_precision: 0.0947 - val_recall: 0.0947\n","Epoch 798/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0649 - accuracy: 0.9789 - precision: 0.9815 - recall: 0.9769 - val_loss: 14025.1641 - val_accuracy: 0.1251 - val_precision: 0.1251 - val_recall: 0.1251\n","Epoch 799/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0673 - accuracy: 0.9772 - precision: 0.9793 - recall: 0.9755 - val_loss: 13958.2100 - val_accuracy: 0.1206 - val_precision: 0.1206 - val_recall: 0.1206\n","Epoch 800/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0580 - accuracy: 0.9807 - precision: 0.9822 - recall: 0.9784 - val_loss: 14459.0977 - val_accuracy: 0.1125 - val_precision: 0.1125 - val_recall: 0.1125\n","Epoch 801/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0608 - accuracy: 0.9792 - precision: 0.9813 - recall: 0.9769 - val_loss: 15473.2324 - val_accuracy: 0.1044 - val_precision: 0.1044 - val_recall: 0.1044\n","Epoch 802/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0620 - accuracy: 0.9796 - precision: 0.9810 - recall: 0.9787 - val_loss: 14424.6787 - val_accuracy: 0.1125 - val_precision: 0.1125 - val_recall: 0.1125\n","Epoch 803/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 0.0599 - accuracy: 0.9812 - precision: 0.9832 - recall: 0.9797 - val_loss: 12644.0010 - val_accuracy: 0.1266 - val_precision: 0.1266 - val_recall: 0.1266\n","Epoch 804/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0587 - accuracy: 0.9787 - precision: 0.9813 - recall: 0.9774 - val_loss: 14454.9609 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 805/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0639 - accuracy: 0.9784 - precision: 0.9793 - recall: 0.9769 - val_loss: 14614.2480 - val_accuracy: 0.1297 - val_precision: 0.1297 - val_recall: 0.1297\n","Epoch 806/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0536 - accuracy: 0.9809 - precision: 0.9819 - recall: 0.9794 - val_loss: 13060.2334 - val_accuracy: 0.1211 - val_precision: 0.1211 - val_recall: 0.1211\n","Epoch 807/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0655 - accuracy: 0.9784 - precision: 0.9805 - recall: 0.9769 - val_loss: 12116.0762 - val_accuracy: 0.1337 - val_precision: 0.1337 - val_recall: 0.1337\n","Epoch 808/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0642 - accuracy: 0.9787 - precision: 0.9798 - recall: 0.9772 - val_loss: 12027.8506 - val_accuracy: 0.1211 - val_precision: 0.1211 - val_recall: 0.1211\n","Epoch 809/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0671 - accuracy: 0.9752 - precision: 0.9781 - recall: 0.9736 - val_loss: 14104.5508 - val_accuracy: 0.1074 - val_precision: 0.1074 - val_recall: 0.1074\n","Epoch 810/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0585 - accuracy: 0.9804 - precision: 0.9820 - recall: 0.9782 - val_loss: 14410.3564 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 811/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0634 - accuracy: 0.9784 - precision: 0.9810 - recall: 0.9763 - val_loss: 13984.4707 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 812/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0695 - accuracy: 0.9755 - precision: 0.9768 - recall: 0.9743 - val_loss: 13209.4482 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 813/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0751 - accuracy: 0.9757 - precision: 0.9773 - recall: 0.9736 - val_loss: 12551.8330 - val_accuracy: 0.1261 - val_precision: 0.1261 - val_recall: 0.1261\n","Epoch 814/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0587 - accuracy: 0.9821 - precision: 0.9827 - recall: 0.9806 - val_loss: 11801.7676 - val_accuracy: 0.1368 - val_precision: 0.1368 - val_recall: 0.1368\n","Epoch 815/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0513 - accuracy: 0.9821 - precision: 0.9831 - recall: 0.9814 - val_loss: 13013.9785 - val_accuracy: 0.1114 - val_precision: 0.1114 - val_recall: 0.1114\n","Epoch 816/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0642 - accuracy: 0.9770 - precision: 0.9790 - recall: 0.9755 - val_loss: 13755.5391 - val_accuracy: 0.1266 - val_precision: 0.1266 - val_recall: 0.1266\n","Epoch 817/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 0.0590 - accuracy: 0.9785 - precision: 0.9815 - recall: 0.9760 - val_loss: 12036.5361 - val_accuracy: 0.1297 - val_precision: 0.1297 - val_recall: 0.1297\n","Epoch 818/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0653 - accuracy: 0.9796 - precision: 0.9815 - recall: 0.9779 - val_loss: 13175.0332 - val_accuracy: 0.1221 - val_precision: 0.1221 - val_recall: 0.1221\n","Epoch 819/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0595 - accuracy: 0.9797 - precision: 0.9809 - recall: 0.9785 - val_loss: 12296.3516 - val_accuracy: 0.1312 - val_precision: 0.1312 - val_recall: 0.1312\n","Epoch 820/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0694 - accuracy: 0.9774 - precision: 0.9796 - recall: 0.9755 - val_loss: 16251.0654 - val_accuracy: 0.0947 - val_precision: 0.0947 - val_recall: 0.0947\n","Epoch 821/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0617 - accuracy: 0.9787 - precision: 0.9795 - recall: 0.9765 - val_loss: 11786.8105 - val_accuracy: 0.1302 - val_precision: 0.1302 - val_recall: 0.1302\n","Epoch 822/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0528 - accuracy: 0.9809 - precision: 0.9814 - recall: 0.9801 - val_loss: 13956.8027 - val_accuracy: 0.0978 - val_precision: 0.0978 - val_recall: 0.0978\n","Epoch 823/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0615 - accuracy: 0.9791 - precision: 0.9813 - recall: 0.9774 - val_loss: 12135.2363 - val_accuracy: 0.1287 - val_precision: 0.1287 - val_recall: 0.1287\n","Epoch 824/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0674 - accuracy: 0.9787 - precision: 0.9800 - recall: 0.9770 - val_loss: 14179.4561 - val_accuracy: 0.1266 - val_precision: 0.1266 - val_recall: 0.1266\n","Epoch 825/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0665 - accuracy: 0.9782 - precision: 0.9803 - recall: 0.9770 - val_loss: 15252.0820 - val_accuracy: 0.1312 - val_precision: 0.1312 - val_recall: 0.1312\n","Epoch 826/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0666 - accuracy: 0.9780 - precision: 0.9790 - recall: 0.9765 - val_loss: 13184.3818 - val_accuracy: 0.1059 - val_precision: 0.1059 - val_recall: 0.1059\n","Epoch 827/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0667 - accuracy: 0.9774 - precision: 0.9785 - recall: 0.9753 - val_loss: 16750.1172 - val_accuracy: 0.0947 - val_precision: 0.0947 - val_recall: 0.0947\n","Epoch 828/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0641 - accuracy: 0.9769 - precision: 0.9788 - recall: 0.9753 - val_loss: 15699.8789 - val_accuracy: 0.1054 - val_precision: 0.1054 - val_recall: 0.1054\n","Epoch 829/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0668 - accuracy: 0.9772 - precision: 0.9796 - recall: 0.9758 - val_loss: 14536.4238 - val_accuracy: 0.1099 - val_precision: 0.1099 - val_recall: 0.1099\n","Epoch 830/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0582 - accuracy: 0.9809 - precision: 0.9822 - recall: 0.9787 - val_loss: 14782.0068 - val_accuracy: 0.1069 - val_precision: 0.1069 - val_recall: 0.1069\n","Epoch 831/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 0.0592 - accuracy: 0.9809 - precision: 0.9819 - recall: 0.9792 - val_loss: 13566.4033 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 832/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0522 - accuracy: 0.9824 - precision: 0.9837 - recall: 0.9807 - val_loss: 13653.5742 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 833/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0569 - accuracy: 0.9802 - precision: 0.9830 - recall: 0.9792 - val_loss: 15204.7393 - val_accuracy: 0.1054 - val_precision: 0.1054 - val_recall: 0.1054\n","Epoch 834/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0577 - accuracy: 0.9812 - precision: 0.9820 - recall: 0.9789 - val_loss: 12511.7334 - val_accuracy: 0.1403 - val_precision: 0.1403 - val_recall: 0.1403\n","Epoch 835/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0628 - accuracy: 0.9784 - precision: 0.9795 - recall: 0.9765 - val_loss: 14899.9463 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 836/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0649 - accuracy: 0.9785 - precision: 0.9810 - recall: 0.9767 - val_loss: 13564.3789 - val_accuracy: 0.1282 - val_precision: 0.1282 - val_recall: 0.1282\n","Epoch 837/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0582 - accuracy: 0.9806 - precision: 0.9825 - recall: 0.9791 - val_loss: 15114.5977 - val_accuracy: 0.1023 - val_precision: 0.1023 - val_recall: 0.1023\n","Epoch 838/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0487 - accuracy: 0.9840 - precision: 0.9848 - recall: 0.9829 - val_loss: 16493.0605 - val_accuracy: 0.0927 - val_precision: 0.0927 - val_recall: 0.0927\n","Epoch 839/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0543 - accuracy: 0.9804 - precision: 0.9820 - recall: 0.9796 - val_loss: 17005.9551 - val_accuracy: 0.0927 - val_precision: 0.0927 - val_recall: 0.0927\n","Epoch 840/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0704 - accuracy: 0.9747 - precision: 0.9776 - recall: 0.9733 - val_loss: 13956.6035 - val_accuracy: 0.1297 - val_precision: 0.1297 - val_recall: 0.1297\n","Epoch 841/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0552 - accuracy: 0.9818 - precision: 0.9837 - recall: 0.9804 - val_loss: 13940.5430 - val_accuracy: 0.1196 - val_precision: 0.1196 - val_recall: 0.1196\n","Epoch 842/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0551 - accuracy: 0.9794 - precision: 0.9822 - recall: 0.9775 - val_loss: 12706.7881 - val_accuracy: 0.1266 - val_precision: 0.1266 - val_recall: 0.1266\n","Epoch 843/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0555 - accuracy: 0.9816 - precision: 0.9832 - recall: 0.9806 - val_loss: 12492.6689 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 844/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0734 - accuracy: 0.9775 - precision: 0.9788 - recall: 0.9767 - val_loss: 13523.9834 - val_accuracy: 0.1104 - val_precision: 0.1104 - val_recall: 0.1104\n","Epoch 845/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 0.0638 - accuracy: 0.9785 - precision: 0.9805 - recall: 0.9772 - val_loss: 12965.0293 - val_accuracy: 0.1363 - val_precision: 0.1363 - val_recall: 0.1363\n","Epoch 846/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0614 - accuracy: 0.9811 - precision: 0.9831 - recall: 0.9806 - val_loss: 13247.4229 - val_accuracy: 0.1307 - val_precision: 0.1307 - val_recall: 0.1307\n","Epoch 847/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0503 - accuracy: 0.9831 - precision: 0.9842 - recall: 0.9818 - val_loss: 13183.8477 - val_accuracy: 0.1474 - val_precision: 0.1474 - val_recall: 0.1474\n","Epoch 848/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0642 - accuracy: 0.9775 - precision: 0.9800 - recall: 0.9757 - val_loss: 13335.5508 - val_accuracy: 0.1383 - val_precision: 0.1383 - val_recall: 0.1383\n","Epoch 849/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0596 - accuracy: 0.9785 - precision: 0.9798 - recall: 0.9767 - val_loss: 15730.2207 - val_accuracy: 0.1008 - val_precision: 0.1008 - val_recall: 0.1008\n","Epoch 850/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0573 - accuracy: 0.9797 - precision: 0.9810 - recall: 0.9785 - val_loss: 13747.0078 - val_accuracy: 0.1272 - val_precision: 0.1272 - val_recall: 0.1272\n","Epoch 851/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0513 - accuracy: 0.9826 - precision: 0.9844 - recall: 0.9811 - val_loss: 13485.8994 - val_accuracy: 0.1221 - val_precision: 0.1221 - val_recall: 0.1221\n","Epoch 852/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0534 - accuracy: 0.9845 - precision: 0.9854 - recall: 0.9824 - val_loss: 11755.4951 - val_accuracy: 0.1581 - val_precision: 0.1581 - val_recall: 0.1581\n","Epoch 853/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0504 - accuracy: 0.9818 - precision: 0.9841 - recall: 0.9809 - val_loss: 13021.2773 - val_accuracy: 0.1342 - val_precision: 0.1342 - val_recall: 0.1342\n","Epoch 854/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0592 - accuracy: 0.9791 - precision: 0.9800 - recall: 0.9777 - val_loss: 14161.9795 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 855/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0585 - accuracy: 0.9784 - precision: 0.9800 - recall: 0.9772 - val_loss: 12080.2002 - val_accuracy: 0.1337 - val_precision: 0.1337 - val_recall: 0.1337\n","Epoch 856/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0494 - accuracy: 0.9836 - precision: 0.9856 - recall: 0.9824 - val_loss: 13176.5205 - val_accuracy: 0.1190 - val_precision: 0.1190 - val_recall: 0.1190\n","Epoch 857/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0539 - accuracy: 0.9823 - precision: 0.9834 - recall: 0.9802 - val_loss: 15913.9727 - val_accuracy: 0.1140 - val_precision: 0.1140 - val_recall: 0.1140\n","Epoch 858/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0626 - accuracy: 0.9765 - precision: 0.9786 - recall: 0.9750 - val_loss: 12977.8818 - val_accuracy: 0.1231 - val_precision: 0.1231 - val_recall: 0.1231\n","Epoch 859/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 0.0532 - accuracy: 0.9784 - precision: 0.9803 - recall: 0.9775 - val_loss: 13337.5840 - val_accuracy: 0.1297 - val_precision: 0.1297 - val_recall: 0.1297\n","Epoch 860/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0496 - accuracy: 0.9833 - precision: 0.9851 - recall: 0.9816 - val_loss: 13941.9570 - val_accuracy: 0.1302 - val_precision: 0.1302 - val_recall: 0.1302\n","Epoch 861/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0487 - accuracy: 0.9829 - precision: 0.9848 - recall: 0.9819 - val_loss: 14047.9512 - val_accuracy: 0.1109 - val_precision: 0.1109 - val_recall: 0.1109\n","Epoch 862/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0640 - accuracy: 0.9777 - precision: 0.9795 - recall: 0.9757 - val_loss: 13788.8320 - val_accuracy: 0.1251 - val_precision: 0.1251 - val_recall: 0.1251\n","Epoch 863/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0484 - accuracy: 0.9843 - precision: 0.9851 - recall: 0.9824 - val_loss: 14506.0762 - val_accuracy: 0.1190 - val_precision: 0.1190 - val_recall: 0.1190\n","Epoch 864/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0625 - accuracy: 0.9774 - precision: 0.9793 - recall: 0.9758 - val_loss: 14539.2764 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 865/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0536 - accuracy: 0.9826 - precision: 0.9837 - recall: 0.9818 - val_loss: 12669.6738 - val_accuracy: 0.1403 - val_precision: 0.1403 - val_recall: 0.1403\n","Epoch 866/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0568 - accuracy: 0.9814 - precision: 0.9822 - recall: 0.9804 - val_loss: 13654.3057 - val_accuracy: 0.1155 - val_precision: 0.1155 - val_recall: 0.1155\n","Epoch 867/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0557 - accuracy: 0.9792 - precision: 0.9815 - recall: 0.9784 - val_loss: 12954.8838 - val_accuracy: 0.1363 - val_precision: 0.1363 - val_recall: 0.1363\n","Epoch 868/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0571 - accuracy: 0.9807 - precision: 0.9824 - recall: 0.9797 - val_loss: 14201.8809 - val_accuracy: 0.1221 - val_precision: 0.1221 - val_recall: 0.1221\n","Epoch 869/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0571 - accuracy: 0.9814 - precision: 0.9827 - recall: 0.9801 - val_loss: 13666.6680 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 870/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0590 - accuracy: 0.9792 - precision: 0.9815 - recall: 0.9784 - val_loss: 13870.6455 - val_accuracy: 0.1160 - val_precision: 0.1160 - val_recall: 0.1160\n","Epoch 871/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0523 - accuracy: 0.9821 - precision: 0.9836 - recall: 0.9807 - val_loss: 13418.3125 - val_accuracy: 0.1114 - val_precision: 0.1114 - val_recall: 0.1114\n","Epoch 872/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 0.0537 - accuracy: 0.9816 - precision: 0.9826 - recall: 0.9804 - val_loss: 13562.0205 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 873/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0590 - accuracy: 0.9806 - precision: 0.9830 - recall: 0.9794 - val_loss: 13207.4229 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 874/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0504 - accuracy: 0.9818 - precision: 0.9829 - recall: 0.9804 - val_loss: 13573.3799 - val_accuracy: 0.1261 - val_precision: 0.1261 - val_recall: 0.1261\n","Epoch 875/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0595 - accuracy: 0.9796 - precision: 0.9819 - recall: 0.9780 - val_loss: 15077.7646 - val_accuracy: 0.1033 - val_precision: 0.1033 - val_recall: 0.1033\n","Epoch 876/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0421 - accuracy: 0.9851 - precision: 0.9865 - recall: 0.9841 - val_loss: 13901.9609 - val_accuracy: 0.1084 - val_precision: 0.1084 - val_recall: 0.1084\n","Epoch 877/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0653 - accuracy: 0.9782 - precision: 0.9807 - recall: 0.9765 - val_loss: 17675.5859 - val_accuracy: 0.1130 - val_precision: 0.1130 - val_recall: 0.1130\n","Epoch 878/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0599 - accuracy: 0.9799 - precision: 0.9815 - recall: 0.9787 - val_loss: 13895.8867 - val_accuracy: 0.1125 - val_precision: 0.1125 - val_recall: 0.1125\n","Epoch 879/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0470 - accuracy: 0.9845 - precision: 0.9869 - recall: 0.9826 - val_loss: 14369.3672 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 880/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0551 - accuracy: 0.9824 - precision: 0.9834 - recall: 0.9819 - val_loss: 13444.4180 - val_accuracy: 0.1287 - val_precision: 0.1287 - val_recall: 0.1287\n","Epoch 881/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0452 - accuracy: 0.9841 - precision: 0.9864 - recall: 0.9831 - val_loss: 13594.0273 - val_accuracy: 0.1322 - val_precision: 0.1322 - val_recall: 0.1322\n","Epoch 882/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0552 - accuracy: 0.9792 - precision: 0.9814 - recall: 0.9780 - val_loss: 16338.6680 - val_accuracy: 0.0947 - val_precision: 0.0947 - val_recall: 0.0947\n","Epoch 883/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0564 - accuracy: 0.9797 - precision: 0.9814 - recall: 0.9784 - val_loss: 15906.0547 - val_accuracy: 0.1008 - val_precision: 0.1008 - val_recall: 0.1008\n","Epoch 884/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0553 - accuracy: 0.9785 - precision: 0.9800 - recall: 0.9770 - val_loss: 16223.2588 - val_accuracy: 0.1064 - val_precision: 0.1064 - val_recall: 0.1064\n","Epoch 885/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0602 - accuracy: 0.9819 - precision: 0.9837 - recall: 0.9811 - val_loss: 12966.1592 - val_accuracy: 0.1292 - val_precision: 0.1292 - val_recall: 0.1292\n","Epoch 886/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 0.0529 - accuracy: 0.9826 - precision: 0.9836 - recall: 0.9806 - val_loss: 13802.2822 - val_accuracy: 0.1120 - val_precision: 0.1120 - val_recall: 0.1120\n","Epoch 887/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0519 - accuracy: 0.9818 - precision: 0.9827 - recall: 0.9804 - val_loss: 14280.2197 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 888/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0422 - accuracy: 0.9865 - precision: 0.9875 - recall: 0.9853 - val_loss: 13152.8145 - val_accuracy: 0.1292 - val_precision: 0.1292 - val_recall: 0.1292\n","Epoch 889/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0507 - accuracy: 0.9840 - precision: 0.9848 - recall: 0.9829 - val_loss: 12598.7041 - val_accuracy: 0.1342 - val_precision: 0.1342 - val_recall: 0.1342\n","Epoch 890/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0535 - accuracy: 0.9809 - precision: 0.9822 - recall: 0.9792 - val_loss: 13827.3643 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 891/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0589 - accuracy: 0.9784 - precision: 0.9795 - recall: 0.9775 - val_loss: 13446.4824 - val_accuracy: 0.1383 - val_precision: 0.1383 - val_recall: 0.1383\n","Epoch 892/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0666 - accuracy: 0.9785 - precision: 0.9808 - recall: 0.9772 - val_loss: 13202.5791 - val_accuracy: 0.1307 - val_precision: 0.1307 - val_recall: 0.1307\n","Epoch 893/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0609 - accuracy: 0.9801 - precision: 0.9820 - recall: 0.9784 - val_loss: 13869.0215 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 894/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0536 - accuracy: 0.9821 - precision: 0.9832 - recall: 0.9804 - val_loss: 16999.7461 - val_accuracy: 0.0952 - val_precision: 0.0952 - val_recall: 0.0952\n","Epoch 895/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0520 - accuracy: 0.9819 - precision: 0.9832 - recall: 0.9784 - val_loss: 12905.6797 - val_accuracy: 0.1231 - val_precision: 0.1231 - val_recall: 0.1231\n","Epoch 896/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0575 - accuracy: 0.9779 - precision: 0.9807 - recall: 0.9767 - val_loss: 12306.5752 - val_accuracy: 0.1550 - val_precision: 0.1550 - val_recall: 0.1550\n","Epoch 897/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0551 - accuracy: 0.9807 - precision: 0.9825 - recall: 0.9787 - val_loss: 13308.6738 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 898/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0532 - accuracy: 0.9823 - precision: 0.9841 - recall: 0.9812 - val_loss: 13621.5400 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 899/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 0.0588 - accuracy: 0.9797 - precision: 0.9810 - recall: 0.9789 - val_loss: 14754.7500 - val_accuracy: 0.0942 - val_precision: 0.0942 - val_recall: 0.0942\n","Epoch 900/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0571 - accuracy: 0.9823 - precision: 0.9834 - recall: 0.9804 - val_loss: 14823.2422 - val_accuracy: 0.1104 - val_precision: 0.1104 - val_recall: 0.1104\n","Epoch 901/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0551 - accuracy: 0.9812 - precision: 0.9834 - recall: 0.9799 - val_loss: 15587.0059 - val_accuracy: 0.0937 - val_precision: 0.0937 - val_recall: 0.0937\n","Epoch 902/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0575 - accuracy: 0.9796 - precision: 0.9817 - recall: 0.9779 - val_loss: 14560.1172 - val_accuracy: 0.1069 - val_precision: 0.1069 - val_recall: 0.1069\n","Epoch 903/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0606 - accuracy: 0.9765 - precision: 0.9786 - recall: 0.9753 - val_loss: 16363.3281 - val_accuracy: 0.1185 - val_precision: 0.1185 - val_recall: 0.1185\n","Epoch 904/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0588 - accuracy: 0.9797 - precision: 0.9805 - recall: 0.9784 - val_loss: 13447.4531 - val_accuracy: 0.1231 - val_precision: 0.1231 - val_recall: 0.1231\n","Epoch 905/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0594 - accuracy: 0.9818 - precision: 0.9836 - recall: 0.9802 - val_loss: 15113.9062 - val_accuracy: 0.1307 - val_precision: 0.1307 - val_recall: 0.1307\n","Epoch 906/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0577 - accuracy: 0.9802 - precision: 0.9819 - recall: 0.9801 - val_loss: 14279.0146 - val_accuracy: 0.1302 - val_precision: 0.1302 - val_recall: 0.1302\n","Epoch 907/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0550 - accuracy: 0.9809 - precision: 0.9822 - recall: 0.9796 - val_loss: 13126.0127 - val_accuracy: 0.1337 - val_precision: 0.1337 - val_recall: 0.1337\n","Epoch 908/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0524 - accuracy: 0.9814 - precision: 0.9832 - recall: 0.9806 - val_loss: 16437.4355 - val_accuracy: 0.1140 - val_precision: 0.1140 - val_recall: 0.1140\n","Epoch 909/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0508 - accuracy: 0.9836 - precision: 0.9843 - recall: 0.9828 - val_loss: 14068.8926 - val_accuracy: 0.1272 - val_precision: 0.1272 - val_recall: 0.1272\n","Epoch 910/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0609 - accuracy: 0.9807 - precision: 0.9827 - recall: 0.9794 - val_loss: 12812.0049 - val_accuracy: 0.1484 - val_precision: 0.1484 - val_recall: 0.1484\n","Epoch 911/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0541 - accuracy: 0.9811 - precision: 0.9832 - recall: 0.9791 - val_loss: 10560.3320 - val_accuracy: 0.1525 - val_precision: 0.1525 - val_recall: 0.1525\n","Epoch 912/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0616 - accuracy: 0.9791 - precision: 0.9810 - recall: 0.9779 - val_loss: 12492.4941 - val_accuracy: 0.1388 - val_precision: 0.1388 - val_recall: 0.1388\n","Epoch 913/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.0600 - accuracy: 0.9816 - precision: 0.9824 - recall: 0.9806 - val_loss: 13256.9346 - val_accuracy: 0.1312 - val_precision: 0.1312 - val_recall: 0.1312\n","Epoch 914/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 0.0488 - accuracy: 0.9816 - precision: 0.9829 - recall: 0.9802 - val_loss: 11787.0791 - val_accuracy: 0.1332 - val_precision: 0.1332 - val_recall: 0.1332\n","Epoch 915/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 0.0582 - accuracy: 0.9802 - precision: 0.9820 - recall: 0.9791 - val_loss: 11058.7842 - val_accuracy: 0.1550 - val_precision: 0.1550 - val_recall: 0.1550\n","Epoch 916/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.0491 - accuracy: 0.9816 - precision: 0.9832 - recall: 0.9811 - val_loss: 13136.2549 - val_accuracy: 0.1266 - val_precision: 0.1266 - val_recall: 0.1266\n","Epoch 917/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 0.0569 - accuracy: 0.9823 - precision: 0.9837 - recall: 0.9807 - val_loss: 15752.7207 - val_accuracy: 0.1079 - val_precision: 0.1079 - val_recall: 0.1079\n","Epoch 918/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 0.0604 - accuracy: 0.9789 - precision: 0.9807 - recall: 0.9774 - val_loss: 13374.6494 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 919/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 0.0536 - accuracy: 0.9821 - precision: 0.9836 - recall: 0.9818 - val_loss: 15212.8193 - val_accuracy: 0.1099 - val_precision: 0.1099 - val_recall: 0.1099\n","Epoch 920/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 0.0492 - accuracy: 0.9855 - precision: 0.9865 - recall: 0.9846 - val_loss: 13730.9707 - val_accuracy: 0.1140 - val_precision: 0.1140 - val_recall: 0.1140\n","Epoch 921/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 0.0442 - accuracy: 0.9843 - precision: 0.9859 - recall: 0.9824 - val_loss: 13249.4531 - val_accuracy: 0.1221 - val_precision: 0.1221 - val_recall: 0.1221\n","Epoch 922/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 0.0551 - accuracy: 0.9802 - precision: 0.9810 - recall: 0.9789 - val_loss: 15078.6680 - val_accuracy: 0.1039 - val_precision: 0.1039 - val_recall: 0.1039\n","Epoch 923/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 0.0581 - accuracy: 0.9811 - precision: 0.9831 - recall: 0.9801 - val_loss: 12057.3057 - val_accuracy: 0.1520 - val_precision: 0.1520 - val_recall: 0.1520\n","Epoch 924/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 0.0554 - accuracy: 0.9811 - precision: 0.9827 - recall: 0.9784 - val_loss: 15548.3008 - val_accuracy: 0.1135 - val_precision: 0.1135 - val_recall: 0.1135\n","Epoch 925/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.0567 - accuracy: 0.9809 - precision: 0.9824 - recall: 0.9796 - val_loss: 13786.1367 - val_accuracy: 0.1287 - val_precision: 0.1287 - val_recall: 0.1287\n","Epoch 926/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 0.0516 - accuracy: 0.9821 - precision: 0.9832 - recall: 0.9814 - val_loss: 15011.3096 - val_accuracy: 0.1155 - val_precision: 0.1155 - val_recall: 0.1155\n","Epoch 927/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.0516 - accuracy: 0.9821 - precision: 0.9837 - recall: 0.9814 - val_loss: 14105.8916 - val_accuracy: 0.1302 - val_precision: 0.1302 - val_recall: 0.1302\n","Epoch 928/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 0.0461 - accuracy: 0.9856 - precision: 0.9863 - recall: 0.9840 - val_loss: 14436.5166 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 929/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 0.0443 - accuracy: 0.9840 - precision: 0.9856 - recall: 0.9831 - val_loss: 11487.5586 - val_accuracy: 0.1439 - val_precision: 0.1439 - val_recall: 0.1439\n","Epoch 930/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.0460 - accuracy: 0.9861 - precision: 0.9876 - recall: 0.9848 - val_loss: 13370.3721 - val_accuracy: 0.1130 - val_precision: 0.1130 - val_recall: 0.1130\n","Epoch 931/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 0.0548 - accuracy: 0.9816 - precision: 0.9827 - recall: 0.9807 - val_loss: 13350.0322 - val_accuracy: 0.1231 - val_precision: 0.1231 - val_recall: 0.1231\n","Epoch 932/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0519 - accuracy: 0.9831 - precision: 0.9848 - recall: 0.9819 - val_loss: 13870.7510 - val_accuracy: 0.1099 - val_precision: 0.1099 - val_recall: 0.1099\n","Epoch 933/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0521 - accuracy: 0.9819 - precision: 0.9839 - recall: 0.9797 - val_loss: 12075.8711 - val_accuracy: 0.1424 - val_precision: 0.1424 - val_recall: 0.1424\n","Epoch 934/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.0575 - accuracy: 0.9801 - precision: 0.9809 - recall: 0.9784 - val_loss: 12957.3018 - val_accuracy: 0.1196 - val_precision: 0.1196 - val_recall: 0.1196\n","Epoch 935/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.0540 - accuracy: 0.9804 - precision: 0.9835 - recall: 0.9792 - val_loss: 13201.8701 - val_accuracy: 0.1353 - val_precision: 0.1353 - val_recall: 0.1353\n","Epoch 936/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.0438 - accuracy: 0.9865 - precision: 0.9876 - recall: 0.9856 - val_loss: 14003.6396 - val_accuracy: 0.1251 - val_precision: 0.1251 - val_recall: 0.1251\n","Epoch 937/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0525 - accuracy: 0.9809 - precision: 0.9821 - recall: 0.9802 - val_loss: 15810.9004 - val_accuracy: 0.1236 - val_precision: 0.1236 - val_recall: 0.1236\n","Epoch 938/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.0548 - accuracy: 0.9806 - precision: 0.9820 - recall: 0.9794 - val_loss: 13152.4502 - val_accuracy: 0.1211 - val_precision: 0.1211 - val_recall: 0.1211\n","Epoch 939/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 0.0577 - accuracy: 0.9802 - precision: 0.9817 - recall: 0.9787 - val_loss: 13838.4990 - val_accuracy: 0.1266 - val_precision: 0.1266 - val_recall: 0.1266\n","Epoch 940/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 0.0592 - accuracy: 0.9785 - precision: 0.9803 - recall: 0.9775 - val_loss: 13934.6924 - val_accuracy: 0.1190 - val_precision: 0.1190 - val_recall: 0.1190\n","Epoch 941/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 0.0494 - accuracy: 0.9840 - precision: 0.9856 - recall: 0.9831 - val_loss: 13866.8203 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 942/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 0.0527 - accuracy: 0.9821 - precision: 0.9839 - recall: 0.9811 - val_loss: 14531.3311 - val_accuracy: 0.1155 - val_precision: 0.1155 - val_recall: 0.1155\n","Epoch 943/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 0.0468 - accuracy: 0.9828 - precision: 0.9842 - recall: 0.9814 - val_loss: 12229.4531 - val_accuracy: 0.1332 - val_precision: 0.1332 - val_recall: 0.1332\n","Epoch 944/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.0547 - accuracy: 0.9812 - precision: 0.9826 - recall: 0.9801 - val_loss: 12971.0664 - val_accuracy: 0.1348 - val_precision: 0.1348 - val_recall: 0.1348\n","Epoch 945/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0522 - accuracy: 0.9824 - precision: 0.9836 - recall: 0.9804 - val_loss: 14267.8701 - val_accuracy: 0.1261 - val_precision: 0.1261 - val_recall: 0.1261\n","Epoch 946/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0515 - accuracy: 0.9811 - precision: 0.9829 - recall: 0.9796 - val_loss: 14658.5977 - val_accuracy: 0.1201 - val_precision: 0.1201 - val_recall: 0.1201\n","Epoch 947/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.0527 - accuracy: 0.9823 - precision: 0.9829 - recall: 0.9809 - val_loss: 13066.4971 - val_accuracy: 0.1241 - val_precision: 0.1241 - val_recall: 0.1241\n","Epoch 948/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.0480 - accuracy: 0.9831 - precision: 0.9856 - recall: 0.9819 - val_loss: 13521.5820 - val_accuracy: 0.1246 - val_precision: 0.1246 - val_recall: 0.1246\n","Epoch 949/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 0.0590 - accuracy: 0.9794 - precision: 0.9807 - recall: 0.9782 - val_loss: 15665.7979 - val_accuracy: 0.1054 - val_precision: 0.1054 - val_recall: 0.1054\n","Epoch 950/10000\n","185/185 [==============================] - 19s 100ms/step - loss: 0.0549 - accuracy: 0.9821 - precision: 0.9836 - recall: 0.9799 - val_loss: 13210.8369 - val_accuracy: 0.1180 - val_precision: 0.1180 - val_recall: 0.1180\n","Epoch 951/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0468 - accuracy: 0.9846 - precision: 0.9859 - recall: 0.9829 - val_loss: 13273.0078 - val_accuracy: 0.1287 - val_precision: 0.1287 - val_recall: 0.1287\n","Epoch 952/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0590 - accuracy: 0.9818 - precision: 0.9836 - recall: 0.9801 - val_loss: 13848.6152 - val_accuracy: 0.1074 - val_precision: 0.1074 - val_recall: 0.1074\n","Epoch 953/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.0526 - accuracy: 0.9819 - precision: 0.9841 - recall: 0.9809 - val_loss: 13620.0605 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 954/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0585 - accuracy: 0.9816 - precision: 0.9832 - recall: 0.9796 - val_loss: 13062.5889 - val_accuracy: 0.1454 - val_precision: 0.1454 - val_recall: 0.1454\n","Epoch 955/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0565 - accuracy: 0.9807 - precision: 0.9822 - recall: 0.9785 - val_loss: 14246.6777 - val_accuracy: 0.1211 - val_precision: 0.1211 - val_recall: 0.1211\n","Epoch 956/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0504 - accuracy: 0.9826 - precision: 0.9838 - recall: 0.9821 - val_loss: 15727.8818 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 957/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0509 - accuracy: 0.9819 - precision: 0.9837 - recall: 0.9811 - val_loss: 13110.3096 - val_accuracy: 0.1327 - val_precision: 0.1327 - val_recall: 0.1327\n","Epoch 958/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0498 - accuracy: 0.9826 - precision: 0.9836 - recall: 0.9812 - val_loss: 13165.4932 - val_accuracy: 0.1312 - val_precision: 0.1312 - val_recall: 0.1312\n","Epoch 959/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0482 - accuracy: 0.9840 - precision: 0.9853 - recall: 0.9833 - val_loss: 13742.1836 - val_accuracy: 0.1540 - val_precision: 0.1540 - val_recall: 0.1540\n","Epoch 960/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0558 - accuracy: 0.9828 - precision: 0.9839 - recall: 0.9816 - val_loss: 15707.1240 - val_accuracy: 0.1135 - val_precision: 0.1135 - val_recall: 0.1135\n","Epoch 961/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0507 - accuracy: 0.9801 - precision: 0.9814 - recall: 0.9792 - val_loss: 16922.0527 - val_accuracy: 0.1099 - val_precision: 0.1099 - val_recall: 0.1099\n","Epoch 962/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0512 - accuracy: 0.9818 - precision: 0.9836 - recall: 0.9811 - val_loss: 14486.4805 - val_accuracy: 0.1221 - val_precision: 0.1221 - val_recall: 0.1221\n","Epoch 963/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 0.0504 - accuracy: 0.9833 - precision: 0.9851 - recall: 0.9812 - val_loss: 14969.1113 - val_accuracy: 0.1256 - val_precision: 0.1256 - val_recall: 0.1256\n","Epoch 964/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0557 - accuracy: 0.9816 - precision: 0.9832 - recall: 0.9804 - val_loss: 13998.9414 - val_accuracy: 0.1342 - val_precision: 0.1342 - val_recall: 0.1342\n","Epoch 965/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0489 - accuracy: 0.9858 - precision: 0.9865 - recall: 0.9851 - val_loss: 14000.5586 - val_accuracy: 0.1201 - val_precision: 0.1201 - val_recall: 0.1201\n","Epoch 966/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0493 - accuracy: 0.9823 - precision: 0.9831 - recall: 0.9816 - val_loss: 15096.9092 - val_accuracy: 0.1049 - val_precision: 0.1049 - val_recall: 0.1049\n","Epoch 967/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0515 - accuracy: 0.9826 - precision: 0.9841 - recall: 0.9812 - val_loss: 14206.5762 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 968/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0445 - accuracy: 0.9843 - precision: 0.9858 - recall: 0.9833 - val_loss: 13432.0684 - val_accuracy: 0.1094 - val_precision: 0.1094 - val_recall: 0.1094\n","Epoch 969/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0487 - accuracy: 0.9846 - precision: 0.9853 - recall: 0.9833 - val_loss: 14975.6855 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 970/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0492 - accuracy: 0.9836 - precision: 0.9856 - recall: 0.9824 - val_loss: 15303.8711 - val_accuracy: 0.0978 - val_precision: 0.0978 - val_recall: 0.0978\n","Epoch 971/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0433 - accuracy: 0.9853 - precision: 0.9866 - recall: 0.9846 - val_loss: 13885.2021 - val_accuracy: 0.1266 - val_precision: 0.1266 - val_recall: 0.1266\n","Epoch 972/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0531 - accuracy: 0.9833 - precision: 0.9841 - recall: 0.9818 - val_loss: 13632.0146 - val_accuracy: 0.1266 - val_precision: 0.1266 - val_recall: 0.1266\n","Epoch 973/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0527 - accuracy: 0.9816 - precision: 0.9822 - recall: 0.9806 - val_loss: 13521.2500 - val_accuracy: 0.1287 - val_precision: 0.1287 - val_recall: 0.1287\n","Epoch 974/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0536 - accuracy: 0.9824 - precision: 0.9839 - recall: 0.9812 - val_loss: 14859.8975 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 975/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0501 - accuracy: 0.9826 - precision: 0.9834 - recall: 0.9809 - val_loss: 14988.4531 - val_accuracy: 0.1226 - val_precision: 0.1226 - val_recall: 0.1226\n","Epoch 976/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 0.0470 - accuracy: 0.9816 - precision: 0.9822 - recall: 0.9806 - val_loss: 14736.8740 - val_accuracy: 0.1155 - val_precision: 0.1155 - val_recall: 0.1155\n","Epoch 977/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0494 - accuracy: 0.9840 - precision: 0.9854 - recall: 0.9833 - val_loss: 12847.7891 - val_accuracy: 0.1444 - val_precision: 0.1444 - val_recall: 0.1444\n","Epoch 978/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0542 - accuracy: 0.9814 - precision: 0.9832 - recall: 0.9807 - val_loss: 14905.9922 - val_accuracy: 0.1033 - val_precision: 0.1033 - val_recall: 0.1033\n","Epoch 979/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0370 - accuracy: 0.9875 - precision: 0.9887 - recall: 0.9868 - val_loss: 14326.1729 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 980/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0545 - accuracy: 0.9828 - precision: 0.9841 - recall: 0.9819 - val_loss: 14986.9092 - val_accuracy: 0.1135 - val_precision: 0.1135 - val_recall: 0.1135\n","Epoch 981/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0448 - accuracy: 0.9858 - precision: 0.9866 - recall: 0.9845 - val_loss: 14350.4678 - val_accuracy: 0.1180 - val_precision: 0.1180 - val_recall: 0.1180\n","Epoch 982/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0502 - accuracy: 0.9826 - precision: 0.9833 - recall: 0.9819 - val_loss: 14994.2051 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 983/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0585 - accuracy: 0.9807 - precision: 0.9821 - recall: 0.9799 - val_loss: 15259.4102 - val_accuracy: 0.1013 - val_precision: 0.1013 - val_recall: 0.1013\n","Epoch 984/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.0557 - accuracy: 0.9824 - precision: 0.9841 - recall: 0.9807 - val_loss: 15828.5869 - val_accuracy: 0.1039 - val_precision: 0.1039 - val_recall: 0.1039\n","Epoch 985/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0571 - accuracy: 0.9814 - precision: 0.9831 - recall: 0.9801 - val_loss: 15208.0771 - val_accuracy: 0.1130 - val_precision: 0.1130 - val_recall: 0.1130\n","Epoch 986/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0568 - accuracy: 0.9812 - precision: 0.9821 - recall: 0.9802 - val_loss: 16340.4150 - val_accuracy: 0.0968 - val_precision: 0.0968 - val_recall: 0.0968\n","Epoch 987/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0467 - accuracy: 0.9843 - precision: 0.9848 - recall: 0.9841 - val_loss: 14584.7568 - val_accuracy: 0.1261 - val_precision: 0.1261 - val_recall: 0.1261\n","Epoch 988/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0667 - accuracy: 0.9763 - precision: 0.9778 - recall: 0.9753 - val_loss: 17546.5977 - val_accuracy: 0.0998 - val_precision: 0.0998 - val_recall: 0.0998\n","Epoch 989/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 0.0565 - accuracy: 0.9809 - precision: 0.9821 - recall: 0.9799 - val_loss: 13589.6045 - val_accuracy: 0.1292 - val_precision: 0.1292 - val_recall: 0.1292\n","Epoch 990/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0475 - accuracy: 0.9841 - precision: 0.9856 - recall: 0.9829 - val_loss: 13667.6074 - val_accuracy: 0.1155 - val_precision: 0.1155 - val_recall: 0.1155\n","Epoch 991/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0529 - accuracy: 0.9811 - precision: 0.9820 - recall: 0.9796 - val_loss: 15350.0996 - val_accuracy: 0.0998 - val_precision: 0.0998 - val_recall: 0.0998\n","Epoch 992/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0468 - accuracy: 0.9845 - precision: 0.9859 - recall: 0.9838 - val_loss: 15006.3262 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 993/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0535 - accuracy: 0.9829 - precision: 0.9841 - recall: 0.9816 - val_loss: 14469.2930 - val_accuracy: 0.1180 - val_precision: 0.1180 - val_recall: 0.1180\n","Epoch 994/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0556 - accuracy: 0.9806 - precision: 0.9820 - recall: 0.9797 - val_loss: 15691.9199 - val_accuracy: 0.1125 - val_precision: 0.1125 - val_recall: 0.1125\n","Epoch 995/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0498 - accuracy: 0.9821 - precision: 0.9832 - recall: 0.9811 - val_loss: 18521.9668 - val_accuracy: 0.0897 - val_precision: 0.0897 - val_recall: 0.0897\n","Epoch 996/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0464 - accuracy: 0.9834 - precision: 0.9853 - recall: 0.9824 - val_loss: 13935.9189 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 997/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0508 - accuracy: 0.9814 - precision: 0.9822 - recall: 0.9809 - val_loss: 14572.1260 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 998/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0572 - accuracy: 0.9801 - precision: 0.9815 - recall: 0.9792 - val_loss: 14259.3262 - val_accuracy: 0.1155 - val_precision: 0.1155 - val_recall: 0.1155\n","Epoch 999/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0486 - accuracy: 0.9829 - precision: 0.9844 - recall: 0.9812 - val_loss: 15268.7051 - val_accuracy: 0.1130 - val_precision: 0.1130 - val_recall: 0.1130\n","Epoch 1000/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0500 - accuracy: 0.9845 - precision: 0.9859 - recall: 0.9829 - val_loss: 15188.1318 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 1001/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0472 - accuracy: 0.9841 - precision: 0.9853 - recall: 0.9836 - val_loss: 13532.9531 - val_accuracy: 0.1353 - val_precision: 0.1353 - val_recall: 0.1353\n","Epoch 1002/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 0.0548 - accuracy: 0.9821 - precision: 0.9837 - recall: 0.9804 - val_loss: 15821.5400 - val_accuracy: 0.1348 - val_precision: 0.1348 - val_recall: 0.1348\n","Epoch 1003/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0563 - accuracy: 0.9791 - precision: 0.9815 - recall: 0.9765 - val_loss: 13907.0039 - val_accuracy: 0.1256 - val_precision: 0.1256 - val_recall: 0.1256\n","Epoch 1004/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0540 - accuracy: 0.9787 - precision: 0.9805 - recall: 0.9784 - val_loss: 16100.6631 - val_accuracy: 0.1039 - val_precision: 0.1039 - val_recall: 0.1039\n","Epoch 1005/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0438 - accuracy: 0.9858 - precision: 0.9875 - recall: 0.9846 - val_loss: 13608.6650 - val_accuracy: 0.1287 - val_precision: 0.1287 - val_recall: 0.1287\n","Epoch 1006/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0589 - accuracy: 0.9789 - precision: 0.9802 - recall: 0.9780 - val_loss: 14517.3447 - val_accuracy: 0.1261 - val_precision: 0.1261 - val_recall: 0.1261\n","Epoch 1007/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0463 - accuracy: 0.9845 - precision: 0.9856 - recall: 0.9834 - val_loss: 13505.4385 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 1008/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0566 - accuracy: 0.9807 - precision: 0.9822 - recall: 0.9791 - val_loss: 15345.4639 - val_accuracy: 0.1130 - val_precision: 0.1130 - val_recall: 0.1130\n","Epoch 1009/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0672 - accuracy: 0.9809 - precision: 0.9834 - recall: 0.9797 - val_loss: 16444.2559 - val_accuracy: 0.1312 - val_precision: 0.1312 - val_recall: 0.1312\n","Epoch 1010/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0486 - accuracy: 0.9840 - precision: 0.9848 - recall: 0.9829 - val_loss: 14079.3232 - val_accuracy: 0.1266 - val_precision: 0.1266 - val_recall: 0.1266\n","Epoch 1011/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0537 - accuracy: 0.9833 - precision: 0.9843 - recall: 0.9821 - val_loss: 14007.9365 - val_accuracy: 0.1155 - val_precision: 0.1155 - val_recall: 0.1155\n","Epoch 1012/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0518 - accuracy: 0.9814 - precision: 0.9832 - recall: 0.9802 - val_loss: 14896.3955 - val_accuracy: 0.1201 - val_precision: 0.1201 - val_recall: 0.1201\n","Epoch 1013/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0514 - accuracy: 0.9826 - precision: 0.9849 - recall: 0.9812 - val_loss: 15488.9062 - val_accuracy: 0.1109 - val_precision: 0.1109 - val_recall: 0.1109\n","Epoch 1014/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 0.0465 - accuracy: 0.9848 - precision: 0.9859 - recall: 0.9833 - val_loss: 13673.7568 - val_accuracy: 0.1231 - val_precision: 0.1231 - val_recall: 0.1231\n","Epoch 1015/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0571 - accuracy: 0.9801 - precision: 0.9814 - recall: 0.9792 - val_loss: 11986.8740 - val_accuracy: 0.1368 - val_precision: 0.1368 - val_recall: 0.1368\n","Epoch 1016/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0464 - accuracy: 0.9823 - precision: 0.9832 - recall: 0.9816 - val_loss: 13672.3584 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 1017/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0476 - accuracy: 0.9848 - precision: 0.9866 - recall: 0.9840 - val_loss: 15910.7627 - val_accuracy: 0.1155 - val_precision: 0.1155 - val_recall: 0.1155\n","Epoch 1018/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0511 - accuracy: 0.9841 - precision: 0.9854 - recall: 0.9836 - val_loss: 12842.6855 - val_accuracy: 0.1211 - val_precision: 0.1211 - val_recall: 0.1211\n","Epoch 1019/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0485 - accuracy: 0.9828 - precision: 0.9837 - recall: 0.9811 - val_loss: 11880.0146 - val_accuracy: 0.1439 - val_precision: 0.1439 - val_recall: 0.1439\n","Epoch 1020/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0464 - accuracy: 0.9860 - precision: 0.9878 - recall: 0.9846 - val_loss: 12166.0117 - val_accuracy: 0.1479 - val_precision: 0.1479 - val_recall: 0.1479\n","Epoch 1021/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0502 - accuracy: 0.9843 - precision: 0.9848 - recall: 0.9834 - val_loss: 12381.1123 - val_accuracy: 0.1540 - val_precision: 0.1540 - val_recall: 0.1540\n","Epoch 1022/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0492 - accuracy: 0.9828 - precision: 0.9834 - recall: 0.9818 - val_loss: 14168.0000 - val_accuracy: 0.1074 - val_precision: 0.1074 - val_recall: 0.1074\n","Epoch 1023/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0459 - accuracy: 0.9840 - precision: 0.9851 - recall: 0.9828 - val_loss: 12868.2002 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 1024/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0489 - accuracy: 0.9841 - precision: 0.9854 - recall: 0.9829 - val_loss: 12875.4033 - val_accuracy: 0.1499 - val_precision: 0.1499 - val_recall: 0.1499\n","Epoch 1025/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0442 - accuracy: 0.9867 - precision: 0.9875 - recall: 0.9851 - val_loss: 13037.2451 - val_accuracy: 0.1439 - val_precision: 0.1439 - val_recall: 0.1439\n","Epoch 1026/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0380 - accuracy: 0.9882 - precision: 0.9890 - recall: 0.9873 - val_loss: 12349.7891 - val_accuracy: 0.1489 - val_precision: 0.1489 - val_recall: 0.1489\n","Epoch 1027/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 0.0523 - accuracy: 0.9816 - precision: 0.9831 - recall: 0.9801 - val_loss: 12098.8057 - val_accuracy: 0.1449 - val_precision: 0.1449 - val_recall: 0.1449\n","Epoch 1028/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0503 - accuracy: 0.9846 - precision: 0.9853 - recall: 0.9836 - val_loss: 13455.8945 - val_accuracy: 0.1190 - val_precision: 0.1190 - val_recall: 0.1190\n","Epoch 1029/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0398 - accuracy: 0.9865 - precision: 0.9883 - recall: 0.9858 - val_loss: 13644.0566 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 1030/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0462 - accuracy: 0.9850 - precision: 0.9854 - recall: 0.9834 - val_loss: 13616.8428 - val_accuracy: 0.1261 - val_precision: 0.1261 - val_recall: 0.1261\n","Epoch 1031/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0435 - accuracy: 0.9836 - precision: 0.9853 - recall: 0.9828 - val_loss: 15405.2021 - val_accuracy: 0.1074 - val_precision: 0.1074 - val_recall: 0.1074\n","Epoch 1032/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0484 - accuracy: 0.9834 - precision: 0.9849 - recall: 0.9818 - val_loss: 14304.4414 - val_accuracy: 0.1109 - val_precision: 0.1109 - val_recall: 0.1109\n","Epoch 1033/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0557 - accuracy: 0.9811 - precision: 0.9824 - recall: 0.9804 - val_loss: 15796.0742 - val_accuracy: 0.1246 - val_precision: 0.1246 - val_recall: 0.1246\n","Epoch 1034/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0427 - accuracy: 0.9841 - precision: 0.9854 - recall: 0.9833 - val_loss: 12911.4883 - val_accuracy: 0.1241 - val_precision: 0.1241 - val_recall: 0.1241\n","Epoch 1035/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0399 - accuracy: 0.9875 - precision: 0.9885 - recall: 0.9865 - val_loss: 14666.5674 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 1036/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0440 - accuracy: 0.9840 - precision: 0.9851 - recall: 0.9838 - val_loss: 13752.5586 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 1037/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0382 - accuracy: 0.9877 - precision: 0.9883 - recall: 0.9873 - val_loss: 11755.2773 - val_accuracy: 0.1484 - val_precision: 0.1484 - val_recall: 0.1484\n","Epoch 1038/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0434 - accuracy: 0.9848 - precision: 0.9856 - recall: 0.9841 - val_loss: 14422.9883 - val_accuracy: 0.1079 - val_precision: 0.1079 - val_recall: 0.1079\n","Epoch 1039/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0432 - accuracy: 0.9872 - precision: 0.9880 - recall: 0.9861 - val_loss: 13067.9844 - val_accuracy: 0.1292 - val_precision: 0.1292 - val_recall: 0.1292\n","Epoch 1040/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 0.0456 - accuracy: 0.9848 - precision: 0.9863 - recall: 0.9841 - val_loss: 13997.5977 - val_accuracy: 0.1261 - val_precision: 0.1261 - val_recall: 0.1261\n","Epoch 1041/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0537 - accuracy: 0.9816 - precision: 0.9831 - recall: 0.9804 - val_loss: 13326.0859 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 1042/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0503 - accuracy: 0.9834 - precision: 0.9849 - recall: 0.9821 - val_loss: 15403.0859 - val_accuracy: 0.1099 - val_precision: 0.1099 - val_recall: 0.1099\n","Epoch 1043/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0370 - accuracy: 0.9872 - precision: 0.9886 - recall: 0.9860 - val_loss: 13523.2383 - val_accuracy: 0.1206 - val_precision: 0.1206 - val_recall: 0.1206\n","Epoch 1044/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0457 - accuracy: 0.9848 - precision: 0.9865 - recall: 0.9841 - val_loss: 13205.1152 - val_accuracy: 0.1261 - val_precision: 0.1261 - val_recall: 0.1261\n","Epoch 1045/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0471 - accuracy: 0.9845 - precision: 0.9849 - recall: 0.9826 - val_loss: 13523.4443 - val_accuracy: 0.1231 - val_precision: 0.1231 - val_recall: 0.1231\n","Epoch 1046/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0435 - accuracy: 0.9870 - precision: 0.9881 - recall: 0.9861 - val_loss: 13429.1826 - val_accuracy: 0.1353 - val_precision: 0.1353 - val_recall: 0.1353\n","Epoch 1047/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0434 - accuracy: 0.9853 - precision: 0.9868 - recall: 0.9840 - val_loss: 13805.2168 - val_accuracy: 0.1302 - val_precision: 0.1302 - val_recall: 0.1302\n","Epoch 1048/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0377 - accuracy: 0.9877 - precision: 0.9885 - recall: 0.9865 - val_loss: 14816.1895 - val_accuracy: 0.1206 - val_precision: 0.1206 - val_recall: 0.1206\n","Epoch 1049/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0454 - accuracy: 0.9838 - precision: 0.9848 - recall: 0.9828 - val_loss: 13270.1689 - val_accuracy: 0.1292 - val_precision: 0.1292 - val_recall: 0.1292\n","Epoch 1050/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0491 - accuracy: 0.9834 - precision: 0.9842 - recall: 0.9818 - val_loss: 15565.2070 - val_accuracy: 0.1109 - val_precision: 0.1109 - val_recall: 0.1109\n","Epoch 1051/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0544 - accuracy: 0.9828 - precision: 0.9837 - recall: 0.9814 - val_loss: 14890.9336 - val_accuracy: 0.1094 - val_precision: 0.1094 - val_recall: 0.1094\n","Epoch 1052/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 0.0394 - accuracy: 0.9861 - precision: 0.9883 - recall: 0.9851 - val_loss: 12488.3594 - val_accuracy: 0.1363 - val_precision: 0.1363 - val_recall: 0.1363\n","Epoch 1053/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0433 - accuracy: 0.9846 - precision: 0.9863 - recall: 0.9831 - val_loss: 15304.5146 - val_accuracy: 0.1226 - val_precision: 0.1226 - val_recall: 0.1226\n","Epoch 1054/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0576 - accuracy: 0.9843 - precision: 0.9858 - recall: 0.9833 - val_loss: 14131.7285 - val_accuracy: 0.1256 - val_precision: 0.1256 - val_recall: 0.1256\n","Epoch 1055/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0473 - accuracy: 0.9836 - precision: 0.9853 - recall: 0.9828 - val_loss: 14040.8037 - val_accuracy: 0.1130 - val_precision: 0.1130 - val_recall: 0.1130\n","Epoch 1056/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0383 - accuracy: 0.9867 - precision: 0.9871 - recall: 0.9858 - val_loss: 15241.6797 - val_accuracy: 0.1135 - val_precision: 0.1135 - val_recall: 0.1135\n","Epoch 1057/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0531 - accuracy: 0.9821 - precision: 0.9832 - recall: 0.9807 - val_loss: 14567.0371 - val_accuracy: 0.1246 - val_precision: 0.1246 - val_recall: 0.1246\n","Epoch 1058/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0425 - accuracy: 0.9858 - precision: 0.9868 - recall: 0.9838 - val_loss: 16489.5371 - val_accuracy: 0.1135 - val_precision: 0.1135 - val_recall: 0.1135\n","Epoch 1059/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0368 - accuracy: 0.9883 - precision: 0.9898 - recall: 0.9877 - val_loss: 15470.1025 - val_accuracy: 0.1049 - val_precision: 0.1049 - val_recall: 0.1049\n","Epoch 1060/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0518 - accuracy: 0.9826 - precision: 0.9837 - recall: 0.9814 - val_loss: 13776.7227 - val_accuracy: 0.1266 - val_precision: 0.1266 - val_recall: 0.1266\n","Epoch 1061/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0412 - accuracy: 0.9851 - precision: 0.9859 - recall: 0.9838 - val_loss: 15195.6611 - val_accuracy: 0.1084 - val_precision: 0.1084 - val_recall: 0.1084\n","Epoch 1062/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0466 - accuracy: 0.9846 - precision: 0.9858 - recall: 0.9834 - val_loss: 14634.0625 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 1063/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0421 - accuracy: 0.9845 - precision: 0.9863 - recall: 0.9840 - val_loss: 13960.9893 - val_accuracy: 0.1429 - val_precision: 0.1429 - val_recall: 0.1429\n","Epoch 1064/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0484 - accuracy: 0.9850 - precision: 0.9864 - recall: 0.9838 - val_loss: 13944.7275 - val_accuracy: 0.1120 - val_precision: 0.1120 - val_recall: 0.1120\n","Epoch 1065/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 0.0459 - accuracy: 0.9848 - precision: 0.9860 - recall: 0.9843 - val_loss: 13428.5117 - val_accuracy: 0.1383 - val_precision: 0.1383 - val_recall: 0.1383\n","Epoch 1066/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0518 - accuracy: 0.9829 - precision: 0.9839 - recall: 0.9806 - val_loss: 12926.1084 - val_accuracy: 0.1307 - val_precision: 0.1307 - val_recall: 0.1307\n","Epoch 1067/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0432 - accuracy: 0.9846 - precision: 0.9858 - recall: 0.9834 - val_loss: 13218.8350 - val_accuracy: 0.1388 - val_precision: 0.1388 - val_recall: 0.1388\n","Epoch 1068/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0428 - accuracy: 0.9865 - precision: 0.9875 - recall: 0.9858 - val_loss: 14277.4678 - val_accuracy: 0.1155 - val_precision: 0.1155 - val_recall: 0.1155\n","Epoch 1069/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0504 - accuracy: 0.9833 - precision: 0.9844 - recall: 0.9831 - val_loss: 14019.3086 - val_accuracy: 0.1196 - val_precision: 0.1196 - val_recall: 0.1196\n","Epoch 1070/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0403 - accuracy: 0.9872 - precision: 0.9887 - recall: 0.9861 - val_loss: 13383.6816 - val_accuracy: 0.1322 - val_precision: 0.1322 - val_recall: 0.1322\n","Epoch 1071/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0473 - accuracy: 0.9851 - precision: 0.9863 - recall: 0.9840 - val_loss: 14075.9785 - val_accuracy: 0.1272 - val_precision: 0.1272 - val_recall: 0.1272\n","Epoch 1072/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0426 - accuracy: 0.9860 - precision: 0.9868 - recall: 0.9851 - val_loss: 15191.7285 - val_accuracy: 0.1246 - val_precision: 0.1246 - val_recall: 0.1246\n","Epoch 1073/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0371 - accuracy: 0.9877 - precision: 0.9890 - recall: 0.9865 - val_loss: 13027.0654 - val_accuracy: 0.1241 - val_precision: 0.1241 - val_recall: 0.1241\n","Epoch 1074/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0452 - accuracy: 0.9834 - precision: 0.9844 - recall: 0.9829 - val_loss: 15063.9189 - val_accuracy: 0.1114 - val_precision: 0.1114 - val_recall: 0.1114\n","Epoch 1075/10000\n","185/185 [==============================] - 16s 86ms/step - loss: 0.0336 - accuracy: 0.9905 - precision: 0.9910 - recall: 0.9900 - val_loss: 13873.9834 - val_accuracy: 0.1256 - val_precision: 0.1256 - val_recall: 0.1256\n","Epoch 1076/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0405 - accuracy: 0.9875 - precision: 0.9877 - recall: 0.9870 - val_loss: 13012.0977 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 1077/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 0.0442 - accuracy: 0.9840 - precision: 0.9851 - recall: 0.9828 - val_loss: 13225.1904 - val_accuracy: 0.1398 - val_precision: 0.1398 - val_recall: 0.1398\n","Epoch 1078/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0434 - accuracy: 0.9851 - precision: 0.9858 - recall: 0.9840 - val_loss: 13647.7363 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 1079/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0474 - accuracy: 0.9841 - precision: 0.9858 - recall: 0.9828 - val_loss: 13980.9717 - val_accuracy: 0.1348 - val_precision: 0.1348 - val_recall: 0.1348\n","Epoch 1080/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0486 - accuracy: 0.9829 - precision: 0.9839 - recall: 0.9819 - val_loss: 15223.7842 - val_accuracy: 0.1160 - val_precision: 0.1160 - val_recall: 0.1160\n","Epoch 1081/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0487 - accuracy: 0.9829 - precision: 0.9848 - recall: 0.9824 - val_loss: 18213.2754 - val_accuracy: 0.0963 - val_precision: 0.0963 - val_recall: 0.0963\n","Epoch 1082/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0526 - accuracy: 0.9841 - precision: 0.9854 - recall: 0.9834 - val_loss: 18537.3516 - val_accuracy: 0.0932 - val_precision: 0.0932 - val_recall: 0.0932\n","Epoch 1083/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0373 - accuracy: 0.9885 - precision: 0.9890 - recall: 0.9873 - val_loss: 13184.7637 - val_accuracy: 0.1287 - val_precision: 0.1287 - val_recall: 0.1287\n","Epoch 1084/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0503 - accuracy: 0.9843 - precision: 0.9849 - recall: 0.9840 - val_loss: 14947.3271 - val_accuracy: 0.1312 - val_precision: 0.1312 - val_recall: 0.1312\n","Epoch 1085/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0494 - accuracy: 0.9846 - precision: 0.9859 - recall: 0.9833 - val_loss: 14361.6992 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 1086/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0553 - accuracy: 0.9814 - precision: 0.9829 - recall: 0.9801 - val_loss: 12293.5596 - val_accuracy: 0.1444 - val_precision: 0.1444 - val_recall: 0.1444\n","Epoch 1087/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0587 - accuracy: 0.9802 - precision: 0.9812 - recall: 0.9792 - val_loss: 14754.1738 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 1088/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0419 - accuracy: 0.9867 - precision: 0.9883 - recall: 0.9856 - val_loss: 14361.6572 - val_accuracy: 0.1358 - val_precision: 0.1358 - val_recall: 0.1358\n","Epoch 1089/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0413 - accuracy: 0.9878 - precision: 0.9887 - recall: 0.9867 - val_loss: 14456.5293 - val_accuracy: 0.1256 - val_precision: 0.1256 - val_recall: 0.1256\n","Epoch 1090/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 0.0523 - accuracy: 0.9812 - precision: 0.9827 - recall: 0.9801 - val_loss: 13677.2158 - val_accuracy: 0.1408 - val_precision: 0.1408 - val_recall: 0.1408\n","Epoch 1091/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0432 - accuracy: 0.9843 - precision: 0.9856 - recall: 0.9836 - val_loss: 13287.0107 - val_accuracy: 0.1393 - val_precision: 0.1393 - val_recall: 0.1393\n","Epoch 1092/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0436 - accuracy: 0.9858 - precision: 0.9865 - recall: 0.9846 - val_loss: 12928.3975 - val_accuracy: 0.1494 - val_precision: 0.1494 - val_recall: 0.1494\n","Epoch 1093/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0394 - accuracy: 0.9873 - precision: 0.9882 - recall: 0.9863 - val_loss: 14982.0195 - val_accuracy: 0.1196 - val_precision: 0.1196 - val_recall: 0.1196\n","Epoch 1094/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0446 - accuracy: 0.9846 - precision: 0.9861 - recall: 0.9836 - val_loss: 13003.6875 - val_accuracy: 0.1449 - val_precision: 0.1449 - val_recall: 0.1449\n","Epoch 1095/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0426 - accuracy: 0.9868 - precision: 0.9876 - recall: 0.9861 - val_loss: 14330.8271 - val_accuracy: 0.1196 - val_precision: 0.1196 - val_recall: 0.1196\n","Epoch 1096/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0466 - accuracy: 0.9855 - precision: 0.9873 - recall: 0.9841 - val_loss: 14542.0820 - val_accuracy: 0.1302 - val_precision: 0.1302 - val_recall: 0.1302\n","Epoch 1097/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0450 - accuracy: 0.9846 - precision: 0.9861 - recall: 0.9834 - val_loss: 15039.1260 - val_accuracy: 0.1246 - val_precision: 0.1246 - val_recall: 0.1246\n","Epoch 1098/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0491 - accuracy: 0.9831 - precision: 0.9844 - recall: 0.9819 - val_loss: 14376.7812 - val_accuracy: 0.1388 - val_precision: 0.1388 - val_recall: 0.1388\n","Epoch 1099/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0465 - accuracy: 0.9848 - precision: 0.9866 - recall: 0.9833 - val_loss: 14156.1768 - val_accuracy: 0.1236 - val_precision: 0.1236 - val_recall: 0.1236\n","Epoch 1100/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0398 - accuracy: 0.9878 - precision: 0.9890 - recall: 0.9867 - val_loss: 15503.9111 - val_accuracy: 0.0993 - val_precision: 0.0993 - val_recall: 0.0993\n","Epoch 1101/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0483 - accuracy: 0.9831 - precision: 0.9843 - recall: 0.9823 - val_loss: 11991.8408 - val_accuracy: 0.1297 - val_precision: 0.1297 - val_recall: 0.1297\n","Epoch 1102/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0483 - accuracy: 0.9838 - precision: 0.9854 - recall: 0.9828 - val_loss: 14347.9424 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 1103/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 0.0411 - accuracy: 0.9872 - precision: 0.9881 - recall: 0.9861 - val_loss: 13844.2510 - val_accuracy: 0.1307 - val_precision: 0.1307 - val_recall: 0.1307\n","Epoch 1104/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0469 - accuracy: 0.9860 - precision: 0.9868 - recall: 0.9858 - val_loss: 16577.0156 - val_accuracy: 0.0993 - val_precision: 0.0993 - val_recall: 0.0993\n","Epoch 1105/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0393 - accuracy: 0.9863 - precision: 0.9873 - recall: 0.9851 - val_loss: 14621.5752 - val_accuracy: 0.1287 - val_precision: 0.1287 - val_recall: 0.1287\n","Epoch 1106/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0381 - accuracy: 0.9867 - precision: 0.9876 - recall: 0.9855 - val_loss: 15151.3711 - val_accuracy: 0.1069 - val_precision: 0.1069 - val_recall: 0.1069\n","Epoch 1107/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0494 - accuracy: 0.9843 - precision: 0.9856 - recall: 0.9831 - val_loss: 13270.4971 - val_accuracy: 0.1272 - val_precision: 0.1272 - val_recall: 0.1272\n","Epoch 1108/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0346 - accuracy: 0.9868 - precision: 0.9871 - recall: 0.9861 - val_loss: 13593.4639 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 1109/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0472 - accuracy: 0.9851 - precision: 0.9861 - recall: 0.9840 - val_loss: 14508.8184 - val_accuracy: 0.1196 - val_precision: 0.1196 - val_recall: 0.1196\n","Epoch 1110/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0448 - accuracy: 0.9867 - precision: 0.9873 - recall: 0.9861 - val_loss: 14202.4746 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 1111/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0445 - accuracy: 0.9856 - precision: 0.9861 - recall: 0.9843 - val_loss: 15299.0352 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 1112/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0393 - accuracy: 0.9873 - precision: 0.9878 - recall: 0.9861 - val_loss: 15152.2646 - val_accuracy: 0.1130 - val_precision: 0.1130 - val_recall: 0.1130\n","Epoch 1113/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0360 - accuracy: 0.9880 - precision: 0.9888 - recall: 0.9873 - val_loss: 14616.1709 - val_accuracy: 0.1256 - val_precision: 0.1256 - val_recall: 0.1256\n","Epoch 1114/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0434 - accuracy: 0.9848 - precision: 0.9866 - recall: 0.9845 - val_loss: 13774.5625 - val_accuracy: 0.1287 - val_precision: 0.1287 - val_recall: 0.1287\n","Epoch 1115/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 0.0405 - accuracy: 0.9851 - precision: 0.9860 - recall: 0.9841 - val_loss: 16369.4834 - val_accuracy: 0.1018 - val_precision: 0.1018 - val_recall: 0.1018\n","Epoch 1116/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0439 - accuracy: 0.9860 - precision: 0.9868 - recall: 0.9846 - val_loss: 14684.5293 - val_accuracy: 0.1185 - val_precision: 0.1185 - val_recall: 0.1185\n","Epoch 1117/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0394 - accuracy: 0.9861 - precision: 0.9870 - recall: 0.9850 - val_loss: 14064.9727 - val_accuracy: 0.1221 - val_precision: 0.1221 - val_recall: 0.1221\n","Epoch 1118/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0418 - accuracy: 0.9860 - precision: 0.9871 - recall: 0.9851 - val_loss: 16330.9668 - val_accuracy: 0.1160 - val_precision: 0.1160 - val_recall: 0.1160\n","Epoch 1119/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0515 - accuracy: 0.9826 - precision: 0.9841 - recall: 0.9819 - val_loss: 15723.0488 - val_accuracy: 0.1196 - val_precision: 0.1196 - val_recall: 0.1196\n","Epoch 1120/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0442 - accuracy: 0.9848 - precision: 0.9860 - recall: 0.9841 - val_loss: 19171.6035 - val_accuracy: 0.0851 - val_precision: 0.0851 - val_recall: 0.0851\n","Epoch 1121/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0526 - accuracy: 0.9836 - precision: 0.9843 - recall: 0.9833 - val_loss: 14093.8525 - val_accuracy: 0.1140 - val_precision: 0.1140 - val_recall: 0.1140\n","Epoch 1122/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 0.0470 - accuracy: 0.9846 - precision: 0.9858 - recall: 0.9838 - val_loss: 17822.0742 - val_accuracy: 0.0917 - val_precision: 0.0917 - val_recall: 0.0917\n","Epoch 1123/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0481 - accuracy: 0.9818 - precision: 0.9829 - recall: 0.9811 - val_loss: 14860.5117 - val_accuracy: 0.1089 - val_precision: 0.1089 - val_recall: 0.1089\n","Epoch 1124/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0370 - accuracy: 0.9873 - precision: 0.9878 - recall: 0.9867 - val_loss: 14697.1729 - val_accuracy: 0.1135 - val_precision: 0.1135 - val_recall: 0.1135\n","Epoch 1125/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0426 - accuracy: 0.9848 - precision: 0.9859 - recall: 0.9840 - val_loss: 15500.2998 - val_accuracy: 0.1363 - val_precision: 0.1363 - val_recall: 0.1363\n","Epoch 1126/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0458 - accuracy: 0.9846 - precision: 0.9858 - recall: 0.9838 - val_loss: 15046.6045 - val_accuracy: 0.1322 - val_precision: 0.1322 - val_recall: 0.1322\n","Epoch 1127/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0359 - accuracy: 0.9878 - precision: 0.9887 - recall: 0.9873 - val_loss: 15118.6406 - val_accuracy: 0.1246 - val_precision: 0.1246 - val_recall: 0.1246\n","Epoch 1128/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 0.0475 - accuracy: 0.9843 - precision: 0.9848 - recall: 0.9840 - val_loss: 15358.3506 - val_accuracy: 0.1266 - val_precision: 0.1266 - val_recall: 0.1266\n","Epoch 1129/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0468 - accuracy: 0.9841 - precision: 0.9851 - recall: 0.9833 - val_loss: 14445.8975 - val_accuracy: 0.1246 - val_precision: 0.1246 - val_recall: 0.1246\n","Epoch 1130/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0336 - accuracy: 0.9890 - precision: 0.9900 - recall: 0.9885 - val_loss: 12798.0459 - val_accuracy: 0.1449 - val_precision: 0.1449 - val_recall: 0.1449\n","Epoch 1131/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0385 - accuracy: 0.9856 - precision: 0.9871 - recall: 0.9850 - val_loss: 16004.2793 - val_accuracy: 0.1099 - val_precision: 0.1099 - val_recall: 0.1099\n","Epoch 1132/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0440 - accuracy: 0.9848 - precision: 0.9859 - recall: 0.9840 - val_loss: 14688.5645 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 1133/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0395 - accuracy: 0.9887 - precision: 0.9897 - recall: 0.9875 - val_loss: 15226.4971 - val_accuracy: 0.1084 - val_precision: 0.1084 - val_recall: 0.1084\n","Epoch 1134/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0382 - accuracy: 0.9872 - precision: 0.9882 - recall: 0.9868 - val_loss: 15068.9785 - val_accuracy: 0.1180 - val_precision: 0.1180 - val_recall: 0.1180\n","Epoch 1135/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0435 - accuracy: 0.9858 - precision: 0.9865 - recall: 0.9851 - val_loss: 15202.3350 - val_accuracy: 0.1094 - val_precision: 0.1094 - val_recall: 0.1094\n","Epoch 1136/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0470 - accuracy: 0.9836 - precision: 0.9853 - recall: 0.9831 - val_loss: 14376.6387 - val_accuracy: 0.1322 - val_precision: 0.1322 - val_recall: 0.1322\n","Epoch 1137/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0459 - accuracy: 0.9860 - precision: 0.9870 - recall: 0.9850 - val_loss: 14740.4697 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 1138/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0373 - accuracy: 0.9882 - precision: 0.9888 - recall: 0.9865 - val_loss: 14606.7422 - val_accuracy: 0.1059 - val_precision: 0.1059 - val_recall: 0.1059\n","Epoch 1139/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0455 - accuracy: 0.9861 - precision: 0.9875 - recall: 0.9853 - val_loss: 16494.0234 - val_accuracy: 0.1185 - val_precision: 0.1185 - val_recall: 0.1185\n","Epoch 1140/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 0.0355 - accuracy: 0.9895 - precision: 0.9902 - recall: 0.9883 - val_loss: 16861.2324 - val_accuracy: 0.0998 - val_precision: 0.0998 - val_recall: 0.0998\n","Epoch 1141/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0446 - accuracy: 0.9836 - precision: 0.9849 - recall: 0.9828 - val_loss: 14190.3467 - val_accuracy: 0.1342 - val_precision: 0.1342 - val_recall: 0.1342\n","Epoch 1142/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0358 - accuracy: 0.9887 - precision: 0.9902 - recall: 0.9877 - val_loss: 14322.1680 - val_accuracy: 0.1231 - val_precision: 0.1231 - val_recall: 0.1231\n","Epoch 1143/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0391 - accuracy: 0.9875 - precision: 0.9890 - recall: 0.9868 - val_loss: 15076.3896 - val_accuracy: 0.1125 - val_precision: 0.1125 - val_recall: 0.1125\n","Epoch 1144/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0486 - accuracy: 0.9845 - precision: 0.9863 - recall: 0.9840 - val_loss: 15168.5127 - val_accuracy: 0.1383 - val_precision: 0.1383 - val_recall: 0.1383\n","Epoch 1145/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0383 - accuracy: 0.9877 - precision: 0.9885 - recall: 0.9870 - val_loss: 13904.2441 - val_accuracy: 0.1211 - val_precision: 0.1211 - val_recall: 0.1211\n","Epoch 1146/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0414 - accuracy: 0.9840 - precision: 0.9858 - recall: 0.9833 - val_loss: 15821.7510 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 1147/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0440 - accuracy: 0.9846 - precision: 0.9858 - recall: 0.9840 - val_loss: 14793.3975 - val_accuracy: 0.1246 - val_precision: 0.1246 - val_recall: 0.1246\n","Epoch 1148/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0353 - accuracy: 0.9880 - precision: 0.9887 - recall: 0.9867 - val_loss: 14691.1289 - val_accuracy: 0.1185 - val_precision: 0.1185 - val_recall: 0.1185\n","Epoch 1149/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0348 - accuracy: 0.9880 - precision: 0.9888 - recall: 0.9873 - val_loss: 13652.1650 - val_accuracy: 0.1393 - val_precision: 0.1393 - val_recall: 0.1393\n","Epoch 1150/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0370 - accuracy: 0.9861 - precision: 0.9871 - recall: 0.9853 - val_loss: 14292.6182 - val_accuracy: 0.1353 - val_precision: 0.1353 - val_recall: 0.1353\n","Epoch 1151/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0386 - accuracy: 0.9856 - precision: 0.9871 - recall: 0.9845 - val_loss: 15523.7529 - val_accuracy: 0.1003 - val_precision: 0.1003 - val_recall: 0.1003\n","Epoch 1152/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0424 - accuracy: 0.9872 - precision: 0.9878 - recall: 0.9865 - val_loss: 15719.7559 - val_accuracy: 0.1104 - val_precision: 0.1104 - val_recall: 0.1104\n","Epoch 1153/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 0.0388 - accuracy: 0.9863 - precision: 0.9870 - recall: 0.9856 - val_loss: 16879.0215 - val_accuracy: 0.0973 - val_precision: 0.0973 - val_recall: 0.0973\n","Epoch 1154/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0455 - accuracy: 0.9845 - precision: 0.9861 - recall: 0.9838 - val_loss: 16218.7852 - val_accuracy: 0.1023 - val_precision: 0.1023 - val_recall: 0.1023\n","Epoch 1155/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0437 - accuracy: 0.9858 - precision: 0.9866 - recall: 0.9846 - val_loss: 13502.5703 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 1156/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0372 - accuracy: 0.9880 - precision: 0.9883 - recall: 0.9868 - val_loss: 16162.4736 - val_accuracy: 0.1049 - val_precision: 0.1049 - val_recall: 0.1049\n","Epoch 1157/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0358 - accuracy: 0.9868 - precision: 0.9883 - recall: 0.9858 - val_loss: 16994.4453 - val_accuracy: 0.1059 - val_precision: 0.1059 - val_recall: 0.1059\n","Epoch 1158/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0403 - accuracy: 0.9853 - precision: 0.9863 - recall: 0.9845 - val_loss: 15786.8838 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 1159/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0427 - accuracy: 0.9850 - precision: 0.9866 - recall: 0.9845 - val_loss: 15617.5215 - val_accuracy: 0.1201 - val_precision: 0.1201 - val_recall: 0.1201\n","Epoch 1160/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0417 - accuracy: 0.9860 - precision: 0.9870 - recall: 0.9850 - val_loss: 15712.0664 - val_accuracy: 0.1084 - val_precision: 0.1084 - val_recall: 0.1084\n","Epoch 1161/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0466 - accuracy: 0.9855 - precision: 0.9865 - recall: 0.9846 - val_loss: 13120.2256 - val_accuracy: 0.1378 - val_precision: 0.1378 - val_recall: 0.1378\n","Epoch 1162/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0358 - accuracy: 0.9872 - precision: 0.9880 - recall: 0.9856 - val_loss: 14264.8213 - val_accuracy: 0.1120 - val_precision: 0.1120 - val_recall: 0.1120\n","Epoch 1163/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0475 - accuracy: 0.9855 - precision: 0.9870 - recall: 0.9845 - val_loss: 15018.3555 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 1164/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0370 - accuracy: 0.9878 - precision: 0.9890 - recall: 0.9870 - val_loss: 14579.6768 - val_accuracy: 0.1317 - val_precision: 0.1317 - val_recall: 0.1317\n","Epoch 1165/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 0.0398 - accuracy: 0.9853 - precision: 0.9866 - recall: 0.9843 - val_loss: 14184.4014 - val_accuracy: 0.1388 - val_precision: 0.1388 - val_recall: 0.1388\n","Epoch 1166/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0414 - accuracy: 0.9846 - precision: 0.9858 - recall: 0.9838 - val_loss: 12603.4258 - val_accuracy: 0.1398 - val_precision: 0.1398 - val_recall: 0.1398\n","Epoch 1167/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0534 - accuracy: 0.9819 - precision: 0.9837 - recall: 0.9809 - val_loss: 14992.7412 - val_accuracy: 0.1251 - val_precision: 0.1251 - val_recall: 0.1251\n","Epoch 1168/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0319 - accuracy: 0.9892 - precision: 0.9914 - recall: 0.9887 - val_loss: 14675.4434 - val_accuracy: 0.1241 - val_precision: 0.1241 - val_recall: 0.1241\n","Epoch 1169/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0415 - accuracy: 0.9870 - precision: 0.9873 - recall: 0.9863 - val_loss: 17297.8320 - val_accuracy: 0.0957 - val_precision: 0.0957 - val_recall: 0.0957\n","Epoch 1170/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0467 - accuracy: 0.9846 - precision: 0.9855 - recall: 0.9843 - val_loss: 15861.0957 - val_accuracy: 0.1125 - val_precision: 0.1125 - val_recall: 0.1125\n","Epoch 1171/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0408 - accuracy: 0.9863 - precision: 0.9868 - recall: 0.9855 - val_loss: 15021.8438 - val_accuracy: 0.1190 - val_precision: 0.1190 - val_recall: 0.1190\n","Epoch 1172/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0326 - accuracy: 0.9892 - precision: 0.9898 - recall: 0.9885 - val_loss: 14722.9736 - val_accuracy: 0.1256 - val_precision: 0.1256 - val_recall: 0.1256\n","Epoch 1173/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0422 - accuracy: 0.9848 - precision: 0.9861 - recall: 0.9846 - val_loss: 16491.0078 - val_accuracy: 0.1160 - val_precision: 0.1160 - val_recall: 0.1160\n","Epoch 1174/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0463 - accuracy: 0.9851 - precision: 0.9865 - recall: 0.9841 - val_loss: 14871.3779 - val_accuracy: 0.1074 - val_precision: 0.1074 - val_recall: 0.1074\n","Epoch 1175/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0416 - accuracy: 0.9846 - precision: 0.9856 - recall: 0.9840 - val_loss: 15436.1992 - val_accuracy: 0.1221 - val_precision: 0.1221 - val_recall: 0.1221\n","Epoch 1176/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0373 - accuracy: 0.9873 - precision: 0.9881 - recall: 0.9861 - val_loss: 14973.1523 - val_accuracy: 0.1135 - val_precision: 0.1135 - val_recall: 0.1135\n","Epoch 1177/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0422 - accuracy: 0.9855 - precision: 0.9875 - recall: 0.9850 - val_loss: 15538.2754 - val_accuracy: 0.1226 - val_precision: 0.1226 - val_recall: 0.1226\n","Epoch 1178/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 0.0389 - accuracy: 0.9865 - precision: 0.9870 - recall: 0.9856 - val_loss: 16334.4951 - val_accuracy: 0.1114 - val_precision: 0.1114 - val_recall: 0.1114\n","Epoch 1179/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0434 - accuracy: 0.9846 - precision: 0.9855 - recall: 0.9843 - val_loss: 15218.1543 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 1180/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0395 - accuracy: 0.9870 - precision: 0.9873 - recall: 0.9856 - val_loss: 17437.5605 - val_accuracy: 0.1145 - val_precision: 0.1145 - val_recall: 0.1145\n","Epoch 1181/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0408 - accuracy: 0.9861 - precision: 0.9873 - recall: 0.9856 - val_loss: 15751.9180 - val_accuracy: 0.1114 - val_precision: 0.1114 - val_recall: 0.1114\n","Epoch 1182/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0441 - accuracy: 0.9860 - precision: 0.9878 - recall: 0.9850 - val_loss: 12430.3584 - val_accuracy: 0.1505 - val_precision: 0.1505 - val_recall: 0.1505\n","Epoch 1183/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0439 - accuracy: 0.9856 - precision: 0.9866 - recall: 0.9850 - val_loss: 14834.4629 - val_accuracy: 0.1251 - val_precision: 0.1251 - val_recall: 0.1251\n","Epoch 1184/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0340 - accuracy: 0.9882 - precision: 0.9887 - recall: 0.9875 - val_loss: 14984.8975 - val_accuracy: 0.1170 - val_precision: 0.1170 - val_recall: 0.1170\n","Epoch 1185/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0322 - accuracy: 0.9899 - precision: 0.9905 - recall: 0.9888 - val_loss: 13764.9307 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 1186/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0299 - accuracy: 0.9895 - precision: 0.9904 - recall: 0.9888 - val_loss: 13913.0010 - val_accuracy: 0.1373 - val_precision: 0.1373 - val_recall: 0.1373\n","Epoch 1187/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0476 - accuracy: 0.9824 - precision: 0.9841 - recall: 0.9812 - val_loss: 15275.3760 - val_accuracy: 0.1155 - val_precision: 0.1155 - val_recall: 0.1155\n","Epoch 1188/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0443 - accuracy: 0.9840 - precision: 0.9849 - recall: 0.9833 - val_loss: 14967.9189 - val_accuracy: 0.1277 - val_precision: 0.1277 - val_recall: 0.1277\n","Epoch 1189/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0319 - accuracy: 0.9904 - precision: 0.9910 - recall: 0.9900 - val_loss: 13475.5713 - val_accuracy: 0.1393 - val_precision: 0.1393 - val_recall: 0.1393\n","Epoch 1190/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 0.0357 - accuracy: 0.9877 - precision: 0.9882 - recall: 0.9863 - val_loss: 15010.4697 - val_accuracy: 0.1337 - val_precision: 0.1337 - val_recall: 0.1337\n","Epoch 1191/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0438 - accuracy: 0.9860 - precision: 0.9870 - recall: 0.9850 - val_loss: 14128.2158 - val_accuracy: 0.1312 - val_precision: 0.1312 - val_recall: 0.1312\n","Epoch 1192/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0416 - accuracy: 0.9861 - precision: 0.9873 - recall: 0.9856 - val_loss: 18068.7363 - val_accuracy: 0.1059 - val_precision: 0.1059 - val_recall: 0.1059\n","Epoch 1193/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0356 - accuracy: 0.9883 - precision: 0.9890 - recall: 0.9877 - val_loss: 16183.4854 - val_accuracy: 0.1201 - val_precision: 0.1201 - val_recall: 0.1201\n","Epoch 1194/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0370 - accuracy: 0.9865 - precision: 0.9883 - recall: 0.9858 - val_loss: 15339.0820 - val_accuracy: 0.1241 - val_precision: 0.1241 - val_recall: 0.1241\n","Epoch 1195/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0401 - accuracy: 0.9863 - precision: 0.9875 - recall: 0.9860 - val_loss: 16408.0586 - val_accuracy: 0.1089 - val_precision: 0.1089 - val_recall: 0.1089\n","Epoch 1196/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0399 - accuracy: 0.9863 - precision: 0.9875 - recall: 0.9855 - val_loss: 16309.4961 - val_accuracy: 0.1104 - val_precision: 0.1104 - val_recall: 0.1104\n","Epoch 1197/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0325 - accuracy: 0.9888 - precision: 0.9900 - recall: 0.9878 - val_loss: 15338.8125 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 1198/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0420 - accuracy: 0.9861 - precision: 0.9875 - recall: 0.9856 - val_loss: 13163.3115 - val_accuracy: 0.1393 - val_precision: 0.1393 - val_recall: 0.1393\n","Epoch 1199/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0351 - accuracy: 0.9873 - precision: 0.9876 - recall: 0.9861 - val_loss: 14586.9668 - val_accuracy: 0.1261 - val_precision: 0.1261 - val_recall: 0.1261\n","Epoch 1200/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0319 - accuracy: 0.9875 - precision: 0.9878 - recall: 0.9865 - val_loss: 13254.3164 - val_accuracy: 0.1363 - val_precision: 0.1363 - val_recall: 0.1363\n","Epoch 1201/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0373 - accuracy: 0.9868 - precision: 0.9882 - recall: 0.9863 - val_loss: 14364.9248 - val_accuracy: 0.1211 - val_precision: 0.1211 - val_recall: 0.1211\n","Epoch 1202/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0439 - accuracy: 0.9855 - precision: 0.9870 - recall: 0.9850 - val_loss: 14646.5723 - val_accuracy: 0.1261 - val_precision: 0.1261 - val_recall: 0.1261\n","Epoch 1203/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 0.0496 - accuracy: 0.9826 - precision: 0.9834 - recall: 0.9821 - val_loss: 12877.2793 - val_accuracy: 0.1535 - val_precision: 0.1535 - val_recall: 0.1535\n","Epoch 1204/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0410 - accuracy: 0.9882 - precision: 0.9897 - recall: 0.9868 - val_loss: 14869.2979 - val_accuracy: 0.1089 - val_precision: 0.1089 - val_recall: 0.1089\n","Epoch 1205/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0388 - accuracy: 0.9867 - precision: 0.9875 - recall: 0.9861 - val_loss: 14113.1885 - val_accuracy: 0.1185 - val_precision: 0.1185 - val_recall: 0.1185\n","Epoch 1206/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0412 - accuracy: 0.9861 - precision: 0.9870 - recall: 0.9855 - val_loss: 18317.3535 - val_accuracy: 0.1028 - val_precision: 0.1028 - val_recall: 0.1028\n","Epoch 1207/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0448 - accuracy: 0.9840 - precision: 0.9853 - recall: 0.9831 - val_loss: 14154.1709 - val_accuracy: 0.1226 - val_precision: 0.1226 - val_recall: 0.1226\n","Epoch 1208/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0454 - accuracy: 0.9850 - precision: 0.9863 - recall: 0.9845 - val_loss: 18664.3145 - val_accuracy: 0.0881 - val_precision: 0.0881 - val_recall: 0.0881\n","Epoch 1209/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0429 - accuracy: 0.9846 - precision: 0.9858 - recall: 0.9836 - val_loss: 15659.7881 - val_accuracy: 0.1054 - val_precision: 0.1054 - val_recall: 0.1054\n","Epoch 1210/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0433 - accuracy: 0.9851 - precision: 0.9870 - recall: 0.9845 - val_loss: 16450.9648 - val_accuracy: 0.1160 - val_precision: 0.1160 - val_recall: 0.1160\n","Epoch 1211/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0429 - accuracy: 0.9850 - precision: 0.9863 - recall: 0.9840 - val_loss: 14192.4102 - val_accuracy: 0.1160 - val_precision: 0.1160 - val_recall: 0.1160\n","Epoch 1212/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0435 - accuracy: 0.9858 - precision: 0.9873 - recall: 0.9848 - val_loss: 14909.2510 - val_accuracy: 0.1261 - val_precision: 0.1261 - val_recall: 0.1261\n","Epoch 1213/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0398 - accuracy: 0.9858 - precision: 0.9870 - recall: 0.9855 - val_loss: 14954.9668 - val_accuracy: 0.1211 - val_precision: 0.1211 - val_recall: 0.1211\n","Epoch 1214/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0465 - accuracy: 0.9850 - precision: 0.9864 - recall: 0.9836 - val_loss: 12929.7471 - val_accuracy: 0.1353 - val_precision: 0.1353 - val_recall: 0.1353\n","Epoch 1215/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 0.0369 - accuracy: 0.9880 - precision: 0.9887 - recall: 0.9873 - val_loss: 14297.7090 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 1216/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0368 - accuracy: 0.9865 - precision: 0.9871 - recall: 0.9856 - val_loss: 16543.7363 - val_accuracy: 0.1185 - val_precision: 0.1185 - val_recall: 0.1185\n","Epoch 1217/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0453 - accuracy: 0.9846 - precision: 0.9853 - recall: 0.9840 - val_loss: 12359.0342 - val_accuracy: 0.1530 - val_precision: 0.1530 - val_recall: 0.1530\n","Epoch 1218/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0380 - accuracy: 0.9873 - precision: 0.9887 - recall: 0.9861 - val_loss: 15456.1855 - val_accuracy: 0.1246 - val_precision: 0.1246 - val_recall: 0.1246\n","Epoch 1219/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0444 - accuracy: 0.9843 - precision: 0.9853 - recall: 0.9829 - val_loss: 16634.1816 - val_accuracy: 0.1150 - val_precision: 0.1150 - val_recall: 0.1150\n","Epoch 1220/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 0.0343 - accuracy: 0.9888 - precision: 0.9895 - recall: 0.9883 - val_loss: 16779.9414 - val_accuracy: 0.1084 - val_precision: 0.1084 - val_recall: 0.1084\n","Epoch 1221/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0438 - accuracy: 0.9856 - precision: 0.9865 - recall: 0.9850 - val_loss: 16315.2383 - val_accuracy: 0.1094 - val_precision: 0.1094 - val_recall: 0.1094\n","Epoch 1222/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0370 - accuracy: 0.9868 - precision: 0.9876 - recall: 0.9860 - val_loss: 17671.7461 - val_accuracy: 0.1013 - val_precision: 0.1013 - val_recall: 0.1013\n","Epoch 1223/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0360 - accuracy: 0.9877 - precision: 0.9883 - recall: 0.9867 - val_loss: 16280.5781 - val_accuracy: 0.1094 - val_precision: 0.1094 - val_recall: 0.1094\n","Epoch 1224/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0367 - accuracy: 0.9870 - precision: 0.9880 - recall: 0.9863 - val_loss: 16763.5664 - val_accuracy: 0.1054 - val_precision: 0.1054 - val_recall: 0.1054\n","Epoch 1225/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0487 - accuracy: 0.9838 - precision: 0.9851 - recall: 0.9833 - val_loss: 15643.2441 - val_accuracy: 0.1307 - val_precision: 0.1307 - val_recall: 0.1307\n","Epoch 1226/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0374 - accuracy: 0.9887 - precision: 0.9890 - recall: 0.9877 - val_loss: 15008.4922 - val_accuracy: 0.1256 - val_precision: 0.1256 - val_recall: 0.1256\n","Epoch 1227/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 0.0354 - accuracy: 0.9888 - precision: 0.9897 - recall: 0.9877 - val_loss: 14724.8730 - val_accuracy: 0.1099 - val_precision: 0.1099 - val_recall: 0.1099\n","Epoch 1228/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0476 - accuracy: 0.9836 - precision: 0.9849 - recall: 0.9826 - val_loss: 13873.4961 - val_accuracy: 0.1241 - val_precision: 0.1241 - val_recall: 0.1241\n","Epoch 1229/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0360 - accuracy: 0.9880 - precision: 0.9893 - recall: 0.9872 - val_loss: 16231.5947 - val_accuracy: 0.0952 - val_precision: 0.0952 - val_recall: 0.0952\n","Epoch 1230/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0407 - accuracy: 0.9868 - precision: 0.9880 - recall: 0.9851 - val_loss: 17006.3789 - val_accuracy: 0.1130 - val_precision: 0.1130 - val_recall: 0.1130\n","Epoch 1231/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0387 - accuracy: 0.9867 - precision: 0.9880 - recall: 0.9863 - val_loss: 16982.0020 - val_accuracy: 0.0922 - val_precision: 0.0922 - val_recall: 0.0922\n","Epoch 1232/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0431 - accuracy: 0.9855 - precision: 0.9858 - recall: 0.9846 - val_loss: 16021.3584 - val_accuracy: 0.1094 - val_precision: 0.1094 - val_recall: 0.1094\n","Epoch 1233/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0419 - accuracy: 0.9851 - precision: 0.9863 - recall: 0.9838 - val_loss: 14889.3467 - val_accuracy: 0.1418 - val_precision: 0.1418 - val_recall: 0.1418\n","Epoch 1234/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0465 - accuracy: 0.9855 - precision: 0.9866 - recall: 0.9846 - val_loss: 12565.0654 - val_accuracy: 0.1459 - val_precision: 0.1459 - val_recall: 0.1459\n","Epoch 1235/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0379 - accuracy: 0.9867 - precision: 0.9878 - recall: 0.9861 - val_loss: 13923.2422 - val_accuracy: 0.1332 - val_precision: 0.1332 - val_recall: 0.1332\n","Epoch 1236/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0357 - accuracy: 0.9885 - precision: 0.9888 - recall: 0.9877 - val_loss: 13982.9746 - val_accuracy: 0.1358 - val_precision: 0.1358 - val_recall: 0.1358\n","Epoch 1237/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0405 - accuracy: 0.9860 - precision: 0.9878 - recall: 0.9851 - val_loss: 16370.7344 - val_accuracy: 0.1028 - val_precision: 0.1028 - val_recall: 0.1028\n","Epoch 1238/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0468 - accuracy: 0.9840 - precision: 0.9844 - recall: 0.9833 - val_loss: 18430.7266 - val_accuracy: 0.0993 - val_precision: 0.0993 - val_recall: 0.0993\n","Epoch 1239/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0444 - accuracy: 0.9872 - precision: 0.9875 - recall: 0.9863 - val_loss: 15373.1738 - val_accuracy: 0.1165 - val_precision: 0.1165 - val_recall: 0.1165\n","Epoch 1240/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 0.0419 - accuracy: 0.9856 - precision: 0.9865 - recall: 0.9848 - val_loss: 17200.0762 - val_accuracy: 0.0988 - val_precision: 0.0988 - val_recall: 0.0988\n","Epoch 1241/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0377 - accuracy: 0.9865 - precision: 0.9873 - recall: 0.9860 - val_loss: 15797.1846 - val_accuracy: 0.1069 - val_precision: 0.1069 - val_recall: 0.1069\n","Epoch 1242/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 0.0285 - accuracy: 0.9909 - precision: 0.9912 - recall: 0.9907 - val_loss: 14319.4854 - val_accuracy: 0.1160 - val_precision: 0.1160 - val_recall: 0.1160\n","Epoch 1243/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0285 - accuracy: 0.9912 - precision: 0.9917 - recall: 0.9904 - val_loss: 13624.7656 - val_accuracy: 0.1201 - val_precision: 0.1201 - val_recall: 0.1201\n","Epoch 1244/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 0.0325 - accuracy: 0.9895 - precision: 0.9907 - recall: 0.9890 - val_loss: 16522.6387 - val_accuracy: 0.1008 - val_precision: 0.1008 - val_recall: 0.1008\n","Epoch 1245/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0416 - accuracy: 0.9860 - precision: 0.9868 - recall: 0.9856 - val_loss: 17406.4531 - val_accuracy: 0.0963 - val_precision: 0.0963 - val_recall: 0.0963\n","Epoch 1246/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0342 - accuracy: 0.9887 - precision: 0.9888 - recall: 0.9885 - val_loss: 12957.3857 - val_accuracy: 0.1272 - val_precision: 0.1272 - val_recall: 0.1272\n","Epoch 1247/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0355 - accuracy: 0.9867 - precision: 0.9881 - recall: 0.9858 - val_loss: 14346.1533 - val_accuracy: 0.1241 - val_precision: 0.1241 - val_recall: 0.1241\n","Epoch 1248/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0444 - accuracy: 0.9850 - precision: 0.9866 - recall: 0.9833 - val_loss: 15077.4170 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 1249/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0401 - accuracy: 0.9868 - precision: 0.9880 - recall: 0.9858 - val_loss: 15423.6387 - val_accuracy: 0.1028 - val_precision: 0.1028 - val_recall: 0.1028\n","Epoch 1250/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.0456 - accuracy: 0.9863 - precision: 0.9878 - recall: 0.9850 - val_loss: 14826.2930 - val_accuracy: 0.1013 - val_precision: 0.1013 - val_recall: 0.1013\n","Epoch 1251/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.0414 - accuracy: 0.9868 - precision: 0.9875 - recall: 0.9865 - val_loss: 15829.1807 - val_accuracy: 0.1054 - val_precision: 0.1054 - val_recall: 0.1054\n","Epoch 1252/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 0.0394 - accuracy: 0.9868 - precision: 0.9873 - recall: 0.9863 - val_loss: 13121.8477 - val_accuracy: 0.1363 - val_precision: 0.1363 - val_recall: 0.1363\n","Epoch 1253/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0382 - accuracy: 0.9878 - precision: 0.9887 - recall: 0.9872 - val_loss: 13010.1123 - val_accuracy: 0.1261 - val_precision: 0.1261 - val_recall: 0.1261\n","Epoch 1254/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0404 - accuracy: 0.9858 - precision: 0.9866 - recall: 0.9850 - val_loss: 18057.7695 - val_accuracy: 0.1069 - val_precision: 0.1069 - val_recall: 0.1069\n","Epoch 1255/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0277 - accuracy: 0.9910 - precision: 0.9915 - recall: 0.9905 - val_loss: 12313.1016 - val_accuracy: 0.1368 - val_precision: 0.1368 - val_recall: 0.1368\n","Epoch 1256/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0405 - accuracy: 0.9867 - precision: 0.9880 - recall: 0.9856 - val_loss: 15890.1318 - val_accuracy: 0.1140 - val_precision: 0.1140 - val_recall: 0.1140\n","Epoch 1257/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.0398 - accuracy: 0.9860 - precision: 0.9871 - recall: 0.9851 - val_loss: 14306.4805 - val_accuracy: 0.1282 - val_precision: 0.1282 - val_recall: 0.1282\n","Epoch 1258/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0365 - accuracy: 0.9887 - precision: 0.9892 - recall: 0.9873 - val_loss: 14055.3115 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 1259/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 0.0397 - accuracy: 0.9860 - precision: 0.9870 - recall: 0.9850 - val_loss: 17595.8828 - val_accuracy: 0.0993 - val_precision: 0.0993 - val_recall: 0.0993\n","Epoch 1260/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0390 - accuracy: 0.9861 - precision: 0.9881 - recall: 0.9853 - val_loss: 15019.4766 - val_accuracy: 0.1272 - val_precision: 0.1272 - val_recall: 0.1272\n","Epoch 1261/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0402 - accuracy: 0.9860 - precision: 0.9875 - recall: 0.9850 - val_loss: 14656.1719 - val_accuracy: 0.1439 - val_precision: 0.1439 - val_recall: 0.1439\n","Epoch 1262/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0343 - accuracy: 0.9894 - precision: 0.9903 - recall: 0.9882 - val_loss: 13177.2822 - val_accuracy: 0.1388 - val_precision: 0.1388 - val_recall: 0.1388\n","Epoch 1263/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0349 - accuracy: 0.9878 - precision: 0.9887 - recall: 0.9872 - val_loss: 13823.7363 - val_accuracy: 0.1256 - val_precision: 0.1256 - val_recall: 0.1256\n","Epoch 1264/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 0.0339 - accuracy: 0.9883 - precision: 0.9898 - recall: 0.9880 - val_loss: 14673.0420 - val_accuracy: 0.1211 - val_precision: 0.1211 - val_recall: 0.1211\n","Epoch 1265/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0371 - accuracy: 0.9878 - precision: 0.9888 - recall: 0.9873 - val_loss: 13886.9707 - val_accuracy: 0.1424 - val_precision: 0.1424 - val_recall: 0.1424\n","Epoch 1266/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0382 - accuracy: 0.9873 - precision: 0.9883 - recall: 0.9863 - val_loss: 14197.2432 - val_accuracy: 0.1408 - val_precision: 0.1408 - val_recall: 0.1408\n","Epoch 1267/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0414 - accuracy: 0.9860 - precision: 0.9870 - recall: 0.9851 - val_loss: 13597.7939 - val_accuracy: 0.1216 - val_precision: 0.1216 - val_recall: 0.1216\n","Epoch 1268/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0309 - accuracy: 0.9899 - precision: 0.9902 - recall: 0.9892 - val_loss: 13584.0977 - val_accuracy: 0.1317 - val_precision: 0.1317 - val_recall: 0.1317\n","Epoch 1269/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0311 - accuracy: 0.9882 - precision: 0.9888 - recall: 0.9875 - val_loss: 13514.4922 - val_accuracy: 0.1479 - val_precision: 0.1479 - val_recall: 0.1479\n","Epoch 1270/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0323 - accuracy: 0.9883 - precision: 0.9890 - recall: 0.9878 - val_loss: 13286.3408 - val_accuracy: 0.1454 - val_precision: 0.1454 - val_recall: 0.1454\n","Epoch 1271/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0393 - accuracy: 0.9875 - precision: 0.9880 - recall: 0.9865 - val_loss: 14689.7871 - val_accuracy: 0.1322 - val_precision: 0.1322 - val_recall: 0.1322\n","Epoch 1272/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0324 - accuracy: 0.9883 - precision: 0.9888 - recall: 0.9877 - val_loss: 14274.7832 - val_accuracy: 0.1510 - val_precision: 0.1510 - val_recall: 0.1510\n","Epoch 1273/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0403 - accuracy: 0.9875 - precision: 0.9887 - recall: 0.9873 - val_loss: 13726.0029 - val_accuracy: 0.1383 - val_precision: 0.1383 - val_recall: 0.1383\n","Epoch 1274/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0347 - accuracy: 0.9878 - precision: 0.9880 - recall: 0.9868 - val_loss: 14064.0010 - val_accuracy: 0.1373 - val_precision: 0.1373 - val_recall: 0.1373\n","Epoch 1275/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0400 - accuracy: 0.9850 - precision: 0.9856 - recall: 0.9843 - val_loss: 13748.8213 - val_accuracy: 0.1484 - val_precision: 0.1484 - val_recall: 0.1484\n","Epoch 1276/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 0.0479 - accuracy: 0.9850 - precision: 0.9855 - recall: 0.9848 - val_loss: 13247.7588 - val_accuracy: 0.1449 - val_precision: 0.1449 - val_recall: 0.1449\n","Epoch 1277/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0414 - accuracy: 0.9882 - precision: 0.9887 - recall: 0.9873 - val_loss: 12599.0166 - val_accuracy: 0.1373 - val_precision: 0.1373 - val_recall: 0.1373\n","Epoch 1278/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0327 - accuracy: 0.9890 - precision: 0.9900 - recall: 0.9887 - val_loss: 13133.6357 - val_accuracy: 0.1439 - val_precision: 0.1439 - val_recall: 0.1439\n","Epoch 1279/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0353 - accuracy: 0.9877 - precision: 0.9878 - recall: 0.9863 - val_loss: 14496.8594 - val_accuracy: 0.1064 - val_precision: 0.1064 - val_recall: 0.1064\n","Epoch 1280/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0454 - accuracy: 0.9860 - precision: 0.9870 - recall: 0.9848 - val_loss: 13564.9795 - val_accuracy: 0.1297 - val_precision: 0.1297 - val_recall: 0.1297\n","Epoch 1281/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0391 - accuracy: 0.9861 - precision: 0.9866 - recall: 0.9851 - val_loss: 14169.2969 - val_accuracy: 0.1175 - val_precision: 0.1175 - val_recall: 0.1175\n","Epoch 1282/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 0.0358 - accuracy: 0.9873 - precision: 0.9885 - recall: 0.9868 - val_loss: 15138.8838 - val_accuracy: 0.1226 - val_precision: 0.1226 - val_recall: 0.1226\n","Epoch 1283/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 0.0331 - accuracy: 0.9897 - precision: 0.9904 - recall: 0.9890 - val_loss: 14320.3555 - val_accuracy: 0.1256 - val_precision: 0.1256 - val_recall: 0.1256\n","Epoch 1284/10000\n"," 68/185 [==========>...................] - ETA: 9s - loss: 0.0325 - accuracy: 0.9885 - precision: 0.9885 - recall: 0.9885 "]}],"source":["history = model.fit(x_train,y_train,batch_size=32, epochs =10000, verbose =1, validation_data=(X_Val, y_Val))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zH2g9CLAqoo1"},"outputs":[],"source":["# y_pred = model.predict(x_test)\n","# y_pred = [np.round(value) for value in y_pred]\n","# print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oBF32zdwuWoQ"},"outputs":[],"source":["# prediction = model.predict(X[:1])\n","# np.where(prediction[0] == 1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"144lZB6D4cxU"},"outputs":[],"source":["output = model.predict(X) #Results are truncated (outputs where zero are magnitude E-29)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KYr4-otyB3eM"},"outputs":[],"source":["import pickle\n","pickle.dump(model, open('/content/drive/MyDrive/ENG 4000/model4.pkl', 'wb'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jEaDwKnRQ8Gn"},"outputs":[],"source":["from sklearn import decomposition\n","from sklearn.decomposition import PCA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q08KnnofM4Q4"},"outputs":[],"source":["#THIS IS A TEST\n","model.predict(valid_0) #We perform an inference\n","\n","#So we take the digit we looked at at the beginning of our validation set\n","#In the 7th position, we can see it has a 92% chance it is a 7\n","#A 4% chance it is a 9"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zqld16ViTbz5"},"outputs":[],"source":["#legacy, using old database\n","\n","X = [1e-02,2e-02,3e-02,4e-02,5e-02,6e-02,7e-02,8e-02,9e-02,10e-02,11e-02,34e-02]\n","\n","import psycopg2\n","connection = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=\"JYjdBJP2Cc7LaaN!\", host=\"db.ddxvuuzejyelldehkgyl.supabase.co\", port=\"5432\")\n","cursor = connection.cursor()\n","cursor.execute(\"INSERT INTO model_values VALUES (\" + \"'\" + str(X[0]) + \"', \" + \"'\" + str(X[1]) + \"', \" + \"'\" + str(X[2]) + \"', \" + \"'\" + str(X[3])\n"," + \"', \" + \"'\" + str(X[4]) + \"', \" + \"'\" + str(X[5]) + \"', \" + \"'\" + str(X[6]) + \"', \" + \"'\" + str(X[7]) + \"', \" + \"'\" + str(X[8]) + \"', \" + \"'\" +\n","  str(X[9]) + \"', \" + \"'\" + str(X[10]) + \"', \" + \"'\" + str(X[11]) + \"');\")\n","\n","connection.commit()\n","connection.close()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UXtlkzkK7W_3"},"outputs":[],"source":["# for X in output:\n","#   cursor.execute(\"INSERT INTO model_values VALUES (\" + \"'\" + str(X[0]) + \"', \" + \"'\" + str(X[1]) + \"', \" + \"'\" + str(X[2]) + \"', \" + \"'\" + str(X[3])\n","#  + \"', \" + \"'\" + str(X[4]) + \"', \" + \"'\" + str(X[5]) + \"', \" + \"'\" + str(X[6]) + \"', \" + \"'\" + str(X[7]) + \"', \" + \"'\" + str(X[8]) + \"', \" + \"'\" +\n","#   str(X[9]) + \"', \" + \"'\" + str(X[10]) + \"', \" + \"'\" + str(X[11]) + \"');\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UybH3D5ZOIpq"},"outputs":[],"source":["#Working code, using new google sql database\n","\n","X = [121e-02,2e-02,3e-02,4e-02,5e-02,6e-02,7e-02,8e-02,9e-02,10e-02,11e-02,34e-02] # test data\n","\n","from google.cloud.sql.connector import Connector, IPTypes\n","import sqlalchemy\n","\n","def getconn():\n","    with Connector() as connector:\n","        conn = connector.connect(\n","            \"potent-comfort-376221:northamerica-northeast2:the-pollen-project\", \n","            \"pg8000\",\n","            user=\"postgres\",\n","            password=\"lLyl3\\\"{xg9`X*t`Q\",\n","            db=\"postgres\",\n","            ip_type=IPTypes.PUBLIC \n","        )\n","    return conn\n","\n","pool = sqlalchemy.create_engine(\n","    \"postgresql+pg8000://\",\n","    creator=getconn,\n",")\n","\n","with pool.connect() as db_conn:\n","\n","    result = db_conn.execute(\"INSERT INTO pollen_data VALUES ( now(), '\" + str(X[0]) + \"', \" + \"'\" + str(X[1])\n","     + \"', \" + \"'\" + str(X[2]) + \"', \" + \"'\" + str(X[3]) + \"', \" + \"'\" + str(X[4]) + \"', \" + \"'\" + str(X[5])\n","      + \"', \" + \"'\" + str(X[6]) + \"', \" + \"'\" + str(X[7]) + \"', \" + \"'\" + str(X[8]) + \"', \" + \"'\" + str(X[9])\n","       + \"', \" + \"'\" + str(X[10]) + \"', \" + \"'\" + str(X[11]) + \"')\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d46yNVF_7whD","executionInfo":{"status":"error","timestamp":1675890550856,"user_tz":300,"elapsed":6,"user":{"displayName":"Mayuran Ganesathas","userId":"07492144986827614912"}},"outputId":"abca6cc8-2813-4632-c04c-3eb8d0892a09","colab":{"base_uri":"https://localhost:8080/","height":374}},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-7c7ab350565f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Working code, modified by Randy and Jimmy to be compatable with new SQL database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#!pip install \"cloud-sql-python-connector[pg8000]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConnector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIPTypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msqlalchemy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.cloud.sql'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["#Working code, modified by Randy and Jimmy to be compatable with new SQL database\n","#!pip install \"cloud-sql-python-connector[pg8000]\"\n","from google.cloud.sql.connector import Connector, IPTypes\n","import sqlalchemy\n","from sqlalchemy import text\n","\n","test = np.round(output, 3)\n","\n","def getconn():\n","    with Connector() as connector:\n","        conn = connector.connect(\n","            \"potent-comfort-376221:northamerica-northeast2:the-pollen-project\", \n","            \"pg8000\",\n","            user=\"postgres\",\n","            password=\"lLyl3\\\"{xg9`X*t`Q\",\n","            db=\"postgres\",\n","            ip_type=IPTypes.PUBLIC \n","        )\n","    return conn\n","\n","pool = sqlalchemy.create_engine(\"postgresql+pg8000://\",creator=getconn,)\n","i = 1\n","with pool.connect() as db_conn:\n","    for X in test:\n","        db_conn.execute(\"INSERT INTO pollen_data VALUES (\" + str(X[0]) + \", \" + \"\" + str(X[1]) + \", \"\n","          + str(X[2]) + \", \" + str(X[3]) + \", \" + str(X[4]) + \", \" + str(X[5]) + \", \" + str(X[6]) + \", \"\n","           + str(X[7]) + \", \" + str(X[8]) + \", \" +  str(X[9]) + \", \" + str(X[10]) + \", \" +  str(X[11])  + \", \" + str(i) + \")\")\n","        i+=1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W0gYi0WWFllf"},"outputs":[],"source":["import csv\n","\n","with open(\"data.csv\",\"w+\") as my_csv:\n","    csvWriter = csv.writer(my_csv,delimiter=',')\n","    csvWriter.writerows(output)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H4gcV4VZJUea"},"outputs":[],"source":["from google.colab import auth\n","auth.authenticate_user()\n","\n","\n","#@markdown Please fill in the value below with your GCP project ID and then run the cell.\n","\n","# Please fill in these values.\n","project_id = \"the-pollen-project\" #@param {type:\"string\"}\n","\n","# Quick input validations.\n","assert project_id, \"⚠️ Please provide a Google Cloud project ID\"\n","\n","# Configure gcloud.\n","!gcloud config set project {project_id}\n","\n","# grant Cloud SQL Client role to authenticated user\n","current_user = !gcloud auth list --filter=status:ACTIVE --format=\"value(account)\"\n","\n","!gcloud projects add-iam-policy-binding {project_id} \\\n","  --member=user:{current_user[0]} \\\n","  --role=\"roles/cloudsql.client\"\n","\n","!gcloud services enable sqladmin.googleapis.com\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7PeEUlT1Vs-i"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}